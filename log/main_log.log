2017-12-29 18:07:20,513 - tensorflow - INFO - this is a test message
2017-12-29 19:04:09,479 - tensorflow - INFO - this is a test message
2017-12-29 19:04:09,479 - tensorflow - INFO - this is a test message
2017-12-29 19:06:50,513 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:06:50,514 : INFO : collecting all words and their counts
2017-12-29 19:06:50,514 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:06:50,537 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:06:50,538 : INFO : Loading a fresh vocabulary
2017-12-29 19:06:50,644 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:06:50,645 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:06:50,666 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:06:50,667 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:06:50,667 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:06:50,667 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:06:50,679 : INFO : resetting layer weights
2017-12-29 19:06:50,764 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:06:51,238 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:06:51,238 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:06:51,245 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:06:51,245 : INFO : training on 797984 raw words (558278 effective words) took 0.5s, 1170701 effective words/s
2017-12-29 19:06:51,245 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:06:51,814 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:06:51,819 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:06:51,821 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:06:51,822 : INFO : training on 797984 raw words (558682 effective words) took 0.6s, 976258 effective words/s
2017-12-29 19:10:21,651 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:10:21,652 : INFO : collecting all words and their counts
2017-12-29 19:10:21,652 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:10:21,709 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:10:21,709 : INFO : Loading a fresh vocabulary
2017-12-29 19:10:21,848 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:10:21,848 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:10:21,877 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:10:21,880 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:10:21,880 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:10:21,881 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:10:21,920 : INFO : resetting layer weights
2017-12-29 19:10:22,025 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:10:22,461 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:10:22,466 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:10:22,469 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:10:22,470 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1271827 effective words/s
2017-12-29 19:10:22,470 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:10:22,921 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:10:22,926 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:10:22,927 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:10:22,927 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1235080 effective words/s
2017-12-29 19:13:37,278 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:13:37,279 : INFO : collecting all words and their counts
2017-12-29 19:13:37,279 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:13:37,311 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:13:37,312 : INFO : Loading a fresh vocabulary
2017-12-29 19:13:37,415 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:13:37,415 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:13:37,436 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:13:37,437 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:13:37,437 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:13:37,437 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:13:37,451 : INFO : resetting layer weights
2017-12-29 19:13:37,545 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:13:38,160 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:13:38,166 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:13:38,169 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:13:38,170 : INFO : training on 797984 raw words (558313 effective words) took 0.6s, 901067 effective words/s
2017-12-29 19:13:38,170 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:13:38,670 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:13:38,674 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:13:38,676 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:13:38,676 : INFO : training on 797984 raw words (558760 effective words) took 0.5s, 1126686 effective words/s
2018-01-02 09:24:51,347 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 09:24:51,353 : INFO : collecting all words and their counts
2018-01-02 09:24:51,354 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 09:24:51,378 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 09:24:51,378 : INFO : Loading a fresh vocabulary
2018-01-02 09:24:51,466 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 09:24:51,466 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 09:24:51,492 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 09:24:51,495 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 09:24:51,495 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 09:24:51,496 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 09:24:51,514 : INFO : resetting layer weights
2018-01-02 09:24:51,586 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:24:52,023 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:24:52,025 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:24:52,030 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:24:52,030 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1270283 effective words/s
2018-01-02 09:24:52,031 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:24:52,447 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:24:52,451 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:24:52,454 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:24:52,454 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1333767 effective words/s
2018-01-02 09:46:30,619 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 09:46:30,620 : INFO : collecting all words and their counts
2018-01-02 09:46:30,620 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 09:46:30,649 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 09:46:30,649 : INFO : Loading a fresh vocabulary
2018-01-02 09:46:30,666 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 09:46:30,666 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 09:46:30,688 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 09:46:30,688 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 09:46:30,688 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 09:46:30,688 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 09:46:30,706 : INFO : resetting layer weights
2018-01-02 09:46:30,786 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:46:31,212 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:46:31,219 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:46:31,220 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:46:31,220 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1382626 effective words/s
2018-01-02 10:01:03,125 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:01:03,126 : INFO : collecting all words and their counts
2018-01-02 10:01:03,126 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:01:03,150 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:01:03,150 : INFO : Loading a fresh vocabulary
2018-01-02 10:01:03,170 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:01:03,170 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:01:03,195 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:01:03,195 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:01:03,195 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:01:03,195 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:01:03,210 : INFO : resetting layer weights
2018-01-02 10:01:03,295 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:01:03,850 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:01:03,854 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:01:03,860 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:01:03,860 : INFO : training on 827888 raw words (591883 effective words) took 0.6s, 1055121 effective words/s
2018-01-02 10:02:34,197 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:02:34,198 : INFO : collecting all words and their counts
2018-01-02 10:02:34,198 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:02:34,221 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:02:34,222 : INFO : Loading a fresh vocabulary
2018-01-02 10:02:34,236 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:02:34,236 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:02:34,260 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:02:34,260 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:02:34,260 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:02:34,260 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:02:34,273 : INFO : resetting layer weights
2018-01-02 10:02:34,357 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:02:34,805 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:02:34,809 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:02:34,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:02:34,812 : INFO : training on 827888 raw words (592151 effective words) took 0.5s, 1312741 effective words/s
2018-01-02 10:02:51,234 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:02:51,234 : INFO : collecting all words and their counts
2018-01-02 10:02:51,234 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:02:51,258 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:02:51,258 : INFO : Loading a fresh vocabulary
2018-01-02 10:02:51,272 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:02:51,273 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:02:51,295 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:02:51,295 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:02:51,295 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:02:51,296 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:02:51,309 : INFO : resetting layer weights
2018-01-02 10:02:51,390 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:02:51,805 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:02:51,808 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:02:51,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:02:51,812 : INFO : training on 827888 raw words (591820 effective words) took 0.4s, 1416934 effective words/s
2018-01-02 10:03:19,652 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:03:19,652 : INFO : collecting all words and their counts
2018-01-02 10:03:19,652 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:03:19,678 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:03:19,678 : INFO : Loading a fresh vocabulary
2018-01-02 10:03:19,695 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:03:19,695 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:03:19,715 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:03:19,716 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:03:19,716 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:03:19,716 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:03:19,733 : INFO : resetting layer weights
2018-01-02 10:03:19,815 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:03:20,234 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:03:20,235 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:03:20,240 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:03:20,240 : INFO : training on 827888 raw words (592368 effective words) took 0.4s, 1408810 effective words/s
2018-01-02 10:06:10,206 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:06:10,207 : INFO : collecting all words and their counts
2018-01-02 10:06:10,208 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:06:10,231 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:06:10,231 : INFO : Loading a fresh vocabulary
2018-01-02 10:06:10,247 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:06:10,247 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:06:10,269 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:06:10,269 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:06:10,269 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:06:10,269 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:06:10,283 : INFO : resetting layer weights
2018-01-02 10:06:10,366 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:06:10,806 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:06:10,809 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:06:10,811 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:06:10,811 : INFO : training on 827888 raw words (591936 effective words) took 0.4s, 1342125 effective words/s
2018-01-02 10:06:35,126 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:06:35,126 : INFO : collecting all words and their counts
2018-01-02 10:06:35,126 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:06:35,149 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:06:35,150 : INFO : Loading a fresh vocabulary
2018-01-02 10:06:35,163 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:06:35,163 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:06:35,184 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:06:35,185 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:06:35,185 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:06:35,185 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:06:35,202 : INFO : resetting layer weights
2018-01-02 10:06:35,281 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:06:35,706 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:06:35,708 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:06:35,710 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:06:35,710 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1391799 effective words/s
2018-01-02 14:34:50,174 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:34:50,176 : INFO : collecting all words and their counts
2018-01-02 14:34:50,177 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:34:50,198 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 14:34:50,198 : INFO : Loading a fresh vocabulary
2018-01-02 14:34:50,212 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 14:34:50,212 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 14:34:50,231 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 14:34:50,232 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 14:34:50,232 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 14:34:50,232 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 14:34:50,245 : INFO : resetting layer weights
2018-01-02 14:34:50,322 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:34:50,888 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:34:50,895 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:34:50,898 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:34:50,898 : INFO : training on 827888 raw words (592108 effective words) took 0.6s, 1035817 effective words/s
2018-01-02 14:45:41,237 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:45:41,241 : INFO : collecting all words and their counts
2018-01-02 14:45:41,241 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:45:41,267 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:45:41,267 : INFO : Loading a fresh vocabulary
2018-01-02 14:45:41,286 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:45:41,287 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:45:41,305 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:45:41,305 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:45:41,305 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:45:41,307 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 14:45:41,321 : INFO : resetting layer weights
2018-01-02 14:45:41,399 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:45:41,905 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:45:41,907 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:45:41,912 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:45:41,912 : INFO : training on 797984 raw words (558613 effective words) took 0.5s, 1099640 effective words/s
2018-01-02 14:45:41,912 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:45:42,415 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:45:42,417 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:45:42,421 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:45:42,421 : INFO : training on 797984 raw words (558450 effective words) took 0.5s, 1107059 effective words/s
2018-01-02 14:53:28,707 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:53:28,708 : INFO : collecting all words and their counts
2018-01-02 14:53:28,708 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:53:28,738 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:53:28,738 : INFO : Loading a fresh vocabulary
2018-01-02 14:53:28,753 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:53:28,753 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:53:28,772 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:53:28,772 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:53:28,772 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:53:28,772 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 14:53:28,784 : INFO : resetting layer weights
2018-01-02 14:53:28,865 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:53:29,320 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:53:29,325 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:53:29,327 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:53:29,327 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1220903 effective words/s
2018-01-02 14:53:29,327 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:53:29,757 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:53:29,759 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:53:29,764 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:53:29,764 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1287463 effective words/s
2018-01-02 14:54:10,429 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:54:10,430 : INFO : collecting all words and their counts
2018-01-02 14:54:10,430 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:54:10,453 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:54:10,453 : INFO : Loading a fresh vocabulary
2018-01-02 14:54:10,468 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:54:10,468 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:54:10,485 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:54:10,485 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:54:10,485 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:54:10,485 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 14:54:10,496 : INFO : resetting layer weights
2018-01-02 14:54:10,569 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:54:10,984 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:54:10,986 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:54:10,989 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:54:10,989 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1343077 effective words/s
2018-01-02 14:54:10,989 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:54:11,402 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:54:11,404 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:54:11,406 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:54:11,406 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1350976 effective words/s
2018-01-02 15:00:47,778 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 15:00:47,778 : INFO : collecting all words and their counts
2018-01-02 15:00:47,778 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 15:00:47,801 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 15:00:47,801 : INFO : Loading a fresh vocabulary
2018-01-02 15:00:47,817 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 15:00:47,817 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 15:00:47,839 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 15:00:47,839 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 15:00:47,839 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 15:00:47,839 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 15:00:47,855 : INFO : resetting layer weights
2018-01-02 15:00:47,938 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 15:00:48,416 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 15:00:48,419 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 15:00:48,421 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 15:00:48,421 : INFO : training on 827888 raw words (592107 effective words) took 0.5s, 1241856 effective words/s
2018-01-02 16:50:34,146 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:50:34,147 : INFO : collecting all words and their counts
2018-01-02 16:50:34,147 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:50:34,171 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 16:50:34,171 : INFO : Loading a fresh vocabulary
2018-01-02 16:50:34,188 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 16:50:34,188 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 16:50:34,206 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 16:50:34,206 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 16:50:34,206 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 16:50:34,206 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 16:50:34,219 : INFO : resetting layer weights
2018-01-02 16:50:34,296 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:50:34,722 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:50:34,728 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:50:34,732 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:50:34,732 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1297903 effective words/s
2018-01-02 16:50:34,732 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:50:35,163 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:50:35,169 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:50:35,170 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:50:35,170 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1285754 effective words/s
2018-01-02 16:56:55,599 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:56:55,599 : INFO : collecting all words and their counts
2018-01-02 16:56:55,600 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:56:55,622 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 16:56:55,622 : INFO : Loading a fresh vocabulary
2018-01-02 16:56:55,634 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 16:56:55,635 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 16:56:55,652 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 16:56:55,652 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 16:56:55,652 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 16:56:55,652 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 16:56:55,666 : INFO : resetting layer weights
2018-01-02 16:56:55,748 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:56:56,185 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:56:56,185 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:56:56,190 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:56:56,190 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1277113 effective words/s
2018-01-02 16:56:56,190 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:56:56,612 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:56:56,615 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:56:56,618 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:56:56,619 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1314804 effective words/s
2018-01-02 16:59:00,231 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:59:00,231 : INFO : collecting all words and their counts
2018-01-02 16:59:00,232 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:59:00,257 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 16:59:00,257 : INFO : Loading a fresh vocabulary
2018-01-02 16:59:00,271 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 16:59:00,271 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 16:59:00,296 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 16:59:00,296 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 16:59:00,296 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 16:59:00,296 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 16:59:00,311 : INFO : resetting layer weights
2018-01-02 16:59:00,393 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:59:00,847 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:59:00,850 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:59:00,854 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:59:00,854 : INFO : training on 827888 raw words (592290 effective words) took 0.5s, 1296381 effective words/s
2018-01-02 17:11:02,710 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:02,713 : INFO : collecting all words and their counts
2018-01-02 17:11:02,713 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:02,737 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:02,738 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:02,758 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:02,758 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:02,781 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:02,781 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:02,781 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:02,781 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:02,796 : INFO : resetting layer weights
2018-01-02 17:11:02,882 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:03,424 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:03,427 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:03,431 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:03,431 : INFO : training on 827888 raw words (592301 effective words) took 0.5s, 1097077 effective words/s
2018-01-02 17:11:27,892 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:27,893 : INFO : collecting all words and their counts
2018-01-02 17:11:27,893 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:27,916 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:27,916 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:27,935 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:27,936 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:27,958 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:27,959 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:27,959 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:27,959 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:27,972 : INFO : resetting layer weights
2018-01-02 17:11:28,052 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:28,533 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:28,539 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:28,543 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:28,543 : INFO : training on 827888 raw words (591661 effective words) took 0.5s, 1217171 effective words/s
2018-01-02 17:11:55,212 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:55,214 : INFO : collecting all words and their counts
2018-01-02 17:11:55,214 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:55,241 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:55,241 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:55,264 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:55,264 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:55,286 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:55,287 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:55,287 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:55,287 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:55,305 : INFO : resetting layer weights
2018-01-02 17:11:55,386 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:55,847 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:55,849 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:55,854 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:55,854 : INFO : training on 827888 raw words (591820 effective words) took 0.5s, 1276808 effective words/s
2018-01-02 17:15:38,831 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:15:38,833 : INFO : collecting all words and their counts
2018-01-02 17:15:38,833 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:15:38,857 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:15:38,858 : INFO : Loading a fresh vocabulary
2018-01-02 17:15:38,877 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:15:38,877 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:15:38,898 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:15:38,898 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:15:38,898 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:15:38,899 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:15:38,915 : INFO : resetting layer weights
2018-01-02 17:15:38,994 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:15:39,605 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:15:39,608 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:15:39,616 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:15:39,616 : INFO : training on 827888 raw words (591653 effective words) took 0.6s, 957054 effective words/s
2018-01-02 17:20:33,540 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:20:33,544 : INFO : collecting all words and their counts
2018-01-02 17:20:33,544 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:20:33,569 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:20:33,569 : INFO : Loading a fresh vocabulary
2018-01-02 17:20:33,586 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:20:33,586 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:20:33,605 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:20:33,605 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:20:33,605 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:20:33,605 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:20:33,627 : INFO : resetting layer weights
2018-01-02 17:20:33,701 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:20:34,237 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:20:34,245 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:20:34,246 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:20:34,246 : INFO : training on 797984 raw words (558244 effective words) took 0.5s, 1032812 effective words/s
2018-01-02 17:20:34,246 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:20:34,841 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:20:34,846 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:20:34,849 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:20:34,850 : INFO : training on 797984 raw words (559026 effective words) took 0.6s, 933533 effective words/s
2018-01-02 17:21:42,251 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:21:42,251 : INFO : collecting all words and their counts
2018-01-02 17:21:42,251 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:21:42,279 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:21:42,279 : INFO : Loading a fresh vocabulary
2018-01-02 17:21:42,292 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:21:42,292 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:21:42,314 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:21:42,316 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:21:42,316 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:21:42,317 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:21:42,332 : INFO : resetting layer weights
2018-01-02 17:21:42,404 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:21:42,882 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:21:42,884 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:21:42,889 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:21:42,889 : INFO : training on 797984 raw words (558991 effective words) took 0.5s, 1164219 effective words/s
2018-01-02 17:21:42,889 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:21:43,338 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:21:43,342 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:21:43,344 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:21:43,344 : INFO : training on 797984 raw words (558657 effective words) took 0.5s, 1238396 effective words/s
2018-01-02 17:22:34,247 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:22:34,247 : INFO : collecting all words and their counts
2018-01-02 17:22:34,247 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:22:34,272 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:22:34,272 : INFO : Loading a fresh vocabulary
2018-01-02 17:22:34,289 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:22:34,290 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:22:34,310 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:22:34,310 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:22:34,310 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:22:34,310 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:22:34,324 : INFO : resetting layer weights
2018-01-02 17:22:34,395 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:22:34,865 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:22:34,868 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:22:34,871 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:22:34,871 : INFO : training on 797984 raw words (559130 effective words) took 0.5s, 1183127 effective words/s
2018-01-02 17:22:34,872 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:22:35,289 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:22:35,294 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:22:35,295 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:22:35,295 : INFO : training on 797984 raw words (558519 effective words) took 0.4s, 1332702 effective words/s
2018-01-02 17:26:53,448 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:26:53,448 : INFO : collecting all words and their counts
2018-01-02 17:26:53,448 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:26:53,470 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:26:53,470 : INFO : Loading a fresh vocabulary
2018-01-02 17:26:53,484 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:26:53,484 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:26:53,507 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:26:53,507 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:26:53,507 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:26:53,507 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:26:53,522 : INFO : resetting layer weights
2018-01-02 17:26:53,594 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:26:54,067 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:26:54,071 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:26:54,075 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:26:54,075 : INFO : training on 797984 raw words (558924 effective words) took 0.5s, 1173226 effective words/s
2018-01-02 17:26:54,075 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:26:54,594 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:26:54,596 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:26:54,599 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:26:54,599 : INFO : training on 797984 raw words (558926 effective words) took 0.5s, 1074545 effective words/s
2018-01-02 17:27:23,432 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:27:23,432 : INFO : collecting all words and their counts
2018-01-02 17:27:23,433 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:27:23,459 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:27:23,460 : INFO : Loading a fresh vocabulary
2018-01-02 17:27:23,475 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:27:23,475 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:27:23,503 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:27:23,504 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:27:23,504 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:27:23,504 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:27:23,519 : INFO : resetting layer weights
2018-01-02 17:27:23,587 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:27:24,023 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:27:24,027 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:27:24,030 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:27:24,030 : INFO : training on 797984 raw words (558463 effective words) took 0.4s, 1273150 effective words/s
2018-01-02 17:27:24,030 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:27:24,489 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:27:24,489 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:27:24,498 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:27:24,498 : INFO : training on 797984 raw words (558220 effective words) took 0.5s, 1203186 effective words/s
2018-01-02 17:28:32,158 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:28:32,159 : INFO : collecting all words and their counts
2018-01-02 17:28:32,159 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:28:32,181 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:28:32,181 : INFO : Loading a fresh vocabulary
2018-01-02 17:28:32,195 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:28:32,195 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:28:32,213 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:28:32,213 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:28:32,214 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:28:32,214 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:28:32,227 : INFO : resetting layer weights
2018-01-02 17:28:32,312 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:28:32,927 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:28:32,928 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:28:32,933 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:28:32,933 : INFO : training on 797984 raw words (558496 effective words) took 0.6s, 906040 effective words/s
2018-01-02 17:28:32,933 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:28:33,384 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:28:33,387 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:28:33,392 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:28:33,392 : INFO : training on 797984 raw words (558545 effective words) took 0.5s, 1231387 effective words/s
2018-01-02 17:33:28,376 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:33:28,377 : INFO : collecting all words and their counts
2018-01-02 17:33:28,377 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:33:28,401 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:33:28,401 : INFO : Loading a fresh vocabulary
2018-01-02 17:33:28,415 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:33:28,415 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:33:28,435 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:33:28,435 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:33:28,435 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:33:28,435 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:33:28,447 : INFO : resetting layer weights
2018-01-02 17:33:28,519 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:33:28,937 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:33:28,938 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:33:28,941 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:33:28,941 : INFO : training on 797984 raw words (558464 effective words) took 0.4s, 1339043 effective words/s
2018-01-02 17:33:28,941 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:33:29,363 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:33:29,367 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:33:29,370 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:33:29,370 : INFO : training on 797984 raw words (558276 effective words) took 0.4s, 1314765 effective words/s
2018-01-02 18:39:36,642 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:39:36,643 : INFO : collecting all words and their counts
2018-01-02 18:39:36,643 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:39:36,671 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:39:36,671 : INFO : Loading a fresh vocabulary
2018-01-02 18:39:36,695 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:39:36,695 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:39:36,714 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:39:36,714 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:39:36,714 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:39:36,714 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:39:36,728 : INFO : resetting layer weights
2018-01-02 18:39:36,798 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:37,237 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:37,242 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:37,244 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:37,244 : INFO : training on 797984 raw words (558538 effective words) took 0.4s, 1266320 effective words/s
2018-01-02 18:39:37,244 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:37,795 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:37,811 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:37,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:37,812 : INFO : training on 797984 raw words (558961 effective words) took 0.6s, 991490 effective words/s
2018-01-02 18:39:55,524 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:39:55,529 : INFO : collecting all words and their counts
2018-01-02 18:39:55,530 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:39:55,556 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:39:55,556 : INFO : Loading a fresh vocabulary
2018-01-02 18:39:55,579 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:39:55,579 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:39:55,596 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:39:55,596 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:39:55,597 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:39:55,597 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:39:55,610 : INFO : resetting layer weights
2018-01-02 18:39:55,688 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:56,112 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:56,118 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:56,120 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:56,120 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1308562 effective words/s
2018-01-02 18:39:56,120 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:56,556 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:56,561 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:56,562 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:56,563 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1273881 effective words/s
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:43:38,862 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:43:38,877 : INFO : collecting all words and their counts
2018-01-02 18:43:38,877 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:43:38,901 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:43:38,902 : INFO : Loading a fresh vocabulary
2018-01-02 18:43:38,917 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:43:38,917 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:43:38,938 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:43:38,938 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:43:38,938 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:43:38,939 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:43:38,955 : INFO : resetting layer weights
2018-01-02 18:43:39,042 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:43:39,501 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:43:39,506 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:43:39,507 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:43:39,507 : INFO : training on 827888 raw words (591936 effective words) took 0.5s, 1284742 effective words/s
2018-01-02 18:48:49,385 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:48:49,386 : INFO : collecting all words and their counts
2018-01-02 18:48:49,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:48:49,411 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:48:49,411 : INFO : Loading a fresh vocabulary
2018-01-02 18:48:49,429 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:48:49,430 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:48:49,453 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:48:49,453 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:48:49,453 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:48:49,453 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:48:49,470 : INFO : resetting layer weights
2018-01-02 18:48:49,549 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:48:49,971 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:48:49,976 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:48:49,978 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:48:49,978 : INFO : training on 827888 raw words (592080 effective words) took 0.4s, 1394608 effective words/s
2018-01-02 18:49:20,260 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:49:20,261 : INFO : collecting all words and their counts
2018-01-02 18:49:20,261 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:49:20,286 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:49:20,286 : INFO : Loading a fresh vocabulary
2018-01-02 18:49:20,304 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:49:20,305 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:49:20,322 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:49:20,322 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:49:20,322 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:49:20,322 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:49:20,334 : INFO : resetting layer weights
2018-01-02 18:49:20,421 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:49:20,845 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:49:20,846 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:49:20,849 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:49:20,849 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1320162 effective words/s
2018-01-02 18:49:20,850 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:49:21,274 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:49:21,276 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:49:21,281 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:49:21,281 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1305008 effective words/s
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:52:00,836 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:52:00,839 : INFO : collecting all words and their counts
2018-01-02 18:52:00,839 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:52:00,864 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:52:00,864 : INFO : Loading a fresh vocabulary
2018-01-02 18:52:00,880 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:52:00,880 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:52:00,901 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:52:00,902 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:52:00,902 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:52:00,902 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:52:00,919 : INFO : resetting layer weights
2018-01-02 18:52:01,000 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:52:01,425 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:52:01,429 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:52:01,432 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:52:01,433 : INFO : training on 827888 raw words (592108 effective words) took 0.4s, 1383641 effective words/s
2018-01-02 19:00:36,363 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:00:36,364 : INFO : collecting all words and their counts
2018-01-02 19:00:36,364 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:00:36,385 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:00:36,385 : INFO : Loading a fresh vocabulary
2018-01-02 19:00:36,399 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:00:36,399 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:00:36,416 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:00:36,416 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:00:36,416 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:00:36,417 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:00:36,430 : INFO : resetting layer weights
2018-01-02 19:00:36,503 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:36,934 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:36,942 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:36,945 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:36,945 : INFO : training on 797984 raw words (558607 effective words) took 0.4s, 1277989 effective words/s
2018-01-02 19:00:36,945 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:37,447 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:37,451 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:37,452 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:37,452 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1113653 effective words/s
2018-01-02 19:00:56,971 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:00:56,977 : INFO : collecting all words and their counts
2018-01-02 19:00:56,977 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:00:57,009 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:00:57,010 : INFO : Loading a fresh vocabulary
2018-01-02 19:00:57,023 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:00:57,023 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:00:57,045 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:00:57,045 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:00:57,045 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:00:57,045 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:00:57,057 : INFO : resetting layer weights
2018-01-02 19:00:57,145 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:57,573 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:57,581 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:57,582 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:57,582 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1289586 effective words/s
2018-01-02 19:00:57,583 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:57,999 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:58,005 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:58,007 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:58,007 : INFO : training on 797984 raw words (558457 effective words) took 0.4s, 1327425 effective words/s
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:01,785 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:05:01,786 : INFO : collecting all words and their counts
2018-01-02 19:05:01,786 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:05:01,808 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:05:01,808 : INFO : Loading a fresh vocabulary
2018-01-02 19:05:01,822 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:05:01,822 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:05:01,841 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:05:01,842 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:05:01,842 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:05:01,842 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:05:01,857 : INFO : resetting layer weights
2018-01-02 19:05:01,936 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:05:02,348 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:05:02,351 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:05:02,355 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:05:02,356 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1346070 effective words/s
2018-01-02 19:05:02,356 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:05:02,781 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:05:02,785 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:05:02,787 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:05:02,787 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1307127 effective words/s
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:07:44,909 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:07:44,909 : INFO : collecting all words and their counts
2018-01-02 19:07:44,909 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:07:44,931 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:07:44,931 : INFO : Loading a fresh vocabulary
2018-01-02 19:07:44,943 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:07:44,943 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:07:44,960 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:07:44,960 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:07:44,960 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:07:44,960 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:07:44,971 : INFO : resetting layer weights
2018-01-02 19:07:45,039 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:07:45,483 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:07:45,488 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:07:45,489 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:07:45,489 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1254369 effective words/s
2018-01-02 19:07:45,489 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:07:45,909 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:07:45,915 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:07:45,916 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:07:45,916 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1322208 effective words/s
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:12:58,387 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:12:58,387 : INFO : collecting all words and their counts
2018-01-02 19:12:58,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:12:58,410 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:12:58,410 : INFO : Loading a fresh vocabulary
2018-01-02 19:12:58,423 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:12:58,423 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:12:58,439 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:12:58,439 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:12:58,439 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:12:58,439 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:12:58,452 : INFO : resetting layer weights
2018-01-02 19:12:58,519 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:12:58,949 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:12:58,955 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:12:58,956 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:12:58,956 : INFO : training on 797984 raw words (558482 effective words) took 0.4s, 1289651 effective words/s
2018-01-02 19:12:58,956 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:12:59,387 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:12:59,392 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:12:59,394 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:12:59,394 : INFO : training on 797984 raw words (558258 effective words) took 0.4s, 1285742 effective words/s
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:22:48,251 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:22:48,252 : INFO : collecting all words and their counts
2018-01-02 19:22:48,252 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:22:48,278 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 19:22:48,278 : INFO : Loading a fresh vocabulary
2018-01-02 19:22:48,298 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 19:22:48,299 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 19:22:48,319 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 19:22:48,319 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 19:22:48,319 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 19:22:48,319 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 19:22:48,333 : INFO : resetting layer weights
2018-01-02 19:22:48,408 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:48,832 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:48,836 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:48,836 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:48,836 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1399837 effective words/s
2018-01-02 19:22:55,849 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:22:55,850 : INFO : collecting all words and their counts
2018-01-02 19:22:55,850 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:22:55,878 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:22:55,878 : INFO : Loading a fresh vocabulary
2018-01-02 19:22:55,892 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:22:55,893 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:22:55,913 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:22:55,914 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:22:55,914 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:22:55,914 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:22:55,926 : INFO : resetting layer weights
2018-01-02 19:22:56,002 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:56,418 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:56,422 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:56,425 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:56,425 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1334330 effective words/s
2018-01-02 19:22:56,425 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:56,837 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:56,844 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:56,846 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:56,846 : INFO : training on 797984 raw words (558916 effective words) took 0.4s, 1340855 effective words/s
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 : INFO : Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 : INFO : Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 : INFO : Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 : INFO : Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 : INFO : Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 : INFO : Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 : INFO : Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 : INFO : Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 : INFO : Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 : INFO : Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 : INFO : Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 : INFO : Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 : INFO : Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 : INFO : Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 : INFO : Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 : INFO : Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 : INFO : Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 : INFO : Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 : INFO : Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 : INFO : Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 : INFO : Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 : INFO : Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 : INFO : Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 : INFO : Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 : INFO : Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 : INFO : Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 : INFO : Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 : INFO : Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 : INFO : Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 : INFO : Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 : INFO : Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 : INFO : Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 : INFO : Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 : INFO : Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 : INFO : Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 : INFO : Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 : INFO : Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 : INFO : Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 : INFO : Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 : INFO : Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:28:03,149 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:28:03,150 : INFO : collecting all words and their counts
2018-01-02 19:28:03,150 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:28:03,178 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:28:03,178 : INFO : Loading a fresh vocabulary
2018-01-02 19:28:03,192 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:28:03,192 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:28:03,213 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:28:03,213 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:28:03,214 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:28:03,214 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 19:28:03,231 : INFO : resetting layer weights
2018-01-02 19:28:03,303 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:03,790 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:03,792 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:03,794 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:03,795 : INFO : training on 797984 raw words (558538 effective words) took 0.5s, 1146586 effective words/s
2018-01-02 19:28:03,795 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:04,296 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:04,299 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:04,304 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:04,304 : INFO : training on 797984 raw words (558204 effective words) took 0.5s, 1104781 effective words/s
2018-01-02 19:28:42,209 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:28:42,209 : INFO : collecting all words and their counts
2018-01-02 19:28:42,209 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:28:42,231 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:28:42,231 : INFO : Loading a fresh vocabulary
2018-01-02 19:28:42,244 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:28:42,245 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:28:42,262 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:28:42,262 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:28:42,262 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:28:42,262 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 19:28:42,274 : INFO : resetting layer weights
2018-01-02 19:28:42,349 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:42,790 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:42,797 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:42,797 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:42,797 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1259820 effective words/s
2018-01-02 19:28:42,798 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:43,244 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:43,251 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:43,253 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:43,253 : INFO : training on 797984 raw words (558916 effective words) took 0.5s, 1237408 effective words/s
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 : INFO : Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 : INFO : Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 : INFO : Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 : INFO : Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 : INFO : Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 : INFO : Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 : INFO : Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 : INFO : Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 : INFO : Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 : INFO : Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 : INFO : Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 : INFO : Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 : INFO : Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 : INFO : Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 : INFO : Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 : INFO : Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 : INFO : Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 : INFO : Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 : INFO : Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 : INFO : Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-03 09:50:27,808 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:50:27,812 : INFO : collecting all words and their counts
2018-01-03 09:50:27,813 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:50:27,845 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:50:27,846 : INFO : Loading a fresh vocabulary
2018-01-03 09:50:27,876 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:50:27,876 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:50:27,908 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:50:27,908 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:50:27,908 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:50:27,909 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:50:27,925 : INFO : resetting layer weights
2018-01-03 09:50:28,016 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:50:28,439 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:50:28,440 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:50:28,446 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:50:28,446 : INFO : training on 797984 raw words (558582 effective words) took 0.4s, 1333700 effective words/s
2018-01-03 09:50:28,446 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:50:28,950 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:50:28,953 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:50:28,956 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:50:28,956 : INFO : training on 797984 raw words (558696 effective words) took 0.5s, 1114391 effective words/s
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:53:59,151 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:53:59,151 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:53:59,151 : INFO : collecting all words and their counts
2018-01-03 09:53:59,151 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 09:53:59,152 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:53:59,152 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:53:59,177 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:53:59,177 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:53:59,177 : INFO : Loading a fresh vocabulary
2018-01-03 09:53:59,177 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 09:53:59,193 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:53:59,193 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:53:59,193 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:53:59,193 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:53:59,218 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:53:59,218 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 09:53:59,219 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 09:53:59,219 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:53:59,219 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:53:59,233 : INFO : resetting layer weights
2018-01-03 09:53:59,233 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 09:53:59,313 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,313 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,765 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:53:59,765 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:53:59,769 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:53:59,769 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:53:59,773 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:53:59,773 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1225854 effective words/s
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1225854 effective words/s
2018-01-03 09:53:59,773 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:54:00,357 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:54:00,357 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:54:00,366 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:54:00,366 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:54:00,369 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:54:00,369 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:54:00,369 : INFO : training on 797984 raw words (558766 effective words) took 0.6s, 947092 effective words/s
2018-01-03 09:54:00,369 - gensim.models.word2vec - INFO - training on 797984 raw words (558766 effective words) took 0.6s, 947092 effective words/s
2018-01-03 09:54:18,479 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:54:18,479 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:54:28,233 : INFO : Step 1, Minibatch Loss= 0.3887, Training Accuracy= 0.884
2018-01-03 09:54:28,233 - root - INFO - Step 1, Minibatch Loss= 0.3887, Training Accuracy= 0.884
2018-01-03 09:54:28,289 : INFO : Step 1, Validation Loss= 0.5196, Validation Accuracy= 0.751
2018-01-03 09:54:28,289 - root - INFO - Step 1, Validation Loss= 0.5196, Validation Accuracy= 0.751
2018-01-03 09:55:57,363 : INFO : test
2018-01-03 09:55:57,363 - root - INFO - test
2018-01-03 09:57:01,986 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:57:01,986 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:57:01,987 : INFO : collecting all words and their counts
2018-01-03 09:57:01,987 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 09:57:01,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:57:01,987 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:57:02,021 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:57:02,021 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:57:02,021 : INFO : Loading a fresh vocabulary
2018-01-03 09:57:02,021 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 09:57:02,039 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:57:02,039 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:57:02,040 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:57:02,040 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:57:02,078 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 09:57:02,078 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 09:57:02,078 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:57:02,079 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:57:02,079 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:57:02,100 : INFO : resetting layer weights
2018-01-03 09:57:02,100 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 09:57:02,170 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,170 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,632 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:02,632 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:02,634 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:02,634 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:02,641 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:02,641 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1200088 effective words/s
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1200088 effective words/s
2018-01-03 09:57:02,641 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:03,171 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:03,171 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:03,174 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:03,174 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:03,178 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:03,178 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:03,178 : INFO : training on 797984 raw words (558875 effective words) took 0.5s, 1049312 effective words/s
2018-01-03 09:57:03,178 - gensim.models.word2vec - INFO - training on 797984 raw words (558875 effective words) took 0.5s, 1049312 effective words/s
2018-01-03 09:57:21,546 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:57:21,546 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:57:31,145 : INFO : Step 1, Minibatch Loss= 0.2820, Training Accuracy= 0.923
2018-01-03 09:57:31,145 - root - INFO - Step 1, Minibatch Loss= 0.2820, Training Accuracy= 0.923
2018-01-03 09:57:31,200 : INFO : Step 1, Validation Loss= 0.4428, Validation Accuracy= 0.804
2018-01-03 09:57:31,200 - root - INFO - Step 1, Validation Loss= 0.4428, Validation Accuracy= 0.804
2018-01-03 09:57:31,201 : INFO : Code run-time: 29.735768795013428 seconds
2018-01-03 09:57:31,201 - root - INFO - Code run-time: 29.735768795013428 seconds
2018-01-03 10:08:30,512 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,512 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,512 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,513 : INFO : collecting all words and their counts
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:08:30,513 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,538 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 : INFO : Loading a fresh vocabulary
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:08:30,552 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,552 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,552 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,553 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,553 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,553 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,570 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,570 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,570 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,571 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,572 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,572 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,572 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,589 : INFO : resetting layer weights
2018-01-03 10:08:30,589 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:08:30,589 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:08:30,665 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:30,665 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:30,665 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,104 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,109 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,109 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,109 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,111 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,583 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,583 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,583 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,588 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,588 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,588 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,592 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,592 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,592 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,593 : INFO : training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:31,593 - gensim.models.word2vec - INFO - training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:31,593 - gensim.models.word2vec - INFO - training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:49,977 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:49,977 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:49,977 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:57,621 : INFO : Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,621 - root - INFO - Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,621 - root - INFO - Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,677 : INFO : Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 - root - INFO - Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 - root - INFO - Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 : INFO : Code run-time: 27.631388187408447 seconds
2018-01-03 10:08:57,677 - root - INFO - Code run-time: 27.631388187408447 seconds
2018-01-03 10:08:57,677 - root - INFO - Code run-time: 27.631388187408447 seconds
2018-01-03 10:10:22,344 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,344 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,344 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,345 : INFO : collecting all words and their counts
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:10:22,345 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,368 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 : INFO : Loading a fresh vocabulary
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:10:22,382 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,402 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,402 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,402 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,403 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,421 : INFO : resetting layer weights
2018-01-03 10:10:22,421 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:10:22,421 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:10:22,500 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,500 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,500 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,960 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,967 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,967 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,967 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,968 : INFO : training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:23,502 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,502 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,502 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,509 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,509 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,509 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,510 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 : INFO : training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:17:00,602 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,602 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,602 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,603 : INFO : collecting all words and their counts
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:17:00,603 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,626 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 : INFO : Loading a fresh vocabulary
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:17:00,640 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,659 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,660 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,660 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,660 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,674 : INFO : resetting layer weights
2018-01-03 10:17:00,674 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:17:00,674 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:17:00,750 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:00,750 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:00,750 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,176 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,181 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,182 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,616 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,616 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,616 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,622 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,622 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,622 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,624 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:21,615 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:21,615 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:21,615 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:29,250 : INFO : Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,250 - root - INFO - Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,250 - root - INFO - Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,305 : INFO : Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 - root - INFO - Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 - root - INFO - Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 : INFO : Code run-time: 29.17209815979004 seconds
2018-01-03 10:17:29,305 - root - INFO - Code run-time: 29.17209815979004 seconds
2018-01-03 10:17:29,305 - root - INFO - Code run-time: 29.17209815979004 seconds
2018-01-03 10:20:13,486 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:20:13,487 : INFO : collecting all words and their counts
2018-01-03 10:20:13,487 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:20:13,523 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:20:13,523 : INFO : Loading a fresh vocabulary
2018-01-03 10:20:13,539 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:20:13,539 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:20:13,556 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:20:13,557 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:20:13,557 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:20:13,557 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:20:13,568 : INFO : resetting layer weights
2018-01-03 10:20:13,639 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:20:14,072 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:20:14,075 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:20:14,078 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:20:14,078 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1283174 effective words/s
2018-01-03 10:20:14,079 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:20:14,496 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:20:14,499 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:20:14,503 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:20:14,503 : INFO : training on 797984 raw words (558651 effective words) took 0.4s, 1327742 effective words/s
2018-01-03 10:20:32,417 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:20:40,486 : INFO : Step 1, Minibatch Loss= 0.3690, Training Accuracy= 0.888
2018-01-03 10:20:40,550 : INFO : Step 1, Validation Loss= 0.5586, Validation Accuracy= 0.727
2018-01-03 10:20:40,551 : INFO : Code run-time: 27.581203937530518 seconds
2018-01-03 10:54:03,472 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:03,472 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:03,472 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:03,473 : INFO : collecting all words and their counts
2018-01-03 10:54:03,473 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:54:03,473 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:54:03,473 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:03,473 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:03,473 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:03,500 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:03,500 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:03,500 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:03,500 : INFO : Loading a fresh vocabulary
2018-01-03 10:54:03,500 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:54:03,500 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:54:03,517 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:03,517 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:03,517 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:03,517 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:03,517 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:03,517 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:03,535 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:03,535 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:03,535 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:03,536 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:03,536 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:03,536 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:03,536 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:03,551 : INFO : resetting layer weights
2018-01-03 10:54:03,551 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:54:03,551 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:54:03,628 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:03,628 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:03,628 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:04,099 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,099 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,099 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,104 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,105 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,105 : INFO : training on 797984 raw words (558659 effective words) took 0.5s, 1181584 effective words/s
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - training on 797984 raw words (558659 effective words) took 0.5s, 1181584 effective words/s
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - training on 797984 raw words (558659 effective words) took 0.5s, 1181584 effective words/s
2018-01-03 10:54:04,105 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:04,105 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:04,640 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,640 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,640 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:04,645 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:04,648 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:04,648 : INFO : training on 797984 raw words (558098 effective words) took 0.5s, 1037925 effective words/s
2018-01-03 10:54:04,648 - gensim.models.word2vec - INFO - training on 797984 raw words (558098 effective words) took 0.5s, 1037925 effective words/s
2018-01-03 10:54:04,648 - gensim.models.word2vec - INFO - training on 797984 raw words (558098 effective words) took 0.5s, 1037925 effective words/s
2018-01-03 10:54:35,456 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:35,456 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:35,456 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:54:35,456 : INFO : collecting all words and their counts
2018-01-03 10:54:35,456 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:54:35,456 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:54:35,457 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:35,457 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:35,457 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:54:35,482 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:35,482 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:35,482 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:54:35,483 : INFO : Loading a fresh vocabulary
2018-01-03 10:54:35,483 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:54:35,483 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:54:35,496 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:35,496 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:35,496 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:54:35,496 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:35,496 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:35,496 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:54:35,515 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:35,515 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:35,515 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:54:35,515 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:35,515 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:35,515 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:54:35,516 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:35,516 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:35,516 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:54:35,516 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:35,516 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:35,516 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:54:35,530 : INFO : resetting layer weights
2018-01-03 10:54:35,530 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:54:35,530 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:54:35,613 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:35,613 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:35,613 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:36,068 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,068 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,068 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,070 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,070 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,070 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,071 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,071 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,071 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,072 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1230343 effective words/s
2018-01-03 10:54:36,072 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1230343 effective words/s
2018-01-03 10:54:36,072 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1230343 effective words/s
2018-01-03 10:54:36,073 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:36,073 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:36,073 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:54:36,518 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,518 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,518 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:54:36,521 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,521 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,521 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:54:36,525 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,525 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,525 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:54:36,526 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1248147 effective words/s
2018-01-03 10:54:36,526 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1248147 effective words/s
2018-01-03 10:54:36,526 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1248147 effective words/s
2018-01-03 10:56:39,131 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:56:39,131 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:56:39,131 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:56:39,131 : INFO : collecting all words and their counts
2018-01-03 10:56:39,131 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:56:39,131 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:56:39,132 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:56:39,132 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:56:39,132 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:56:39,153 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:56:39,153 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:56:39,153 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:56:39,153 : INFO : Loading a fresh vocabulary
2018-01-03 10:56:39,153 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:56:39,153 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:56:39,166 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:56:39,166 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:56:39,166 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:56:39,167 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:56:39,167 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:56:39,167 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:56:39,183 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:56:39,183 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:56:39,183 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:56:39,183 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:56:39,183 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:56:39,183 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:56:39,184 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:56:39,184 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:56:39,184 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:56:39,184 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:56:39,184 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:56:39,184 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:56:39,195 : INFO : resetting layer weights
2018-01-03 10:56:39,195 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:56:39,195 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:56:39,289 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:39,289 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:39,289 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:39,766 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:39,766 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:39,766 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:39,768 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:39,768 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:39,768 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:39,773 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:39,773 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:39,773 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:39,774 : INFO : training on 797984 raw words (558890 effective words) took 0.5s, 1167795 effective words/s
2018-01-03 10:56:39,774 - gensim.models.word2vec - INFO - training on 797984 raw words (558890 effective words) took 0.5s, 1167795 effective words/s
2018-01-03 10:56:39,774 - gensim.models.word2vec - INFO - training on 797984 raw words (558890 effective words) took 0.5s, 1167795 effective words/s
2018-01-03 10:56:39,774 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:39,774 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:39,774 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:56:40,233 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:40,233 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:40,233 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:56:40,239 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:40,239 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:40,239 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:56:40,241 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:40,241 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:40,241 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:56:40,241 : INFO : training on 797984 raw words (558365 effective words) took 0.5s, 1207305 effective words/s
2018-01-03 10:56:40,241 - gensim.models.word2vec - INFO - training on 797984 raw words (558365 effective words) took 0.5s, 1207305 effective words/s
2018-01-03 10:56:40,241 - gensim.models.word2vec - INFO - training on 797984 raw words (558365 effective words) took 0.5s, 1207305 effective words/s
2018-01-03 10:59:02,234 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:59:02,234 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:59:02,234 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:59:02,234 : INFO : collecting all words and their counts
2018-01-03 10:59:02,234 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:59:02,234 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:59:02,235 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:59:02,235 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:59:02,235 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:59:02,272 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:59:02,272 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:59:02,272 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:59:02,273 : INFO : Loading a fresh vocabulary
2018-01-03 10:59:02,273 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:59:02,273 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:59:02,289 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:59:02,289 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:59:02,289 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:59:02,289 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:59:02,289 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:59:02,289 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:59:02,306 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:59:02,306 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:59:02,306 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:59:02,306 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:59:02,306 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:59:02,306 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:59:02,307 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:59:02,307 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:59:02,307 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:59:02,307 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:59:02,307 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:59:02,307 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:59:02,319 : INFO : resetting layer weights
2018-01-03 10:59:02,319 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:59:02,319 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:59:02,386 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:02,386 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:02,386 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:02,881 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:02,881 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:02,881 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:02,888 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:02,888 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:02,888 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:02,890 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:02,890 : INFO : training on 797984 raw words (558602 effective words) took 0.5s, 1117934 effective words/s
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - training on 797984 raw words (558602 effective words) took 0.5s, 1117934 effective words/s
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - training on 797984 raw words (558602 effective words) took 0.5s, 1117934 effective words/s
2018-01-03 10:59:02,890 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:02,890 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:59:03,336 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:03,336 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:03,336 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:59:03,341 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:03,341 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:03,341 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:59:03,341 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:03,341 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:03,341 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:59:03,342 : INFO : training on 797984 raw words (558149 effective words) took 0.4s, 1248148 effective words/s
2018-01-03 10:59:03,342 - gensim.models.word2vec - INFO - training on 797984 raw words (558149 effective words) took 0.4s, 1248148 effective words/s
2018-01-03 10:59:03,342 - gensim.models.word2vec - INFO - training on 797984 raw words (558149 effective words) took 0.4s, 1248148 effective words/s
2018-01-03 11:39:51,252 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 11:39:51,252 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 11:39:51,252 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 11:39:51,253 : INFO : collecting all words and their counts
2018-01-03 11:39:51,253 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 11:39:51,253 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 11:39:51,253 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 11:39:51,253 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 11:39:51,253 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 11:39:51,279 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 11:39:51,279 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 11:39:51,279 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 11:39:51,280 : INFO : Loading a fresh vocabulary
2018-01-03 11:39:51,280 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 11:39:51,280 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 11:39:51,295 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 11:39:51,295 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 11:39:51,295 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 11:39:51,296 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 11:39:51,296 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 11:39:51,296 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 11:39:51,314 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 11:39:51,314 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 11:39:51,314 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 11:39:51,314 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 11:39:51,315 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 11:39:51,315 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 11:39:51,315 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 11:39:51,335 : INFO : resetting layer weights
2018-01-03 11:39:51,335 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 11:39:51,335 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 11:39:51,412 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:51,412 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:51,412 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:52,050 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,050 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,050 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,056 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,056 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,056 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,059 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,059 : INFO : training on 797984 raw words (558609 effective words) took 0.6s, 869406 effective words/s
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.6s, 869406 effective words/s
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.6s, 869406 effective words/s
2018-01-03 11:39:52,059 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:52,059 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 11:39:52,650 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,650 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,650 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 11:39:52,654 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,654 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,654 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 11:39:52,656 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,656 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,656 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 11:39:52,656 : INFO : training on 797984 raw words (558667 effective words) took 0.6s, 946423 effective words/s
2018-01-03 11:39:52,656 - gensim.models.word2vec - INFO - training on 797984 raw words (558667 effective words) took 0.6s, 946423 effective words/s
2018-01-03 11:39:52,656 - gensim.models.word2vec - INFO - training on 797984 raw words (558667 effective words) took 0.6s, 946423 effective words/s
2018-01-03 11:40:10,774 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 11:40:10,774 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 11:40:10,774 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 11:40:18,568 : INFO : Step 1, Minibatch Loss= 0.4877, Training Accuracy= 0.773
2018-01-03 11:40:18,568 - root - INFO - Step 1, Minibatch Loss= 0.4877, Training Accuracy= 0.773
2018-01-03 11:40:18,568 - root - INFO - Step 1, Minibatch Loss= 0.4877, Training Accuracy= 0.773
2018-01-03 11:40:18,621 : INFO : Step 1, Validation Loss= 0.7515, Validation Accuracy= 0.484
2018-01-03 11:40:18,621 - root - INFO - Step 1, Validation Loss= 0.7515, Validation Accuracy= 0.484
2018-01-03 11:40:18,621 - root - INFO - Step 1, Validation Loss= 0.7515, Validation Accuracy= 0.484
2018-01-03 11:40:18,622 : INFO : Code run-time: 27.86012077331543 seconds
2018-01-03 11:40:18,622 - root - INFO - Code run-time: 27.86012077331543 seconds
2018-01-03 11:40:18,622 - root - INFO - Code run-time: 27.86012077331543 seconds
2018-01-03 12:09:35,265 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:09:35,265 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:09:35,265 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:09:35,266 : INFO : collecting all words and their counts
2018-01-03 12:09:35,266 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:09:35,266 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:09:35,266 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:09:35,266 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:09:35,266 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:09:35,302 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:09:35,302 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:09:35,302 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:09:35,302 : INFO : Loading a fresh vocabulary
2018-01-03 12:09:35,302 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:09:35,302 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:09:35,322 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:09:35,322 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:09:35,322 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:09:35,324 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:09:35,324 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:09:35,324 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:09:35,349 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:09:35,349 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:09:35,349 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:09:35,349 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:09:35,350 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:09:35,350 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:09:35,350 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:09:35,364 : INFO : resetting layer weights
2018-01-03 12:09:35,364 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:09:35,364 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:09:35,434 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:35,434 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:35,434 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:35,904 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:35,904 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:35,904 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:35,910 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:35,910 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:35,910 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:35,911 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:35,911 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:35,911 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:35,911 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1182981 effective words/s
2018-01-03 12:09:35,911 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1182981 effective words/s
2018-01-03 12:09:35,911 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1182981 effective words/s
2018-01-03 12:09:35,912 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:35,912 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:35,912 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:09:36,382 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:36,382 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:36,382 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:09:36,387 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:36,387 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:36,387 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:09:36,391 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:36,391 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:36,391 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:09:36,391 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1177541 effective words/s
2018-01-03 12:09:36,391 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1177541 effective words/s
2018-01-03 12:09:36,391 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1177541 effective words/s
2018-01-03 12:09:57,016 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:09:57,016 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:09:57,016 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:09:57,016 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:09:57,016 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:09:57,016 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:10:48,124 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:10:48,124 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:10:48,124 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:10:48,124 : INFO : collecting all words and their counts
2018-01-03 12:10:48,124 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:10:48,124 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:10:48,125 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:10:48,125 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:10:48,125 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:10:48,168 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:10:48,168 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:10:48,168 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:10:48,169 : INFO : Loading a fresh vocabulary
2018-01-03 12:10:48,169 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:10:48,169 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:10:48,189 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:10:48,189 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:10:48,189 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:10:48,189 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:10:48,189 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:10:48,189 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:10:48,208 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:10:48,208 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:10:48,208 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:10:48,208 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:10:48,208 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:10:48,208 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:10:48,209 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:10:48,209 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:10:48,209 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:10:48,209 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:10:48,209 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:10:48,209 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:10:48,222 : INFO : resetting layer weights
2018-01-03 12:10:48,222 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:10:48,222 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:10:48,303 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:48,303 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:48,303 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:48,751 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:48,751 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:48,751 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:48,754 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:48,754 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:48,754 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:48,759 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:48,759 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:48,759 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:48,760 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1237399 effective words/s
2018-01-03 12:10:48,760 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1237399 effective words/s
2018-01-03 12:10:48,760 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1237399 effective words/s
2018-01-03 12:10:48,760 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:48,760 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:48,760 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:10:49,217 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:49,217 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:49,217 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:10:49,218 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:49,218 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:49,218 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:10:49,224 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:49,224 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:49,224 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:10:49,224 : INFO : training on 797984 raw words (558919 effective words) took 0.5s, 1217028 effective words/s
2018-01-03 12:10:49,224 - gensim.models.word2vec - INFO - training on 797984 raw words (558919 effective words) took 0.5s, 1217028 effective words/s
2018-01-03 12:10:49,224 - gensim.models.word2vec - INFO - training on 797984 raw words (558919 effective words) took 0.5s, 1217028 effective words/s
2018-01-03 12:11:06,764 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:11:06,764 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:11:06,764 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:11:06,764 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:11:06,764 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:11:06,764 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:12:41,066 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:12:41,066 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:12:41,066 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:12:41,067 : INFO : collecting all words and their counts
2018-01-03 12:12:41,067 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:12:41,067 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:12:41,067 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:12:41,067 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:12:41,067 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:12:41,093 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:12:41,093 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:12:41,093 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:12:41,093 : INFO : Loading a fresh vocabulary
2018-01-03 12:12:41,093 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:12:41,093 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:12:41,111 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:12:41,111 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:12:41,111 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:12:41,111 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:12:41,111 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:12:41,111 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:12:41,128 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:12:41,128 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:12:41,128 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:12:41,129 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:12:41,129 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:12:41,129 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:12:41,129 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:12:41,147 : INFO : resetting layer weights
2018-01-03 12:12:41,147 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:12:41,147 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:12:41,219 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:41,219 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:41,219 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:41,642 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:41,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:41,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:41,645 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:41,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:41,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:41,648 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:41,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:41,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:41,648 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1315416 effective words/s
2018-01-03 12:12:41,648 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1315416 effective words/s
2018-01-03 12:12:41,648 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1315416 effective words/s
2018-01-03 12:12:41,649 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:41,649 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:41,649 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:12:42,114 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:42,114 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:42,114 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:12:42,119 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:42,119 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:42,119 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:12:42,121 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:42,121 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:42,121 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:12:42,121 : INFO : training on 797984 raw words (558916 effective words) took 0.5s, 1196131 effective words/s
2018-01-03 12:12:42,121 - gensim.models.word2vec - INFO - training on 797984 raw words (558916 effective words) took 0.5s, 1196131 effective words/s
2018-01-03 12:12:42,121 - gensim.models.word2vec - INFO - training on 797984 raw words (558916 effective words) took 0.5s, 1196131 effective words/s
2018-01-03 12:13:01,178 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:01,178 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:01,178 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:01,178 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:13:01,178 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:13:01,178 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:13:08,692 : INFO : Step 1, Minibatch Loss= 0.2040, Training Accuracy= 0.923
2018-01-03 12:13:08,692 - root - INFO - Step 1, Minibatch Loss= 0.2040, Training Accuracy= 0.923
2018-01-03 12:13:08,692 - root - INFO - Step 1, Minibatch Loss= 0.2040, Training Accuracy= 0.923
2018-01-03 12:13:08,753 : INFO : Step 1, Validation Loss= 0.2977, Validation Accuracy= 0.852
2018-01-03 12:13:08,753 - root - INFO - Step 1, Validation Loss= 0.2977, Validation Accuracy= 0.852
2018-01-03 12:13:08,753 - root - INFO - Step 1, Validation Loss= 0.2977, Validation Accuracy= 0.852
2018-01-03 12:13:08,753 : INFO : starting fold 2 in 10-fold CV
2018-01-03 12:13:08,753 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:13:08,753 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:13:16,277 : INFO : Step 1, Minibatch Loss= 0.4322, Training Accuracy= 0.817
2018-01-03 12:13:16,277 - root - INFO - Step 1, Minibatch Loss= 0.4322, Training Accuracy= 0.817
2018-01-03 12:13:16,277 - root - INFO - Step 1, Minibatch Loss= 0.4322, Training Accuracy= 0.817
2018-01-03 12:13:16,333 : INFO : Step 1, Validation Loss= 0.6033, Validation Accuracy= 0.619
2018-01-03 12:13:16,333 - root - INFO - Step 1, Validation Loss= 0.6033, Validation Accuracy= 0.619
2018-01-03 12:13:16,333 - root - INFO - Step 1, Validation Loss= 0.6033, Validation Accuracy= 0.619
2018-01-03 12:13:16,334 : INFO : starting fold 3 in 10-fold CV
2018-01-03 12:13:16,334 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:13:16,334 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:13:22,949 : INFO : Step 1, Minibatch Loss= 0.3391, Training Accuracy= 0.906
2018-01-03 12:13:22,949 - root - INFO - Step 1, Minibatch Loss= 0.3391, Training Accuracy= 0.906
2018-01-03 12:13:22,949 - root - INFO - Step 1, Minibatch Loss= 0.3391, Training Accuracy= 0.906
2018-01-03 12:13:23,014 : INFO : Step 1, Validation Loss= 0.3184, Validation Accuracy= 0.903
2018-01-03 12:13:23,014 - root - INFO - Step 1, Validation Loss= 0.3184, Validation Accuracy= 0.903
2018-01-03 12:13:23,014 - root - INFO - Step 1, Validation Loss= 0.3184, Validation Accuracy= 0.903
2018-01-03 12:13:23,015 : INFO : starting fold 4 in 10-fold CV
2018-01-03 12:13:23,015 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:13:23,015 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:13:35,566 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:13:35,566 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:13:35,566 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:13:35,567 : INFO : collecting all words and their counts
2018-01-03 12:13:35,567 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:13:35,567 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:13:35,568 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:13:35,568 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:13:35,568 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:13:35,596 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:13:35,596 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:13:35,596 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:13:35,596 : INFO : Loading a fresh vocabulary
2018-01-03 12:13:35,596 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:13:35,596 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:13:35,610 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:13:35,610 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:13:35,610 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:13:35,610 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:13:35,610 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:13:35,610 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:13:35,628 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:13:35,628 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:13:35,628 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:13:35,628 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:13:35,628 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:13:35,628 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:13:35,629 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:13:35,629 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:13:35,629 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:13:35,629 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:13:35,629 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:13:35,629 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:13:35,648 : INFO : resetting layer weights
2018-01-03 12:13:35,648 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:13:35,648 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:13:35,723 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:35,723 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:35,723 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:36,251 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,251 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,251 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,255 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,255 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,255 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,261 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,261 : INFO : training on 797984 raw words (558580 effective words) took 0.5s, 1046906 effective words/s
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - training on 797984 raw words (558580 effective words) took 0.5s, 1046906 effective words/s
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - training on 797984 raw words (558580 effective words) took 0.5s, 1046906 effective words/s
2018-01-03 12:13:36,261 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:36,261 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:13:36,752 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,752 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,752 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:13:36,757 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,757 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,757 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:13:36,759 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,759 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,759 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:13:36,760 : INFO : training on 797984 raw words (558166 effective words) took 0.5s, 1130872 effective words/s
2018-01-03 12:13:36,760 - gensim.models.word2vec - INFO - training on 797984 raw words (558166 effective words) took 0.5s, 1130872 effective words/s
2018-01-03 12:13:36,760 - gensim.models.word2vec - INFO - training on 797984 raw words (558166 effective words) took 0.5s, 1130872 effective words/s
2018-01-03 12:13:54,762 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:54,762 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:54,762 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:13:54,763 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:13:54,763 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:13:54,763 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:14:03,292 : INFO : Step 1, Minibatch Loss= 0.4196, Training Accuracy= 0.820
2018-01-03 12:14:03,292 - root - INFO - Step 1, Minibatch Loss= 0.4196, Training Accuracy= 0.820
2018-01-03 12:14:03,292 - root - INFO - Step 1, Minibatch Loss= 0.4196, Training Accuracy= 0.820
2018-01-03 12:14:03,350 : INFO : Step 1, Validation Loss= 0.4449, Validation Accuracy= 0.804
2018-01-03 12:14:03,350 - root - INFO - Step 1, Validation Loss= 0.4449, Validation Accuracy= 0.804
2018-01-03 12:14:03,350 - root - INFO - Step 1, Validation Loss= 0.4449, Validation Accuracy= 0.804
2018-01-03 12:14:05,234 : INFO : Step 2, Minibatch Loss= 0.1516, Training Accuracy= 0.950
2018-01-03 12:14:05,234 - root - INFO - Step 2, Minibatch Loss= 0.1516, Training Accuracy= 0.950
2018-01-03 12:14:05,234 - root - INFO - Step 2, Minibatch Loss= 0.1516, Training Accuracy= 0.950
2018-01-03 12:14:05,289 : INFO : Step 2, Validation Loss= 0.3870, Validation Accuracy= 0.854
2018-01-03 12:14:05,289 - root - INFO - Step 2, Validation Loss= 0.3870, Validation Accuracy= 0.854
2018-01-03 12:14:05,289 - root - INFO - Step 2, Validation Loss= 0.3870, Validation Accuracy= 0.854
2018-01-03 12:14:07,229 : INFO : Step 3, Minibatch Loss= 0.0937, Training Accuracy= 0.970
2018-01-03 12:14:07,229 - root - INFO - Step 3, Minibatch Loss= 0.0937, Training Accuracy= 0.970
2018-01-03 12:14:07,229 - root - INFO - Step 3, Minibatch Loss= 0.0937, Training Accuracy= 0.970
2018-01-03 12:14:07,283 : INFO : Step 3, Validation Loss= 0.2509, Validation Accuracy= 0.920
2018-01-03 12:14:07,283 - root - INFO - Step 3, Validation Loss= 0.2509, Validation Accuracy= 0.920
2018-01-03 12:14:07,283 - root - INFO - Step 3, Validation Loss= 0.2509, Validation Accuracy= 0.920
2018-01-03 12:14:09,064 : INFO : Step 4, Minibatch Loss= 0.0520, Training Accuracy= 0.983
2018-01-03 12:14:09,064 - root - INFO - Step 4, Minibatch Loss= 0.0520, Training Accuracy= 0.983
2018-01-03 12:14:09,064 - root - INFO - Step 4, Minibatch Loss= 0.0520, Training Accuracy= 0.983
2018-01-03 12:14:09,118 : INFO : Step 4, Validation Loss= 0.3029, Validation Accuracy= 0.916
2018-01-03 12:14:09,118 - root - INFO - Step 4, Validation Loss= 0.3029, Validation Accuracy= 0.916
2018-01-03 12:14:09,118 - root - INFO - Step 4, Validation Loss= 0.3029, Validation Accuracy= 0.916
2018-01-03 12:14:09,118 : INFO : starting fold 2 in 10-fold CV
2018-01-03 12:14:09,118 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:14:09,118 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:16:41,948 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:16:41,948 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:16:41,948 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:16:41,949 : INFO : collecting all words and their counts
2018-01-03 12:16:41,949 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:16:41,949 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:16:41,949 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:16:41,949 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:16:41,949 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:16:41,977 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:16:41,977 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:16:41,977 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:16:41,977 : INFO : Loading a fresh vocabulary
2018-01-03 12:16:41,977 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:16:41,977 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:16:41,989 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:16:41,989 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:16:41,989 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:16:41,990 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:16:41,990 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:16:41,990 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:16:42,008 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:16:42,008 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:16:42,008 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:16:42,009 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:16:42,009 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:16:42,009 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:16:42,009 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:16:42,021 : INFO : resetting layer weights
2018-01-03 12:16:42,021 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:16:42,021 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:16:42,099 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,099 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,099 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,544 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,544 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,544 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,545 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:42,545 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:42,545 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:42,550 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:42,550 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:42,550 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:42,550 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1249622 effective words/s
2018-01-03 12:16:42,550 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1249622 effective words/s
2018-01-03 12:16:42,550 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1249622 effective words/s
2018-01-03 12:16:42,551 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,551 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,551 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:16:42,993 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,993 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,993 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:16:42,998 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:42,998 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:42,998 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:16:43,002 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:43,002 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:43,002 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:16:43,002 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1249408 effective words/s
2018-01-03 12:16:43,002 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1249408 effective words/s
2018-01-03 12:16:43,002 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1249408 effective words/s
2018-01-03 12:17:02,288 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:17:02,288 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:17:02,288 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:17:02,288 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:17:02,288 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:17:02,288 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:17:09,796 : INFO : Step 1, Minibatch Loss= 0.4208, Training Accuracy= 0.828
2018-01-03 12:17:09,796 - root - INFO - Step 1, Minibatch Loss= 0.4208, Training Accuracy= 0.828
2018-01-03 12:17:09,796 - root - INFO - Step 1, Minibatch Loss= 0.4208, Training Accuracy= 0.828
2018-01-03 12:17:09,857 : INFO : Step 1, Validation Loss= 0.4566, Validation Accuracy= 0.809
2018-01-03 12:17:09,857 - root - INFO - Step 1, Validation Loss= 0.4566, Validation Accuracy= 0.809
2018-01-03 12:17:09,857 - root - INFO - Step 1, Validation Loss= 0.4566, Validation Accuracy= 0.809
2018-01-03 12:17:11,764 : INFO : Step 2, Minibatch Loss= 0.1459, Training Accuracy= 0.948
2018-01-03 12:17:11,764 - root - INFO - Step 2, Minibatch Loss= 0.1459, Training Accuracy= 0.948
2018-01-03 12:17:11,764 - root - INFO - Step 2, Minibatch Loss= 0.1459, Training Accuracy= 0.948
2018-01-03 12:17:11,818 : INFO : Step 2, Validation Loss= 0.3012, Validation Accuracy= 0.897
2018-01-03 12:17:11,818 - root - INFO - Step 2, Validation Loss= 0.3012, Validation Accuracy= 0.897
2018-01-03 12:17:11,818 - root - INFO - Step 2, Validation Loss= 0.3012, Validation Accuracy= 0.897
2018-01-03 12:17:13,698 : INFO : Step 3, Minibatch Loss= 0.0982, Training Accuracy= 0.962
2018-01-03 12:17:13,698 - root - INFO - Step 3, Minibatch Loss= 0.0982, Training Accuracy= 0.962
2018-01-03 12:17:13,698 - root - INFO - Step 3, Minibatch Loss= 0.0982, Training Accuracy= 0.962
2018-01-03 12:17:13,752 : INFO : Step 3, Validation Loss= 0.1207, Validation Accuracy= 0.955
2018-01-03 12:17:13,752 - root - INFO - Step 3, Validation Loss= 0.1207, Validation Accuracy= 0.955
2018-01-03 12:17:13,752 - root - INFO - Step 3, Validation Loss= 0.1207, Validation Accuracy= 0.955
2018-01-03 12:17:15,578 : INFO : Step 4, Minibatch Loss= 0.0504, Training Accuracy= 0.983
2018-01-03 12:17:15,578 - root - INFO - Step 4, Minibatch Loss= 0.0504, Training Accuracy= 0.983
2018-01-03 12:17:15,578 - root - INFO - Step 4, Minibatch Loss= 0.0504, Training Accuracy= 0.983
2018-01-03 12:17:15,633 : INFO : Step 4, Validation Loss= 0.3371, Validation Accuracy= 0.888
2018-01-03 12:17:15,633 - root - INFO - Step 4, Validation Loss= 0.3371, Validation Accuracy= 0.888
2018-01-03 12:17:15,633 - root - INFO - Step 4, Validation Loss= 0.3371, Validation Accuracy= 0.888
2018-01-03 12:17:15,633 : INFO : starting fold 2 in 10-fold CV
2018-01-03 12:17:15,633 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:17:15,633 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:17:23,262 : INFO : Step 1, Minibatch Loss= 0.2944, Training Accuracy= 0.904
2018-01-03 12:17:23,262 - root - INFO - Step 1, Minibatch Loss= 0.2944, Training Accuracy= 0.904
2018-01-03 12:17:23,262 - root - INFO - Step 1, Minibatch Loss= 0.2944, Training Accuracy= 0.904
2018-01-03 12:17:23,318 : INFO : Step 1, Validation Loss= 0.3171, Validation Accuracy= 0.849
2018-01-03 12:17:23,318 - root - INFO - Step 1, Validation Loss= 0.3171, Validation Accuracy= 0.849
2018-01-03 12:17:23,318 - root - INFO - Step 1, Validation Loss= 0.3171, Validation Accuracy= 0.849
2018-01-03 12:17:25,244 : INFO : Step 2, Minibatch Loss= 0.1034, Training Accuracy= 0.964
2018-01-03 12:17:25,244 - root - INFO - Step 2, Minibatch Loss= 0.1034, Training Accuracy= 0.964
2018-01-03 12:17:25,244 - root - INFO - Step 2, Minibatch Loss= 0.1034, Training Accuracy= 0.964
2018-01-03 12:17:25,298 : INFO : Step 2, Validation Loss= 0.1633, Validation Accuracy= 0.918
2018-01-03 12:17:25,298 - root - INFO - Step 2, Validation Loss= 0.1633, Validation Accuracy= 0.918
2018-01-03 12:17:25,298 - root - INFO - Step 2, Validation Loss= 0.1633, Validation Accuracy= 0.918
2018-01-03 12:17:27,111 : INFO : Step 3, Minibatch Loss= 0.0702, Training Accuracy= 0.974
2018-01-03 12:17:27,111 - root - INFO - Step 3, Minibatch Loss= 0.0702, Training Accuracy= 0.974
2018-01-03 12:17:27,111 - root - INFO - Step 3, Minibatch Loss= 0.0702, Training Accuracy= 0.974
2018-01-03 12:17:27,165 : INFO : Step 3, Validation Loss= 0.3477, Validation Accuracy= 0.856
2018-01-03 12:17:27,165 - root - INFO - Step 3, Validation Loss= 0.3477, Validation Accuracy= 0.856
2018-01-03 12:17:27,165 - root - INFO - Step 3, Validation Loss= 0.3477, Validation Accuracy= 0.856
2018-01-03 12:17:27,165 : INFO : starting fold 3 in 10-fold CV
2018-01-03 12:17:27,165 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:17:27,165 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:17:33,789 : INFO : Step 1, Minibatch Loss= 0.2314, Training Accuracy= 0.917
2018-01-03 12:17:33,789 - root - INFO - Step 1, Minibatch Loss= 0.2314, Training Accuracy= 0.917
2018-01-03 12:17:33,789 - root - INFO - Step 1, Minibatch Loss= 0.2314, Training Accuracy= 0.917
2018-01-03 12:17:33,843 : INFO : Step 1, Validation Loss= 0.2099, Validation Accuracy= 0.925
2018-01-03 12:17:33,843 - root - INFO - Step 1, Validation Loss= 0.2099, Validation Accuracy= 0.925
2018-01-03 12:17:33,843 - root - INFO - Step 1, Validation Loss= 0.2099, Validation Accuracy= 0.925
2018-01-03 12:17:35,764 : INFO : Step 2, Minibatch Loss= 0.0978, Training Accuracy= 0.966
2018-01-03 12:17:35,764 - root - INFO - Step 2, Minibatch Loss= 0.0978, Training Accuracy= 0.966
2018-01-03 12:17:35,764 - root - INFO - Step 2, Minibatch Loss= 0.0978, Training Accuracy= 0.966
2018-01-03 12:17:35,820 : INFO : Step 2, Validation Loss= 0.2231, Validation Accuracy= 0.912
2018-01-03 12:17:35,820 - root - INFO - Step 2, Validation Loss= 0.2231, Validation Accuracy= 0.912
2018-01-03 12:17:35,820 - root - INFO - Step 2, Validation Loss= 0.2231, Validation Accuracy= 0.912
2018-01-03 12:17:35,820 : INFO : starting fold 4 in 10-fold CV
2018-01-03 12:17:35,820 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:17:35,820 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:17:43,269 : INFO : Step 1, Minibatch Loss= 0.2524, Training Accuracy= 0.919
2018-01-03 12:17:43,269 - root - INFO - Step 1, Minibatch Loss= 0.2524, Training Accuracy= 0.919
2018-01-03 12:17:43,269 - root - INFO - Step 1, Minibatch Loss= 0.2524, Training Accuracy= 0.919
2018-01-03 12:17:43,324 : INFO : Step 1, Validation Loss= 0.2580, Validation Accuracy= 0.929
2018-01-03 12:17:43,324 - root - INFO - Step 1, Validation Loss= 0.2580, Validation Accuracy= 0.929
2018-01-03 12:17:43,324 - root - INFO - Step 1, Validation Loss= 0.2580, Validation Accuracy= 0.929
2018-01-03 12:17:45,190 : INFO : Step 2, Minibatch Loss= 0.1001, Training Accuracy= 0.964
2018-01-03 12:17:45,190 - root - INFO - Step 2, Minibatch Loss= 0.1001, Training Accuracy= 0.964
2018-01-03 12:17:45,190 - root - INFO - Step 2, Minibatch Loss= 0.1001, Training Accuracy= 0.964
2018-01-03 12:17:45,240 : INFO : Step 2, Validation Loss= 0.1398, Validation Accuracy= 0.948
2018-01-03 12:17:45,240 - root - INFO - Step 2, Validation Loss= 0.1398, Validation Accuracy= 0.948
2018-01-03 12:17:45,240 - root - INFO - Step 2, Validation Loss= 0.1398, Validation Accuracy= 0.948
2018-01-03 12:17:47,098 : INFO : Step 3, Minibatch Loss= 0.0559, Training Accuracy= 0.984
2018-01-03 12:17:47,098 - root - INFO - Step 3, Minibatch Loss= 0.0559, Training Accuracy= 0.984
2018-01-03 12:17:47,098 - root - INFO - Step 3, Minibatch Loss= 0.0559, Training Accuracy= 0.984
2018-01-03 12:17:47,148 : INFO : Step 3, Validation Loss= 0.1578, Validation Accuracy= 0.944
2018-01-03 12:17:47,148 - root - INFO - Step 3, Validation Loss= 0.1578, Validation Accuracy= 0.944
2018-01-03 12:17:47,148 - root - INFO - Step 3, Validation Loss= 0.1578, Validation Accuracy= 0.944
2018-01-03 12:17:47,148 : INFO : starting fold 5 in 10-fold CV
2018-01-03 12:17:47,148 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 12:17:47,148 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 12:17:53,992 : INFO : Step 1, Minibatch Loss= 0.5537, Training Accuracy= 0.715
2018-01-03 12:17:53,992 - root - INFO - Step 1, Minibatch Loss= 0.5537, Training Accuracy= 0.715
2018-01-03 12:17:53,992 - root - INFO - Step 1, Minibatch Loss= 0.5537, Training Accuracy= 0.715
2018-01-03 12:17:54,053 : INFO : Step 1, Validation Loss= 0.5590, Validation Accuracy= 0.718
2018-01-03 12:17:54,053 - root - INFO - Step 1, Validation Loss= 0.5590, Validation Accuracy= 0.718
2018-01-03 12:17:54,053 - root - INFO - Step 1, Validation Loss= 0.5590, Validation Accuracy= 0.718
2018-01-03 12:17:55,958 : INFO : Step 2, Minibatch Loss= 0.1576, Training Accuracy= 0.938
2018-01-03 12:17:55,958 - root - INFO - Step 2, Minibatch Loss= 0.1576, Training Accuracy= 0.938
2018-01-03 12:17:55,958 - root - INFO - Step 2, Minibatch Loss= 0.1576, Training Accuracy= 0.938
2018-01-03 12:17:56,012 : INFO : Step 2, Validation Loss= 0.2695, Validation Accuracy= 0.873
2018-01-03 12:17:56,012 - root - INFO - Step 2, Validation Loss= 0.2695, Validation Accuracy= 0.873
2018-01-03 12:17:56,012 - root - INFO - Step 2, Validation Loss= 0.2695, Validation Accuracy= 0.873
2018-01-03 12:17:57,838 : INFO : Step 3, Minibatch Loss= 0.0949, Training Accuracy= 0.969
2018-01-03 12:17:57,838 - root - INFO - Step 3, Minibatch Loss= 0.0949, Training Accuracy= 0.969
2018-01-03 12:17:57,838 - root - INFO - Step 3, Minibatch Loss= 0.0949, Training Accuracy= 0.969
2018-01-03 12:17:57,891 : INFO : Step 3, Validation Loss= 0.3933, Validation Accuracy= 0.875
2018-01-03 12:17:57,891 - root - INFO - Step 3, Validation Loss= 0.3933, Validation Accuracy= 0.875
2018-01-03 12:17:57,891 - root - INFO - Step 3, Validation Loss= 0.3933, Validation Accuracy= 0.875
2018-01-03 12:17:59,735 : INFO : Step 4, Minibatch Loss= 0.0527, Training Accuracy= 0.982
2018-01-03 12:17:59,735 - root - INFO - Step 4, Minibatch Loss= 0.0527, Training Accuracy= 0.982
2018-01-03 12:17:59,735 - root - INFO - Step 4, Minibatch Loss= 0.0527, Training Accuracy= 0.982
2018-01-03 12:17:59,787 : INFO : Step 4, Validation Loss= 0.4607, Validation Accuracy= 0.901
2018-01-03 12:17:59,787 - root - INFO - Step 4, Validation Loss= 0.4607, Validation Accuracy= 0.901
2018-01-03 12:17:59,787 - root - INFO - Step 4, Validation Loss= 0.4607, Validation Accuracy= 0.901
2018-01-03 12:18:01,610 : INFO : Step 5, Minibatch Loss= 0.0379, Training Accuracy= 0.988
2018-01-03 12:18:01,610 - root - INFO - Step 5, Minibatch Loss= 0.0379, Training Accuracy= 0.988
2018-01-03 12:18:01,610 - root - INFO - Step 5, Minibatch Loss= 0.0379, Training Accuracy= 0.988
2018-01-03 12:18:01,663 : INFO : Step 5, Validation Loss= 0.4029, Validation Accuracy= 0.895
2018-01-03 12:18:01,663 - root - INFO - Step 5, Validation Loss= 0.4029, Validation Accuracy= 0.895
2018-01-03 12:18:01,663 - root - INFO - Step 5, Validation Loss= 0.4029, Validation Accuracy= 0.895
2018-01-03 12:18:01,663 : INFO : starting fold 6 in 10-fold CV
2018-01-03 12:18:01,663 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 12:18:01,663 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 12:18:09,154 : INFO : Step 1, Minibatch Loss= 0.3286, Training Accuracy= 0.890
2018-01-03 12:18:09,154 - root - INFO - Step 1, Minibatch Loss= 0.3286, Training Accuracy= 0.890
2018-01-03 12:18:09,154 - root - INFO - Step 1, Minibatch Loss= 0.3286, Training Accuracy= 0.890
2018-01-03 12:18:09,215 : INFO : Step 1, Validation Loss= 0.3583, Validation Accuracy= 0.869
2018-01-03 12:18:09,215 - root - INFO - Step 1, Validation Loss= 0.3583, Validation Accuracy= 0.869
2018-01-03 12:18:09,215 - root - INFO - Step 1, Validation Loss= 0.3583, Validation Accuracy= 0.869
2018-01-03 12:18:11,042 : INFO : Step 2, Minibatch Loss= 0.1021, Training Accuracy= 0.967
2018-01-03 12:18:11,042 - root - INFO - Step 2, Minibatch Loss= 0.1021, Training Accuracy= 0.967
2018-01-03 12:18:11,042 - root - INFO - Step 2, Minibatch Loss= 0.1021, Training Accuracy= 0.967
2018-01-03 12:18:11,087 : INFO : Step 2, Validation Loss= 0.2457, Validation Accuracy= 0.910
2018-01-03 12:18:11,087 - root - INFO - Step 2, Validation Loss= 0.2457, Validation Accuracy= 0.910
2018-01-03 12:18:11,087 - root - INFO - Step 2, Validation Loss= 0.2457, Validation Accuracy= 0.910
2018-01-03 12:18:12,927 : INFO : Step 3, Minibatch Loss= 0.0581, Training Accuracy= 0.983
2018-01-03 12:18:12,927 - root - INFO - Step 3, Minibatch Loss= 0.0581, Training Accuracy= 0.983
2018-01-03 12:18:12,927 - root - INFO - Step 3, Minibatch Loss= 0.0581, Training Accuracy= 0.983
2018-01-03 12:18:12,978 : INFO : Step 3, Validation Loss= 0.2210, Validation Accuracy= 0.912
2018-01-03 12:18:12,978 - root - INFO - Step 3, Validation Loss= 0.2210, Validation Accuracy= 0.912
2018-01-03 12:18:12,978 - root - INFO - Step 3, Validation Loss= 0.2210, Validation Accuracy= 0.912
2018-01-03 12:18:14,670 : INFO : Step 4, Minibatch Loss= 0.0299, Training Accuracy= 0.989
2018-01-03 12:18:14,670 - root - INFO - Step 4, Minibatch Loss= 0.0299, Training Accuracy= 0.989
2018-01-03 12:18:14,670 - root - INFO - Step 4, Minibatch Loss= 0.0299, Training Accuracy= 0.989
2018-01-03 12:18:14,720 : INFO : Step 4, Validation Loss= 0.2488, Validation Accuracy= 0.929
2018-01-03 12:18:14,720 - root - INFO - Step 4, Validation Loss= 0.2488, Validation Accuracy= 0.929
2018-01-03 12:18:14,720 - root - INFO - Step 4, Validation Loss= 0.2488, Validation Accuracy= 0.929
2018-01-03 12:18:16,555 : INFO : Step 5, Minibatch Loss= 0.0238, Training Accuracy= 0.995
2018-01-03 12:18:16,555 - root - INFO - Step 5, Minibatch Loss= 0.0238, Training Accuracy= 0.995
2018-01-03 12:18:16,555 - root - INFO - Step 5, Minibatch Loss= 0.0238, Training Accuracy= 0.995
2018-01-03 12:18:16,605 : INFO : Step 5, Validation Loss= 0.3371, Validation Accuracy= 0.912
2018-01-03 12:18:16,605 - root - INFO - Step 5, Validation Loss= 0.3371, Validation Accuracy= 0.912
2018-01-03 12:18:16,605 - root - INFO - Step 5, Validation Loss= 0.3371, Validation Accuracy= 0.912
2018-01-03 12:18:16,605 : INFO : starting fold 7 in 10-fold CV
2018-01-03 12:18:16,605 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 12:18:16,605 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 12:18:23,617 : INFO : Step 1, Minibatch Loss= 0.4152, Training Accuracy= 0.859
2018-01-03 12:18:23,617 - root - INFO - Step 1, Minibatch Loss= 0.4152, Training Accuracy= 0.859
2018-01-03 12:18:23,617 - root - INFO - Step 1, Minibatch Loss= 0.4152, Training Accuracy= 0.859
2018-01-03 12:18:23,678 : INFO : Step 1, Validation Loss= 0.4790, Validation Accuracy= 0.809
2018-01-03 12:18:23,678 - root - INFO - Step 1, Validation Loss= 0.4790, Validation Accuracy= 0.809
2018-01-03 12:18:23,678 - root - INFO - Step 1, Validation Loss= 0.4790, Validation Accuracy= 0.809
2018-01-03 12:18:25,532 : INFO : Step 2, Minibatch Loss= 0.1297, Training Accuracy= 0.950
2018-01-03 12:18:25,532 - root - INFO - Step 2, Minibatch Loss= 0.1297, Training Accuracy= 0.950
2018-01-03 12:18:25,532 - root - INFO - Step 2, Minibatch Loss= 0.1297, Training Accuracy= 0.950
2018-01-03 12:18:25,587 : INFO : Step 2, Validation Loss= 0.2677, Validation Accuracy= 0.914
2018-01-03 12:18:25,587 - root - INFO - Step 2, Validation Loss= 0.2677, Validation Accuracy= 0.914
2018-01-03 12:18:25,587 - root - INFO - Step 2, Validation Loss= 0.2677, Validation Accuracy= 0.914
2018-01-03 12:18:27,501 : INFO : Step 3, Minibatch Loss= 0.0843, Training Accuracy= 0.976
2018-01-03 12:18:27,501 - root - INFO - Step 3, Minibatch Loss= 0.0843, Training Accuracy= 0.976
2018-01-03 12:18:27,501 - root - INFO - Step 3, Minibatch Loss= 0.0843, Training Accuracy= 0.976
2018-01-03 12:18:27,560 : INFO : Step 3, Validation Loss= 0.3061, Validation Accuracy= 0.905
2018-01-03 12:18:27,560 - root - INFO - Step 3, Validation Loss= 0.3061, Validation Accuracy= 0.905
2018-01-03 12:18:27,560 - root - INFO - Step 3, Validation Loss= 0.3061, Validation Accuracy= 0.905
2018-01-03 12:18:27,560 : INFO : starting fold 8 in 10-fold CV
2018-01-03 12:18:27,560 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 12:18:27,560 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 12:18:35,268 : INFO : Step 1, Minibatch Loss= 0.4338, Training Accuracy= 0.808
2018-01-03 12:18:35,268 - root - INFO - Step 1, Minibatch Loss= 0.4338, Training Accuracy= 0.808
2018-01-03 12:18:35,268 - root - INFO - Step 1, Minibatch Loss= 0.4338, Training Accuracy= 0.808
2018-01-03 12:18:35,338 : INFO : Step 1, Validation Loss= 0.4847, Validation Accuracy= 0.757
2018-01-03 12:18:35,338 - root - INFO - Step 1, Validation Loss= 0.4847, Validation Accuracy= 0.757
2018-01-03 12:18:35,338 - root - INFO - Step 1, Validation Loss= 0.4847, Validation Accuracy= 0.757
2018-01-03 12:18:37,283 : INFO : Step 2, Minibatch Loss= 0.1400, Training Accuracy= 0.953
2018-01-03 12:18:37,283 - root - INFO - Step 2, Minibatch Loss= 0.1400, Training Accuracy= 0.953
2018-01-03 12:18:37,283 - root - INFO - Step 2, Minibatch Loss= 0.1400, Training Accuracy= 0.953
2018-01-03 12:18:37,338 : INFO : Step 2, Validation Loss= 0.2110, Validation Accuracy= 0.920
2018-01-03 12:18:37,338 - root - INFO - Step 2, Validation Loss= 0.2110, Validation Accuracy= 0.920
2018-01-03 12:18:37,338 - root - INFO - Step 2, Validation Loss= 0.2110, Validation Accuracy= 0.920
2018-01-03 12:18:39,145 : INFO : Step 3, Minibatch Loss= 0.0798, Training Accuracy= 0.975
2018-01-03 12:18:39,145 - root - INFO - Step 3, Minibatch Loss= 0.0798, Training Accuracy= 0.975
2018-01-03 12:18:39,145 - root - INFO - Step 3, Minibatch Loss= 0.0798, Training Accuracy= 0.975
2018-01-03 12:18:39,196 : INFO : Step 3, Validation Loss= 0.2245, Validation Accuracy= 0.903
2018-01-03 12:18:39,196 - root - INFO - Step 3, Validation Loss= 0.2245, Validation Accuracy= 0.903
2018-01-03 12:18:39,196 - root - INFO - Step 3, Validation Loss= 0.2245, Validation Accuracy= 0.903
2018-01-03 12:18:39,196 : INFO : starting fold 9 in 10-fold CV
2018-01-03 12:18:39,196 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 12:18:39,196 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 12:18:46,098 : INFO : Step 1, Minibatch Loss= 0.2514, Training Accuracy= 0.921
2018-01-03 12:18:46,098 - root - INFO - Step 1, Minibatch Loss= 0.2514, Training Accuracy= 0.921
2018-01-03 12:18:46,098 - root - INFO - Step 1, Minibatch Loss= 0.2514, Training Accuracy= 0.921
2018-01-03 12:18:46,148 : INFO : Step 1, Validation Loss= 0.2828, Validation Accuracy= 0.931
2018-01-03 12:18:46,148 - root - INFO - Step 1, Validation Loss= 0.2828, Validation Accuracy= 0.931
2018-01-03 12:18:46,148 - root - INFO - Step 1, Validation Loss= 0.2828, Validation Accuracy= 0.931
2018-01-03 12:18:48,079 : INFO : Step 2, Minibatch Loss= 0.1051, Training Accuracy= 0.968
2018-01-03 12:18:48,079 - root - INFO - Step 2, Minibatch Loss= 0.1051, Training Accuracy= 0.968
2018-01-03 12:18:48,079 - root - INFO - Step 2, Minibatch Loss= 0.1051, Training Accuracy= 0.968
2018-01-03 12:18:48,138 : INFO : Step 2, Validation Loss= 0.1885, Validation Accuracy= 0.923
2018-01-03 12:18:48,138 - root - INFO - Step 2, Validation Loss= 0.1885, Validation Accuracy= 0.923
2018-01-03 12:18:48,138 - root - INFO - Step 2, Validation Loss= 0.1885, Validation Accuracy= 0.923
2018-01-03 12:18:48,138 : INFO : starting fold 10 in 10-fold CV
2018-01-03 12:18:48,138 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 12:18:48,138 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 12:18:56,044 : INFO : Step 1, Minibatch Loss= 0.3853, Training Accuracy= 0.856
2018-01-03 12:18:56,044 - root - INFO - Step 1, Minibatch Loss= 0.3853, Training Accuracy= 0.856
2018-01-03 12:18:56,044 - root - INFO - Step 1, Minibatch Loss= 0.3853, Training Accuracy= 0.856
2018-01-03 12:18:56,099 : INFO : Step 1, Validation Loss= 0.4439, Validation Accuracy= 0.813
2018-01-03 12:18:56,099 - root - INFO - Step 1, Validation Loss= 0.4439, Validation Accuracy= 0.813
2018-01-03 12:18:56,099 - root - INFO - Step 1, Validation Loss= 0.4439, Validation Accuracy= 0.813
2018-01-03 12:18:57,993 : INFO : Step 2, Minibatch Loss= 0.1060, Training Accuracy= 0.968
2018-01-03 12:18:57,993 - root - INFO - Step 2, Minibatch Loss= 0.1060, Training Accuracy= 0.968
2018-01-03 12:18:57,993 - root - INFO - Step 2, Minibatch Loss= 0.1060, Training Accuracy= 0.968
2018-01-03 12:18:58,044 : INFO : Step 2, Validation Loss= 0.3080, Validation Accuracy= 0.865
2018-01-03 12:18:58,044 - root - INFO - Step 2, Validation Loss= 0.3080, Validation Accuracy= 0.865
2018-01-03 12:18:58,044 - root - INFO - Step 2, Validation Loss= 0.3080, Validation Accuracy= 0.865
2018-01-03 12:18:59,785 : INFO : Step 3, Minibatch Loss= 0.0688, Training Accuracy= 0.981
2018-01-03 12:18:59,785 - root - INFO - Step 3, Minibatch Loss= 0.0688, Training Accuracy= 0.981
2018-01-03 12:18:59,785 - root - INFO - Step 3, Minibatch Loss= 0.0688, Training Accuracy= 0.981
2018-01-03 12:18:59,832 : INFO : Step 3, Validation Loss= 0.3173, Validation Accuracy= 0.873
2018-01-03 12:18:59,832 - root - INFO - Step 3, Validation Loss= 0.3173, Validation Accuracy= 0.873
2018-01-03 12:18:59,832 - root - INFO - Step 3, Validation Loss= 0.3173, Validation Accuracy= 0.873
2018-01-03 12:19:01,721 : INFO : Step 4, Minibatch Loss= 0.0362, Training Accuracy= 0.993
2018-01-03 12:19:01,721 - root - INFO - Step 4, Minibatch Loss= 0.0362, Training Accuracy= 0.993
2018-01-03 12:19:01,721 - root - INFO - Step 4, Minibatch Loss= 0.0362, Training Accuracy= 0.993
2018-01-03 12:19:01,775 : INFO : Step 4, Validation Loss= 0.4332, Validation Accuracy= 0.839
2018-01-03 12:19:01,775 - root - INFO - Step 4, Validation Loss= 0.4332, Validation Accuracy= 0.839
2018-01-03 12:19:01,775 - root - INFO - Step 4, Validation Loss= 0.4332, Validation Accuracy= 0.839
2018-01-03 12:22:10,839 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:22:10,839 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:22:10,839 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:22:10,840 : INFO : collecting all words and their counts
2018-01-03 12:22:10,840 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:22:10,840 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:22:10,840 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:22:10,840 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:22:10,840 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:22:10,866 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:22:10,866 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:22:10,866 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:22:10,866 : INFO : Loading a fresh vocabulary
2018-01-03 12:22:10,866 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:22:10,866 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:22:10,880 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:22:10,880 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:22:10,880 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:22:10,880 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:22:10,880 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:22:10,880 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:22:10,902 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:22:10,902 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:22:10,902 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:22:10,903 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:22:10,903 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:22:10,903 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:22:10,903 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:22:10,921 : INFO : resetting layer weights
2018-01-03 12:22:10,921 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:22:10,921 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:22:11,016 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,016 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,016 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,447 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,447 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,447 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,453 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,453 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,453 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,454 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,454 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,454 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,455 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1287305 effective words/s
2018-01-03 12:22:11,455 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1287305 effective words/s
2018-01-03 12:22:11,455 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1287305 effective words/s
2018-01-03 12:22:11,455 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,455 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,455 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:22:11,925 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,925 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,925 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:22:11,928 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,928 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,928 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:22:11,934 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,934 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,934 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:22:11,934 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1176946 effective words/s
2018-01-03 12:22:11,934 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1176946 effective words/s
2018-01-03 12:22:11,934 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1176946 effective words/s
2018-01-03 12:22:31,090 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:22:31,090 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:22:31,090 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:22:31,091 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:22:31,091 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:22:31,091 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:22:39,622 : INFO : Step 1, Minibatch Loss= 0.2029, Training Accuracy= 0.929
2018-01-03 12:22:39,622 - root - INFO - Step 1, Minibatch Loss= 0.2029, Training Accuracy= 0.929
2018-01-03 12:22:39,622 - root - INFO - Step 1, Minibatch Loss= 0.2029, Training Accuracy= 0.929
2018-01-03 12:22:39,687 : INFO : Step 1, Validation Loss= 0.3265, Validation Accuracy= 0.860
2018-01-03 12:22:39,687 - root - INFO - Step 1, Validation Loss= 0.3265, Validation Accuracy= 0.860
2018-01-03 12:22:39,687 - root - INFO - Step 1, Validation Loss= 0.3265, Validation Accuracy= 0.860
2018-01-03 12:22:41,507 : INFO : Step 2, Minibatch Loss= 0.0904, Training Accuracy= 0.973
2018-01-03 12:22:41,507 - root - INFO - Step 2, Minibatch Loss= 0.0904, Training Accuracy= 0.973
2018-01-03 12:22:41,507 - root - INFO - Step 2, Minibatch Loss= 0.0904, Training Accuracy= 0.973
2018-01-03 12:22:41,563 : INFO : Step 2, Validation Loss= 0.1535, Validation Accuracy= 0.933
2018-01-03 12:22:41,563 - root - INFO - Step 2, Validation Loss= 0.1535, Validation Accuracy= 0.933
2018-01-03 12:22:41,563 - root - INFO - Step 2, Validation Loss= 0.1535, Validation Accuracy= 0.933
2018-01-03 12:22:43,399 : INFO : Step 3, Minibatch Loss= 0.0617, Training Accuracy= 0.984
2018-01-03 12:22:43,399 - root - INFO - Step 3, Minibatch Loss= 0.0617, Training Accuracy= 0.984
2018-01-03 12:22:43,399 - root - INFO - Step 3, Minibatch Loss= 0.0617, Training Accuracy= 0.984
2018-01-03 12:22:43,453 : INFO : Step 3, Validation Loss= 0.3258, Validation Accuracy= 0.888
2018-01-03 12:22:43,453 - root - INFO - Step 3, Validation Loss= 0.3258, Validation Accuracy= 0.888
2018-01-03 12:22:43,453 - root - INFO - Step 3, Validation Loss= 0.3258, Validation Accuracy= 0.888
2018-01-03 12:22:43,453 : INFO : starting fold 2 in 10-fold CV
2018-01-03 12:22:43,453 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:22:43,453 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 12:22:50,049 : INFO : Step 1, Minibatch Loss= 0.3742, Training Accuracy= 0.878
2018-01-03 12:22:50,049 - root - INFO - Step 1, Minibatch Loss= 0.3742, Training Accuracy= 0.878
2018-01-03 12:22:50,049 - root - INFO - Step 1, Minibatch Loss= 0.3742, Training Accuracy= 0.878
2018-01-03 12:22:50,104 : INFO : Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.817
2018-01-03 12:22:50,104 - root - INFO - Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.817
2018-01-03 12:22:50,104 - root - INFO - Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.817
2018-01-03 12:22:52,010 : INFO : Step 2, Minibatch Loss= 0.1248, Training Accuracy= 0.961
2018-01-03 12:22:52,010 - root - INFO - Step 2, Minibatch Loss= 0.1248, Training Accuracy= 0.961
2018-01-03 12:22:52,010 - root - INFO - Step 2, Minibatch Loss= 0.1248, Training Accuracy= 0.961
2018-01-03 12:22:52,064 : INFO : Step 2, Validation Loss= 0.2576, Validation Accuracy= 0.929
2018-01-03 12:22:52,064 - root - INFO - Step 2, Validation Loss= 0.2576, Validation Accuracy= 0.929
2018-01-03 12:22:52,064 - root - INFO - Step 2, Validation Loss= 0.2576, Validation Accuracy= 0.929
2018-01-03 12:22:54,002 : INFO : Step 3, Minibatch Loss= 0.0842, Training Accuracy= 0.977
2018-01-03 12:22:54,002 - root - INFO - Step 3, Minibatch Loss= 0.0842, Training Accuracy= 0.977
2018-01-03 12:22:54,002 - root - INFO - Step 3, Minibatch Loss= 0.0842, Training Accuracy= 0.977
2018-01-03 12:22:54,055 : INFO : Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.938
2018-01-03 12:22:54,055 - root - INFO - Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.938
2018-01-03 12:22:54,055 - root - INFO - Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.938
2018-01-03 12:22:55,962 : INFO : Step 4, Minibatch Loss= 0.0579, Training Accuracy= 0.985
2018-01-03 12:22:55,962 - root - INFO - Step 4, Minibatch Loss= 0.0579, Training Accuracy= 0.985
2018-01-03 12:22:55,962 - root - INFO - Step 4, Minibatch Loss= 0.0579, Training Accuracy= 0.985
2018-01-03 12:22:56,015 : INFO : Step 4, Validation Loss= 0.2588, Validation Accuracy= 0.923
2018-01-03 12:22:56,015 - root - INFO - Step 4, Validation Loss= 0.2588, Validation Accuracy= 0.923
2018-01-03 12:22:56,015 - root - INFO - Step 4, Validation Loss= 0.2588, Validation Accuracy= 0.923
2018-01-03 12:22:56,016 : INFO : starting fold 3 in 10-fold CV
2018-01-03 12:22:56,016 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:22:56,016 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 12:23:02,939 : INFO : Step 1, Minibatch Loss= 0.3403, Training Accuracy= 0.907
2018-01-03 12:23:02,939 - root - INFO - Step 1, Minibatch Loss= 0.3403, Training Accuracy= 0.907
2018-01-03 12:23:02,939 - root - INFO - Step 1, Minibatch Loss= 0.3403, Training Accuracy= 0.907
2018-01-03 12:23:02,995 : INFO : Step 1, Validation Loss= 0.3733, Validation Accuracy= 0.899
2018-01-03 12:23:02,995 - root - INFO - Step 1, Validation Loss= 0.3733, Validation Accuracy= 0.899
2018-01-03 12:23:02,995 - root - INFO - Step 1, Validation Loss= 0.3733, Validation Accuracy= 0.899
2018-01-03 12:23:04,926 : INFO : Step 2, Minibatch Loss= 0.1176, Training Accuracy= 0.966
2018-01-03 12:23:04,926 - root - INFO - Step 2, Minibatch Loss= 0.1176, Training Accuracy= 0.966
2018-01-03 12:23:04,926 - root - INFO - Step 2, Minibatch Loss= 0.1176, Training Accuracy= 0.966
2018-01-03 12:23:04,980 : INFO : Step 2, Validation Loss= 0.1967, Validation Accuracy= 0.920
2018-01-03 12:23:04,980 - root - INFO - Step 2, Validation Loss= 0.1967, Validation Accuracy= 0.920
2018-01-03 12:23:04,980 - root - INFO - Step 2, Validation Loss= 0.1967, Validation Accuracy= 0.920
2018-01-03 12:23:06,911 : INFO : Step 3, Minibatch Loss= 0.0674, Training Accuracy= 0.985
2018-01-03 12:23:06,911 - root - INFO - Step 3, Minibatch Loss= 0.0674, Training Accuracy= 0.985
2018-01-03 12:23:06,911 - root - INFO - Step 3, Minibatch Loss= 0.0674, Training Accuracy= 0.985
2018-01-03 12:23:06,966 : INFO : Step 3, Validation Loss= 0.1900, Validation Accuracy= 0.935
2018-01-03 12:23:06,966 - root - INFO - Step 3, Validation Loss= 0.1900, Validation Accuracy= 0.935
2018-01-03 12:23:06,966 - root - INFO - Step 3, Validation Loss= 0.1900, Validation Accuracy= 0.935
2018-01-03 12:23:08,976 : INFO : Step 4, Minibatch Loss= 0.0437, Training Accuracy= 0.988
2018-01-03 12:23:08,976 - root - INFO - Step 4, Minibatch Loss= 0.0437, Training Accuracy= 0.988
2018-01-03 12:23:08,976 - root - INFO - Step 4, Minibatch Loss= 0.0437, Training Accuracy= 0.988
2018-01-03 12:23:09,038 : INFO : Step 4, Validation Loss= 0.2469, Validation Accuracy= 0.918
2018-01-03 12:23:09,038 - root - INFO - Step 4, Validation Loss= 0.2469, Validation Accuracy= 0.918
2018-01-03 12:23:09,038 - root - INFO - Step 4, Validation Loss= 0.2469, Validation Accuracy= 0.918
2018-01-03 12:23:09,038 : INFO : starting fold 4 in 10-fold CV
2018-01-03 12:23:09,038 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:23:09,038 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 12:23:16,170 : INFO : Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.893
2018-01-03 12:23:16,170 - root - INFO - Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.893
2018-01-03 12:23:16,170 - root - INFO - Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.893
2018-01-03 12:23:16,224 : INFO : Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.912
2018-01-03 12:23:16,224 - root - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.912
2018-01-03 12:23:16,224 - root - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.912
2018-01-03 12:23:18,152 : INFO : Step 2, Minibatch Loss= 0.1166, Training Accuracy= 0.959
2018-01-03 12:23:18,152 - root - INFO - Step 2, Minibatch Loss= 0.1166, Training Accuracy= 0.959
2018-01-03 12:23:18,152 - root - INFO - Step 2, Minibatch Loss= 0.1166, Training Accuracy= 0.959
2018-01-03 12:23:18,202 : INFO : Step 2, Validation Loss= 0.1912, Validation Accuracy= 0.938
2018-01-03 12:23:18,202 - root - INFO - Step 2, Validation Loss= 0.1912, Validation Accuracy= 0.938
2018-01-03 12:23:18,202 - root - INFO - Step 2, Validation Loss= 0.1912, Validation Accuracy= 0.938
2018-01-03 12:23:20,051 : INFO : Step 3, Minibatch Loss= 0.0758, Training Accuracy= 0.977
2018-01-03 12:23:20,051 - root - INFO - Step 3, Minibatch Loss= 0.0758, Training Accuracy= 0.977
2018-01-03 12:23:20,051 - root - INFO - Step 3, Minibatch Loss= 0.0758, Training Accuracy= 0.977
2018-01-03 12:23:20,102 : INFO : Step 3, Validation Loss= 0.1437, Validation Accuracy= 0.948
2018-01-03 12:23:20,102 - root - INFO - Step 3, Validation Loss= 0.1437, Validation Accuracy= 0.948
2018-01-03 12:23:20,102 - root - INFO - Step 3, Validation Loss= 0.1437, Validation Accuracy= 0.948
2018-01-03 12:23:21,932 : INFO : Step 4, Minibatch Loss= 0.0452, Training Accuracy= 0.987
2018-01-03 12:23:21,932 - root - INFO - Step 4, Minibatch Loss= 0.0452, Training Accuracy= 0.987
2018-01-03 12:23:21,932 - root - INFO - Step 4, Minibatch Loss= 0.0452, Training Accuracy= 0.987
2018-01-03 12:23:21,981 : INFO : Step 4, Validation Loss= 0.1601, Validation Accuracy= 0.938
2018-01-03 12:23:21,981 - root - INFO - Step 4, Validation Loss= 0.1601, Validation Accuracy= 0.938
2018-01-03 12:23:21,981 - root - INFO - Step 4, Validation Loss= 0.1601, Validation Accuracy= 0.938
2018-01-03 12:23:21,982 : INFO : starting fold 5 in 10-fold CV
2018-01-03 12:23:21,982 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 12:23:21,982 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 12:23:28,885 : INFO : Step 1, Minibatch Loss= 0.3761, Training Accuracy= 0.875
2018-01-03 12:23:28,885 - root - INFO - Step 1, Minibatch Loss= 0.3761, Training Accuracy= 0.875
2018-01-03 12:23:28,885 - root - INFO - Step 1, Minibatch Loss= 0.3761, Training Accuracy= 0.875
2018-01-03 12:23:28,938 : INFO : Step 1, Validation Loss= 0.4184, Validation Accuracy= 0.862
2018-01-03 12:23:28,938 - root - INFO - Step 1, Validation Loss= 0.4184, Validation Accuracy= 0.862
2018-01-03 12:23:28,938 - root - INFO - Step 1, Validation Loss= 0.4184, Validation Accuracy= 0.862
2018-01-03 12:23:30,820 : INFO : Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.963
2018-01-03 12:23:30,820 - root - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.963
2018-01-03 12:23:30,820 - root - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.963
2018-01-03 12:23:30,873 : INFO : Step 2, Validation Loss= 0.2999, Validation Accuracy= 0.903
2018-01-03 12:23:30,873 - root - INFO - Step 2, Validation Loss= 0.2999, Validation Accuracy= 0.903
2018-01-03 12:23:30,873 - root - INFO - Step 2, Validation Loss= 0.2999, Validation Accuracy= 0.903
2018-01-03 12:23:32,681 : INFO : Step 3, Minibatch Loss= 0.0668, Training Accuracy= 0.981
2018-01-03 12:23:32,681 - root - INFO - Step 3, Minibatch Loss= 0.0668, Training Accuracy= 0.981
2018-01-03 12:23:32,681 - root - INFO - Step 3, Minibatch Loss= 0.0668, Training Accuracy= 0.981
2018-01-03 12:23:32,735 : INFO : Step 3, Validation Loss= 0.4244, Validation Accuracy= 0.875
2018-01-03 12:23:32,735 - root - INFO - Step 3, Validation Loss= 0.4244, Validation Accuracy= 0.875
2018-01-03 12:23:32,735 - root - INFO - Step 3, Validation Loss= 0.4244, Validation Accuracy= 0.875
2018-01-03 12:23:32,735 : INFO : starting fold 6 in 10-fold CV
2018-01-03 12:23:32,735 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 12:23:32,735 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 12:23:40,007 : INFO : Step 1, Minibatch Loss= 0.2880, Training Accuracy= 0.919
2018-01-03 12:23:40,007 - root - INFO - Step 1, Minibatch Loss= 0.2880, Training Accuracy= 0.919
2018-01-03 12:23:40,007 - root - INFO - Step 1, Minibatch Loss= 0.2880, Training Accuracy= 0.919
2018-01-03 12:23:40,068 : INFO : Step 1, Validation Loss= 0.3664, Validation Accuracy= 0.871
2018-01-03 12:23:40,068 - root - INFO - Step 1, Validation Loss= 0.3664, Validation Accuracy= 0.871
2018-01-03 12:23:40,068 - root - INFO - Step 1, Validation Loss= 0.3664, Validation Accuracy= 0.871
2018-01-03 12:23:41,978 : INFO : Step 2, Minibatch Loss= 0.1217, Training Accuracy= 0.966
2018-01-03 12:23:41,978 - root - INFO - Step 2, Minibatch Loss= 0.1217, Training Accuracy= 0.966
2018-01-03 12:23:41,978 - root - INFO - Step 2, Minibatch Loss= 0.1217, Training Accuracy= 0.966
2018-01-03 12:23:42,029 : INFO : Step 2, Validation Loss= 0.2600, Validation Accuracy= 0.918
2018-01-03 12:23:42,029 - root - INFO - Step 2, Validation Loss= 0.2600, Validation Accuracy= 0.918
2018-01-03 12:23:42,029 - root - INFO - Step 2, Validation Loss= 0.2600, Validation Accuracy= 0.918
2018-01-03 12:23:43,925 : INFO : Step 3, Minibatch Loss= 0.0720, Training Accuracy= 0.983
2018-01-03 12:23:43,925 - root - INFO - Step 3, Minibatch Loss= 0.0720, Training Accuracy= 0.983
2018-01-03 12:23:43,925 - root - INFO - Step 3, Minibatch Loss= 0.0720, Training Accuracy= 0.983
2018-01-03 12:23:43,975 : INFO : Step 3, Validation Loss= 0.2395, Validation Accuracy= 0.923
2018-01-03 12:23:43,975 - root - INFO - Step 3, Validation Loss= 0.2395, Validation Accuracy= 0.923
2018-01-03 12:23:43,975 - root - INFO - Step 3, Validation Loss= 0.2395, Validation Accuracy= 0.923
2018-01-03 12:23:45,812 : INFO : Step 4, Minibatch Loss= 0.0395, Training Accuracy= 0.991
2018-01-03 12:23:45,812 - root - INFO - Step 4, Minibatch Loss= 0.0395, Training Accuracy= 0.991
2018-01-03 12:23:45,812 - root - INFO - Step 4, Minibatch Loss= 0.0395, Training Accuracy= 0.991
2018-01-03 12:23:45,861 : INFO : Step 4, Validation Loss= 0.2027, Validation Accuracy= 0.923
2018-01-03 12:23:45,861 - root - INFO - Step 4, Validation Loss= 0.2027, Validation Accuracy= 0.923
2018-01-03 12:23:45,861 - root - INFO - Step 4, Validation Loss= 0.2027, Validation Accuracy= 0.923
2018-01-03 12:23:47,692 : INFO : Step 5, Minibatch Loss= 0.0283, Training Accuracy= 0.994
2018-01-03 12:23:47,692 - root - INFO - Step 5, Minibatch Loss= 0.0283, Training Accuracy= 0.994
2018-01-03 12:23:47,692 - root - INFO - Step 5, Minibatch Loss= 0.0283, Training Accuracy= 0.994
2018-01-03 12:23:47,741 : INFO : Step 5, Validation Loss= 0.2438, Validation Accuracy= 0.929
2018-01-03 12:23:47,741 - root - INFO - Step 5, Validation Loss= 0.2438, Validation Accuracy= 0.929
2018-01-03 12:23:47,741 - root - INFO - Step 5, Validation Loss= 0.2438, Validation Accuracy= 0.929
2018-01-03 12:23:49,563 : INFO : Step 6, Minibatch Loss= 0.0260, Training Accuracy= 0.993
2018-01-03 12:23:49,563 - root - INFO - Step 6, Minibatch Loss= 0.0260, Training Accuracy= 0.993
2018-01-03 12:23:49,563 - root - INFO - Step 6, Minibatch Loss= 0.0260, Training Accuracy= 0.993
2018-01-03 12:23:49,620 : INFO : Step 6, Validation Loss= 0.2272, Validation Accuracy= 0.938
2018-01-03 12:23:49,620 - root - INFO - Step 6, Validation Loss= 0.2272, Validation Accuracy= 0.938
2018-01-03 12:23:49,620 - root - INFO - Step 6, Validation Loss= 0.2272, Validation Accuracy= 0.938
2018-01-03 12:23:51,466 : INFO : Step 7, Minibatch Loss= 0.0182, Training Accuracy= 0.996
2018-01-03 12:23:51,466 - root - INFO - Step 7, Minibatch Loss= 0.0182, Training Accuracy= 0.996
2018-01-03 12:23:51,466 - root - INFO - Step 7, Minibatch Loss= 0.0182, Training Accuracy= 0.996
2018-01-03 12:23:51,516 : INFO : Step 7, Validation Loss= 0.4099, Validation Accuracy= 0.899
2018-01-03 12:23:51,516 - root - INFO - Step 7, Validation Loss= 0.4099, Validation Accuracy= 0.899
2018-01-03 12:23:51,516 - root - INFO - Step 7, Validation Loss= 0.4099, Validation Accuracy= 0.899
2018-01-03 12:23:51,516 : INFO : starting fold 7 in 10-fold CV
2018-01-03 12:23:51,516 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 12:23:51,516 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 12:23:58,497 : INFO : Step 1, Minibatch Loss= 0.2377, Training Accuracy= 0.924
2018-01-03 12:23:58,497 - root - INFO - Step 1, Minibatch Loss= 0.2377, Training Accuracy= 0.924
2018-01-03 12:23:58,497 - root - INFO - Step 1, Minibatch Loss= 0.2377, Training Accuracy= 0.924
2018-01-03 12:23:58,557 : INFO : Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.770
2018-01-03 12:23:58,557 - root - INFO - Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.770
2018-01-03 12:23:58,557 - root - INFO - Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.770
2018-01-03 12:24:00,419 : INFO : Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.971
2018-01-03 12:24:00,419 - root - INFO - Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.971
2018-01-03 12:24:00,419 - root - INFO - Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.971
2018-01-03 12:24:00,472 : INFO : Step 2, Validation Loss= 0.2262, Validation Accuracy= 0.910
2018-01-03 12:24:00,472 - root - INFO - Step 2, Validation Loss= 0.2262, Validation Accuracy= 0.910
2018-01-03 12:24:00,472 - root - INFO - Step 2, Validation Loss= 0.2262, Validation Accuracy= 0.910
2018-01-03 12:24:02,326 : INFO : Step 3, Minibatch Loss= 0.0741, Training Accuracy= 0.979
2018-01-03 12:24:02,326 - root - INFO - Step 3, Minibatch Loss= 0.0741, Training Accuracy= 0.979
2018-01-03 12:24:02,326 - root - INFO - Step 3, Minibatch Loss= 0.0741, Training Accuracy= 0.979
2018-01-03 12:24:02,378 : INFO : Step 3, Validation Loss= 0.2648, Validation Accuracy= 0.908
2018-01-03 12:24:02,378 - root - INFO - Step 3, Validation Loss= 0.2648, Validation Accuracy= 0.908
2018-01-03 12:24:02,378 - root - INFO - Step 3, Validation Loss= 0.2648, Validation Accuracy= 0.908
2018-01-03 12:24:02,378 : INFO : starting fold 8 in 10-fold CV
2018-01-03 12:24:02,378 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 12:24:02,378 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 12:24:09,376 : INFO : Step 1, Minibatch Loss= 0.2633, Training Accuracy= 0.920
2018-01-03 12:24:09,376 - root - INFO - Step 1, Minibatch Loss= 0.2633, Training Accuracy= 0.920
2018-01-03 12:24:09,376 - root - INFO - Step 1, Minibatch Loss= 0.2633, Training Accuracy= 0.920
2018-01-03 12:24:09,444 : INFO : Step 1, Validation Loss= 0.3676, Validation Accuracy= 0.858
2018-01-03 12:24:09,444 - root - INFO - Step 1, Validation Loss= 0.3676, Validation Accuracy= 0.858
2018-01-03 12:24:09,444 - root - INFO - Step 1, Validation Loss= 0.3676, Validation Accuracy= 0.858
2018-01-03 12:24:11,214 : INFO : Step 2, Minibatch Loss= 0.0982, Training Accuracy= 0.970
2018-01-03 12:24:11,214 - root - INFO - Step 2, Minibatch Loss= 0.0982, Training Accuracy= 0.970
2018-01-03 12:24:11,214 - root - INFO - Step 2, Minibatch Loss= 0.0982, Training Accuracy= 0.970
2018-01-03 12:24:11,270 : INFO : Step 2, Validation Loss= 0.2104, Validation Accuracy= 0.923
2018-01-03 12:24:11,270 - root - INFO - Step 2, Validation Loss= 0.2104, Validation Accuracy= 0.923
2018-01-03 12:24:11,270 - root - INFO - Step 2, Validation Loss= 0.2104, Validation Accuracy= 0.923
2018-01-03 12:24:13,088 : INFO : Step 3, Minibatch Loss= 0.0582, Training Accuracy= 0.986
2018-01-03 12:24:13,088 - root - INFO - Step 3, Minibatch Loss= 0.0582, Training Accuracy= 0.986
2018-01-03 12:24:13,088 - root - INFO - Step 3, Minibatch Loss= 0.0582, Training Accuracy= 0.986
2018-01-03 12:24:13,147 : INFO : Step 3, Validation Loss= 0.2263, Validation Accuracy= 0.910
2018-01-03 12:24:13,147 - root - INFO - Step 3, Validation Loss= 0.2263, Validation Accuracy= 0.910
2018-01-03 12:24:13,147 - root - INFO - Step 3, Validation Loss= 0.2263, Validation Accuracy= 0.910
2018-01-03 12:24:13,148 : INFO : starting fold 9 in 10-fold CV
2018-01-03 12:24:13,148 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 12:24:13,148 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 12:24:20,429 : INFO : Step 1, Minibatch Loss= 0.1971, Training Accuracy= 0.933
2018-01-03 12:24:20,429 - root - INFO - Step 1, Minibatch Loss= 0.1971, Training Accuracy= 0.933
2018-01-03 12:24:20,429 - root - INFO - Step 1, Minibatch Loss= 0.1971, Training Accuracy= 0.933
2018-01-03 12:24:20,481 : INFO : Step 1, Validation Loss= 0.2616, Validation Accuracy= 0.923
2018-01-03 12:24:20,481 - root - INFO - Step 1, Validation Loss= 0.2616, Validation Accuracy= 0.923
2018-01-03 12:24:20,481 - root - INFO - Step 1, Validation Loss= 0.2616, Validation Accuracy= 0.923
2018-01-03 12:24:22,396 : INFO : Step 2, Minibatch Loss= 0.0975, Training Accuracy= 0.971
2018-01-03 12:24:22,396 - root - INFO - Step 2, Minibatch Loss= 0.0975, Training Accuracy= 0.971
2018-01-03 12:24:22,396 - root - INFO - Step 2, Minibatch Loss= 0.0975, Training Accuracy= 0.971
2018-01-03 12:24:22,448 : INFO : Step 2, Validation Loss= 0.2195, Validation Accuracy= 0.925
2018-01-03 12:24:22,448 - root - INFO - Step 2, Validation Loss= 0.2195, Validation Accuracy= 0.925
2018-01-03 12:24:22,448 - root - INFO - Step 2, Validation Loss= 0.2195, Validation Accuracy= 0.925
2018-01-03 12:24:24,354 : INFO : Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-03 12:24:24,354 - root - INFO - Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-03 12:24:24,354 - root - INFO - Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-03 12:24:24,404 : INFO : Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.927
2018-01-03 12:24:24,404 - root - INFO - Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.927
2018-01-03 12:24:24,404 - root - INFO - Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.927
2018-01-03 12:24:26,352 : INFO : Step 4, Minibatch Loss= 0.0373, Training Accuracy= 0.989
2018-01-03 12:24:26,352 - root - INFO - Step 4, Minibatch Loss= 0.0373, Training Accuracy= 0.989
2018-01-03 12:24:26,352 - root - INFO - Step 4, Minibatch Loss= 0.0373, Training Accuracy= 0.989
2018-01-03 12:24:26,402 : INFO : Step 4, Validation Loss= 0.2238, Validation Accuracy= 0.942
2018-01-03 12:24:26,402 - root - INFO - Step 4, Validation Loss= 0.2238, Validation Accuracy= 0.942
2018-01-03 12:24:26,402 - root - INFO - Step 4, Validation Loss= 0.2238, Validation Accuracy= 0.942
2018-01-03 12:24:28,238 : INFO : Step 5, Minibatch Loss= 0.0256, Training Accuracy= 0.992
2018-01-03 12:24:28,238 - root - INFO - Step 5, Minibatch Loss= 0.0256, Training Accuracy= 0.992
2018-01-03 12:24:28,238 - root - INFO - Step 5, Minibatch Loss= 0.0256, Training Accuracy= 0.992
2018-01-03 12:24:28,286 : INFO : Step 5, Validation Loss= 0.2997, Validation Accuracy= 0.918
2018-01-03 12:24:28,286 - root - INFO - Step 5, Validation Loss= 0.2997, Validation Accuracy= 0.918
2018-01-03 12:24:28,286 - root - INFO - Step 5, Validation Loss= 0.2997, Validation Accuracy= 0.918
2018-01-03 12:24:28,287 : INFO : starting fold 10 in 10-fold CV
2018-01-03 12:24:28,287 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 12:24:28,287 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 12:24:35,127 : INFO : Step 1, Minibatch Loss= 0.4423, Training Accuracy= 0.790
2018-01-03 12:24:35,127 - root - INFO - Step 1, Minibatch Loss= 0.4423, Training Accuracy= 0.790
2018-01-03 12:24:35,127 - root - INFO - Step 1, Minibatch Loss= 0.4423, Training Accuracy= 0.790
2018-01-03 12:24:35,185 : INFO : Step 1, Validation Loss= 0.5519, Validation Accuracy= 0.712
2018-01-03 12:24:35,185 - root - INFO - Step 1, Validation Loss= 0.5519, Validation Accuracy= 0.712
2018-01-03 12:24:35,185 - root - INFO - Step 1, Validation Loss= 0.5519, Validation Accuracy= 0.712
2018-01-03 12:24:37,028 : INFO : Step 2, Minibatch Loss= 0.1417, Training Accuracy= 0.949
2018-01-03 12:24:37,028 - root - INFO - Step 2, Minibatch Loss= 0.1417, Training Accuracy= 0.949
2018-01-03 12:24:37,028 - root - INFO - Step 2, Minibatch Loss= 0.1417, Training Accuracy= 0.949
2018-01-03 12:24:37,077 : INFO : Step 2, Validation Loss= 0.2759, Validation Accuracy= 0.873
2018-01-03 12:24:37,077 - root - INFO - Step 2, Validation Loss= 0.2759, Validation Accuracy= 0.873
2018-01-03 12:24:37,077 - root - INFO - Step 2, Validation Loss= 0.2759, Validation Accuracy= 0.873
2018-01-03 12:24:38,981 : INFO : Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 12:24:38,981 - root - INFO - Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 12:24:38,981 - root - INFO - Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 12:24:39,037 : INFO : Step 3, Validation Loss= 0.2673, Validation Accuracy= 0.897
2018-01-03 12:24:39,037 - root - INFO - Step 3, Validation Loss= 0.2673, Validation Accuracy= 0.897
2018-01-03 12:24:39,037 - root - INFO - Step 3, Validation Loss= 0.2673, Validation Accuracy= 0.897
2018-01-03 12:24:40,900 : INFO : Step 4, Minibatch Loss= 0.0467, Training Accuracy= 0.988
2018-01-03 12:24:40,900 - root - INFO - Step 4, Minibatch Loss= 0.0467, Training Accuracy= 0.988
2018-01-03 12:24:40,900 - root - INFO - Step 4, Minibatch Loss= 0.0467, Training Accuracy= 0.988
2018-01-03 12:24:40,953 : INFO : Step 4, Validation Loss= 0.2623, Validation Accuracy= 0.895
2018-01-03 12:24:40,953 - root - INFO - Step 4, Validation Loss= 0.2623, Validation Accuracy= 0.895
2018-01-03 12:24:40,953 - root - INFO - Step 4, Validation Loss= 0.2623, Validation Accuracy= 0.895
2018-01-03 12:24:40,953 : INFO : Average accuracy is 0.926667 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:24:40,953 - root - INFO - Average accuracy is 0.926667 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:24:40,953 - root - INFO - Average accuracy is 0.926667 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:24:41,105 : INFO : Code run-time: 150.7257969379425 seconds
2018-01-03 12:24:41,105 - root - INFO - Code run-time: 150.7257969379425 seconds
2018-01-03 12:24:41,105 - root - INFO - Code run-time: 150.7257969379425 seconds
2018-01-03 12:53:28,140 : INFO : Code run-time: 0.00019407272338867188 seconds
2018-01-03 12:53:28,140 - root - INFO - Code run-time: 0.00019407272338867188 seconds
2018-01-03 12:53:28,140 - root - INFO - Code run-time: 0.00019407272338867188 seconds
2018-01-03 12:54:12,353 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:54:12,353 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:54:12,353 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:54:12,354 : INFO : collecting all words and their counts
2018-01-03 12:54:12,354 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:54:12,354 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:54:12,354 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:54:12,354 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:54:12,354 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:54:12,377 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:54:12,377 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:54:12,377 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:54:12,377 : INFO : Loading a fresh vocabulary
2018-01-03 12:54:12,377 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:54:12,377 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:54:12,838 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:54:12,838 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:54:12,838 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:54:12,839 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:54:12,839 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:54:12,839 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:54:12,863 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:54:12,863 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:54:12,863 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:54:12,864 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:54:12,864 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:54:12,864 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:54:12,865 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:54:12,865 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:54:12,865 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:54:12,865 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:54:12,865 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:54:12,865 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:54:12,886 : INFO : resetting layer weights
2018-01-03 12:54:12,886 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:54:12,886 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:54:12,980 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:12,980 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:12,980 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:13,595 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:13,595 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:13,595 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:13,596 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:13,596 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:13,596 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:13,598 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:13,598 : INFO : training on 797984 raw words (558589 effective words) took 0.6s, 914245 effective words/s
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - training on 797984 raw words (558589 effective words) took 0.6s, 914245 effective words/s
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - training on 797984 raw words (558589 effective words) took 0.6s, 914245 effective words/s
2018-01-03 12:54:13,598 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:13,598 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:54:14,285 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:14,285 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:14,285 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:54:14,290 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:14,290 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:14,290 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:54:14,292 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:14,292 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:14,292 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:54:14,293 : INFO : training on 797984 raw words (558381 effective words) took 0.7s, 809221 effective words/s
2018-01-03 12:54:14,293 - gensim.models.word2vec - INFO - training on 797984 raw words (558381 effective words) took 0.7s, 809221 effective words/s
2018-01-03 12:54:14,293 - gensim.models.word2vec - INFO - training on 797984 raw words (558381 effective words) took 0.7s, 809221 effective words/s
2018-01-03 12:57:35,463 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:35,463 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:35,463 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:35,464 : INFO : collecting all words and their counts
2018-01-03 12:57:35,464 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:57:35,464 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:57:35,464 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:35,464 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:35,464 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:35,489 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:35,489 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:35,489 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:35,489 : INFO : Loading a fresh vocabulary
2018-01-03 12:57:35,489 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:57:35,489 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:57:35,506 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:35,506 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:35,506 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:35,506 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:35,506 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:35,506 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:35,524 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:35,524 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:35,524 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:35,524 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:35,524 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:35,539 : INFO : resetting layer weights
2018-01-03 12:57:35,539 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:57:35,539 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:57:35,611 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:35,611 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:35,611 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:36,091 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,091 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,091 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,097 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,097 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,097 : INFO : training on 797984 raw words (558412 effective words) took 0.5s, 1159152 effective words/s
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - training on 797984 raw words (558412 effective words) took 0.5s, 1159152 effective words/s
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - training on 797984 raw words (558412 effective words) took 0.5s, 1159152 effective words/s
2018-01-03 12:57:36,097 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:36,097 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:36,557 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,557 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,557 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:36,558 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,558 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,558 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:36,562 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,562 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,562 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:36,562 : INFO : training on 797984 raw words (558319 effective words) took 0.5s, 1212979 effective words/s
2018-01-03 12:57:36,562 - gensim.models.word2vec - INFO - training on 797984 raw words (558319 effective words) took 0.5s, 1212979 effective words/s
2018-01-03 12:57:36,562 - gensim.models.word2vec - INFO - training on 797984 raw words (558319 effective words) took 0.5s, 1212979 effective words/s
2018-01-03 12:57:55,063 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:55,063 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:55,063 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:57:55,064 : INFO : collecting all words and their counts
2018-01-03 12:57:55,064 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:57:55,064 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:57:55,064 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:55,064 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:55,064 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:57:55,089 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:55,089 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:55,089 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:57:55,089 : INFO : Loading a fresh vocabulary
2018-01-03 12:57:55,089 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:57:55,089 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:57:55,104 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:55,104 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:55,104 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:57:55,104 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:55,104 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:55,104 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:57:55,122 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:55,122 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:55,122 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:57:55,123 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:57:55,123 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:57:55,123 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:55,123 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:57:55,135 : INFO : resetting layer weights
2018-01-03 12:57:55,135 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:57:55,135 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:57:55,202 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:55,202 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:55,202 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:55,679 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:55,679 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:55,679 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:55,684 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:55,684 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:55,684 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:55,685 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:55,685 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:55,685 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:55,686 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1169242 effective words/s
2018-01-03 12:57:55,686 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1169242 effective words/s
2018-01-03 12:57:55,686 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1169242 effective words/s
2018-01-03 12:57:55,686 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:55,686 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:55,686 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:57:56,147 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:56,147 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:56,147 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:57:56,153 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:56,153 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:56,153 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:57:56,154 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:56,154 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:56,154 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:57:56,154 : INFO : training on 797984 raw words (558138 effective words) took 0.5s, 1202464 effective words/s
2018-01-03 12:57:56,154 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1202464 effective words/s
2018-01-03 12:57:56,154 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1202464 effective words/s
2018-01-03 12:58:13,974 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:58:13,974 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:58:13,974 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 12:58:13,974 : INFO : starting fold 1 in 10-fold CV
2018-01-03 12:58:13,974 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:58:13,974 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 12:58:32,703 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:58:32,703 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:58:32,703 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:58:32,703 : INFO : collecting all words and their counts
2018-01-03 12:58:32,703 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:58:32,703 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:58:32,704 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:58:32,704 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:58:32,704 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:58:32,739 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:58:32,739 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:58:32,739 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:58:32,740 : INFO : Loading a fresh vocabulary
2018-01-03 12:58:32,740 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:58:32,740 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:58:32,762 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:58:32,762 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:58:32,762 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:58:32,763 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:58:32,763 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:58:32,763 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:58:32,781 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:58:32,781 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:58:32,781 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:58:32,781 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:58:32,782 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:58:32,782 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:58:32,782 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:58:32,794 : INFO : resetting layer weights
2018-01-03 12:58:32,794 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:58:32,794 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:58:32,860 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:32,860 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:32,860 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:33,297 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,297 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,297 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,301 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,301 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,301 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,304 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,304 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,304 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,305 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1270840 effective words/s
2018-01-03 12:58:33,305 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1270840 effective words/s
2018-01-03 12:58:33,305 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1270840 effective words/s
2018-01-03 12:58:33,305 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:33,305 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:33,305 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:58:33,749 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,749 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,749 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:58:33,755 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,755 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,755 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:58:33,758 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,758 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,758 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:58:33,759 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1241490 effective words/s
2018-01-03 12:58:33,759 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1241490 effective words/s
2018-01-03 12:58:33,759 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1241490 effective words/s
2018-01-03 12:59:46,408 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:59:46,408 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:59:46,408 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 12:59:46,409 : INFO : collecting all words and their counts
2018-01-03 12:59:46,409 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:59:46,409 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 12:59:46,409 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:59:46,409 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:59:46,409 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 12:59:46,432 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:59:46,432 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:59:46,432 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 12:59:46,433 : INFO : Loading a fresh vocabulary
2018-01-03 12:59:46,433 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:59:46,433 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 12:59:46,449 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:59:46,449 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:59:46,449 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 12:59:46,450 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:59:46,450 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:59:46,450 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 12:59:46,468 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 12:59:46,468 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 12:59:46,468 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:59:46,468 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 12:59:46,469 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:59:46,469 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:59:46,469 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 12:59:46,481 : INFO : resetting layer weights
2018-01-03 12:59:46,481 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:59:46,481 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 12:59:46,555 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:46,555 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:46,555 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:47,023 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,023 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,023 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,026 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,026 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,026 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,029 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,029 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1194038 effective words/s
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1194038 effective words/s
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1194038 effective words/s
2018-01-03 12:59:47,029 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:47,029 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 12:59:47,649 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,649 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,649 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 12:59:47,651 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,651 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,651 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 12:59:47,654 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,654 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,654 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 12:59:47,654 : INFO : training on 797984 raw words (558597 effective words) took 0.6s, 900246 effective words/s
2018-01-03 12:59:47,654 - gensim.models.word2vec - INFO - training on 797984 raw words (558597 effective words) took 0.6s, 900246 effective words/s
2018-01-03 12:59:47,654 - gensim.models.word2vec - INFO - training on 797984 raw words (558597 effective words) took 0.6s, 900246 effective words/s
2018-01-03 13:00:31,442 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:00:31,442 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:00:31,442 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:00:31,443 : INFO : collecting all words and their counts
2018-01-03 13:00:31,443 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 13:00:31,443 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 13:00:31,443 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:00:31,443 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:00:31,443 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:00:31,477 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:00:31,477 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:00:31,477 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:00:31,477 : INFO : Loading a fresh vocabulary
2018-01-03 13:00:31,477 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 13:00:31,477 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 13:00:31,501 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:00:31,501 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:00:31,501 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:00:31,502 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:00:31,502 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:00:31,502 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:00:31,523 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 13:00:31,523 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 13:00:31,523 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 13:00:31,524 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 13:00:31,524 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:00:31,524 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:00:31,524 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:00:31,540 : INFO : resetting layer weights
2018-01-03 13:00:31,540 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 13:00:31,540 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 13:00:31,620 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:31,620 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:31,620 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:32,097 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,097 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,100 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,100 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,100 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,102 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,102 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1168259 effective words/s
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1168259 effective words/s
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1168259 effective words/s
2018-01-03 13:00:32,102 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:32,102 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:00:32,603 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,603 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,603 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:00:32,607 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,607 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,607 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:00:32,611 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,611 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,611 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:00:32,611 : INFO : training on 797984 raw words (558135 effective words) took 0.5s, 1108749 effective words/s
2018-01-03 13:00:32,611 - gensim.models.word2vec - INFO - training on 797984 raw words (558135 effective words) took 0.5s, 1108749 effective words/s
2018-01-03 13:00:32,611 - gensim.models.word2vec - INFO - training on 797984 raw words (558135 effective words) took 0.5s, 1108749 effective words/s
2018-01-03 13:01:20,216 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:01:20,216 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:01:20,216 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 13:01:20,217 : INFO : collecting all words and their counts
2018-01-03 13:01:20,217 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 13:01:20,217 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 13:01:20,218 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:01:20,218 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:01:20,218 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 13:01:20,257 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:01:20,257 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:01:20,257 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 13:01:20,258 : INFO : Loading a fresh vocabulary
2018-01-03 13:01:20,258 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 13:01:20,258 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 13:01:20,285 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:01:20,285 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:01:20,285 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 13:01:20,285 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:01:20,285 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:01:20,285 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 13:01:20,307 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 13:01:20,307 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 13:01:20,307 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 13:01:20,308 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 13:01:20,308 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 13:01:20,308 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:01:20,308 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 13:01:20,327 : INFO : resetting layer weights
2018-01-03 13:01:20,327 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 13:01:20,327 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 13:01:20,422 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:20,422 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:20,422 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:20,895 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:20,895 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:20,895 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:20,899 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:20,899 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:20,899 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:20,904 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:20,904 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:20,904 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:20,905 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1174102 effective words/s
2018-01-03 13:01:20,905 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1174102 effective words/s
2018-01-03 13:01:20,905 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1174102 effective words/s
2018-01-03 13:01:20,905 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:20,905 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:20,905 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 13:01:21,430 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:21,430 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:21,430 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 13:01:21,432 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:21,432 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:21,432 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 13:01:21,437 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:21,437 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:21,437 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 13:01:21,437 : INFO : training on 797984 raw words (558456 effective words) took 0.5s, 1059241 effective words/s
2018-01-03 13:01:21,437 - gensim.models.word2vec - INFO - training on 797984 raw words (558456 effective words) took 0.5s, 1059241 effective words/s
2018-01-03 13:01:21,437 - gensim.models.word2vec - INFO - training on 797984 raw words (558456 effective words) took 0.5s, 1059241 effective words/s
2018-01-03 16:16:13,338 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:16:13,338 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:16:13,338 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:16:13,339 : INFO : collecting all words and their counts
2018-01-03 16:16:13,339 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:16:13,339 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:16:13,339 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:16:13,339 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:16:13,339 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:16:13,363 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:16:13,363 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:16:13,363 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:16:13,363 : INFO : Loading a fresh vocabulary
2018-01-03 16:16:13,363 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:16:13,363 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:16:13,382 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:16:13,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:16:13,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:16:13,382 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:16:13,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:16:13,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:16:13,401 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:16:13,401 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:16:13,401 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:16:13,402 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:16:13,402 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:16:13,402 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:16:13,402 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:16:13,414 : INFO : resetting layer weights
2018-01-03 16:16:13,414 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:16:13,414 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:16:13,485 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:13,485 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:13,485 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:13,933 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:13,933 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:13,933 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:13,939 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:13,939 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:13,939 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:13,941 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:13,941 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1237844 effective words/s
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1237844 effective words/s
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1237844 effective words/s
2018-01-03 16:16:13,941 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:13,941 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:16:14,437 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:14,437 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:14,437 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:16:14,441 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:14,441 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:14,441 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:16:14,443 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:14,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:14,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:16:14,443 : INFO : training on 797984 raw words (558132 effective words) took 0.5s, 1121418 effective words/s
2018-01-03 16:16:14,443 - gensim.models.word2vec - INFO - training on 797984 raw words (558132 effective words) took 0.5s, 1121418 effective words/s
2018-01-03 16:16:14,443 - gensim.models.word2vec - INFO - training on 797984 raw words (558132 effective words) took 0.5s, 1121418 effective words/s
2018-01-03 16:35:30,747 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:35:30,747 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:35:30,747 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:35:30,747 : INFO : collecting all words and their counts
2018-01-03 16:35:30,747 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:35:30,747 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:35:30,748 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:35:30,748 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:35:30,748 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:35:30,770 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:35:30,770 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:35:30,770 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:35:30,770 : INFO : Loading a fresh vocabulary
2018-01-03 16:35:30,770 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:35:30,770 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:35:30,783 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:35:30,783 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:35:30,783 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:35:30,783 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:35:30,783 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:35:30,783 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:35:30,801 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:35:30,801 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:35:30,801 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:35:30,801 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:35:30,801 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:35:30,814 : INFO : resetting layer weights
2018-01-03 16:35:30,814 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:35:30,814 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:35:30,893 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:30,893 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:30,893 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:31,388 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,388 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,388 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,390 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,390 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,390 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,392 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,392 : INFO : training on 797984 raw words (558410 effective words) took 0.5s, 1130417 effective words/s
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - training on 797984 raw words (558410 effective words) took 0.5s, 1130417 effective words/s
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - training on 797984 raw words (558410 effective words) took 0.5s, 1130417 effective words/s
2018-01-03 16:35:31,392 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:31,392 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:35:31,893 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,893 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,893 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:35:31,896 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,896 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,896 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:35:31,902 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,902 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,902 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:35:31,902 : INFO : training on 797984 raw words (558737 effective words) took 0.5s, 1104187 effective words/s
2018-01-03 16:35:31,902 - gensim.models.word2vec - INFO - training on 797984 raw words (558737 effective words) took 0.5s, 1104187 effective words/s
2018-01-03 16:35:31,902 - gensim.models.word2vec - INFO - training on 797984 raw words (558737 effective words) took 0.5s, 1104187 effective words/s
2018-01-03 16:40:08,330 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:40:08,330 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:40:08,330 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:40:08,330 : INFO : collecting all words and their counts
2018-01-03 16:40:08,330 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:40:08,330 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:40:08,331 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:40:08,331 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:40:08,331 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:40:08,361 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:40:08,361 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:40:08,361 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:40:08,362 : INFO : Loading a fresh vocabulary
2018-01-03 16:40:08,362 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:40:08,362 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:40:08,376 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:40:08,376 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:40:08,376 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:40:08,377 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:40:08,377 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:40:08,377 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:40:08,394 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:40:08,394 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:40:08,394 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:40:08,395 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:40:08,395 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:40:08,395 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:40:08,395 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:40:08,395 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:40:08,395 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:40:08,396 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:40:08,396 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:40:08,396 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:40:08,410 : INFO : resetting layer weights
2018-01-03 16:40:08,410 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:40:08,410 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:40:08,480 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:08,480 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:08,480 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:08,957 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:08,957 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:08,957 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:08,958 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:08,958 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:08,958 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:08,963 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:08,963 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:08,963 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:08,964 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1164937 effective words/s
2018-01-03 16:40:08,964 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1164937 effective words/s
2018-01-03 16:40:08,964 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1164937 effective words/s
2018-01-03 16:40:08,964 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:08,964 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:08,964 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:40:09,433 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:09,433 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:09,433 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:40:09,440 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:09,440 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:09,440 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:40:09,443 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:09,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:09,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:40:09,443 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1179238 effective words/s
2018-01-03 16:40:09,443 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1179238 effective words/s
2018-01-03 16:40:09,443 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1179238 effective words/s
2018-01-03 16:42:10,875 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:42:10,875 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:42:10,875 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:42:10,875 : INFO : collecting all words and their counts
2018-01-03 16:42:10,875 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:42:10,875 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:42:10,876 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:42:10,876 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:42:10,876 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:42:10,906 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:42:10,906 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:42:10,906 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:42:10,906 : INFO : Loading a fresh vocabulary
2018-01-03 16:42:10,906 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:42:10,906 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:42:10,927 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:42:10,927 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:42:10,927 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:42:10,927 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:42:10,927 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:42:10,927 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:42:10,950 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:42:10,950 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:42:10,950 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:42:10,950 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:42:10,950 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:42:10,968 : INFO : resetting layer weights
2018-01-03 16:42:10,968 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:42:10,968 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:42:11,035 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,035 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,035 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,499 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,499 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,499 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,504 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,504 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,504 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,506 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,506 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1198330 effective words/s
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1198330 effective words/s
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1198330 effective words/s
2018-01-03 16:42:11,506 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,506 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:42:11,974 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,974 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,974 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:42:11,983 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,983 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,983 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:42:11,984 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,984 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,984 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:42:11,984 : INFO : training on 797984 raw words (558138 effective words) took 0.5s, 1177664 effective words/s
2018-01-03 16:42:11,984 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1177664 effective words/s
2018-01-03 16:42:11,984 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1177664 effective words/s
2018-01-03 16:42:30,476 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:42:30,476 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:42:30,476 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:42:30,476 : INFO : starting fold 1 in 10-fold CV
2018-01-03 16:42:30,476 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 16:42:30,476 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 16:46:41,050 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:46:41,050 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:46:41,050 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:46:41,050 : INFO : collecting all words and their counts
2018-01-03 16:46:41,050 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:46:41,050 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:46:41,051 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:46:41,051 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:46:41,051 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:46:41,073 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:46:41,073 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:46:41,073 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:46:41,074 : INFO : Loading a fresh vocabulary
2018-01-03 16:46:41,074 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:46:41,074 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:46:41,086 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:46:41,086 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:46:41,086 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:46:41,087 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:46:41,087 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:46:41,087 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:46:41,104 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:46:41,104 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:46:41,104 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:46:41,104 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:46:41,104 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:46:41,104 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:46:41,105 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:46:41,105 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:46:41,105 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:46:41,105 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:46:41,105 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:46:41,105 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:46:41,122 : INFO : resetting layer weights
2018-01-03 16:46:41,122 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:46:41,122 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:46:41,199 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:41,199 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:41,199 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:41,642 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:41,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:41,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:41,645 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:41,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:41,645 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:41,648 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:41,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:41,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:41,649 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1255294 effective words/s
2018-01-03 16:46:41,649 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1255294 effective words/s
2018-01-03 16:46:41,649 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1255294 effective words/s
2018-01-03 16:46:41,649 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:41,649 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:41,649 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:46:42,118 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:42,118 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:42,118 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:46:42,123 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:42,123 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:42,123 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:46:42,127 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:42,127 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:42,127 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:46:42,127 : INFO : training on 797984 raw words (558356 effective words) took 0.5s, 1181841 effective words/s
2018-01-03 16:46:42,127 - gensim.models.word2vec - INFO - training on 797984 raw words (558356 effective words) took 0.5s, 1181841 effective words/s
2018-01-03 16:46:42,127 - gensim.models.word2vec - INFO - training on 797984 raw words (558356 effective words) took 0.5s, 1181841 effective words/s
2018-01-03 16:47:01,219 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:47:01,219 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:47:01,219 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:47:01,219 : INFO : starting fold 1 in 10-fold CV
2018-01-03 16:47:01,219 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 16:47:01,219 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 16:47:09,349 : INFO : Step 1, Minibatch Loss= 0.4979, Training Accuracy= 0.749
2018-01-03 16:47:09,349 - root - INFO - Step 1, Minibatch Loss= 0.4979, Training Accuracy= 0.749
2018-01-03 16:47:09,349 - root - INFO - Step 1, Minibatch Loss= 0.4979, Training Accuracy= 0.749
2018-01-03 16:47:09,405 : INFO : Step 1, Validation Loss= 0.5043, Validation Accuracy= 0.774
2018-01-03 16:47:09,405 - root - INFO - Step 1, Validation Loss= 0.5043, Validation Accuracy= 0.774
2018-01-03 16:47:09,405 - root - INFO - Step 1, Validation Loss= 0.5043, Validation Accuracy= 0.774
2018-01-03 16:47:11,288 : INFO : Step 2, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 16:47:11,288 - root - INFO - Step 2, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 16:47:11,288 - root - INFO - Step 2, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 16:47:11,342 : INFO : Step 2, Validation Loss= 0.4147, Validation Accuracy= 0.817
2018-01-03 16:47:11,342 - root - INFO - Step 2, Validation Loss= 0.4147, Validation Accuracy= 0.817
2018-01-03 16:47:11,342 - root - INFO - Step 2, Validation Loss= 0.4147, Validation Accuracy= 0.817
2018-01-03 16:47:13,168 : INFO : Step 3, Minibatch Loss= 0.0978, Training Accuracy= 0.964
2018-01-03 16:47:13,168 - root - INFO - Step 3, Minibatch Loss= 0.0978, Training Accuracy= 0.964
2018-01-03 16:47:13,168 - root - INFO - Step 3, Minibatch Loss= 0.0978, Training Accuracy= 0.964
2018-01-03 16:47:13,220 : INFO : Step 3, Validation Loss= 0.2792, Validation Accuracy= 0.916
2018-01-03 16:47:13,220 - root - INFO - Step 3, Validation Loss= 0.2792, Validation Accuracy= 0.916
2018-01-03 16:47:13,220 - root - INFO - Step 3, Validation Loss= 0.2792, Validation Accuracy= 0.916
2018-01-03 16:47:15,034 : INFO : Step 4, Minibatch Loss= 0.0570, Training Accuracy= 0.981
2018-01-03 16:47:15,034 - root - INFO - Step 4, Minibatch Loss= 0.0570, Training Accuracy= 0.981
2018-01-03 16:47:15,034 - root - INFO - Step 4, Minibatch Loss= 0.0570, Training Accuracy= 0.981
2018-01-03 16:47:15,087 : INFO : Step 4, Validation Loss= 0.2610, Validation Accuracy= 0.923
2018-01-03 16:47:15,087 - root - INFO - Step 4, Validation Loss= 0.2610, Validation Accuracy= 0.923
2018-01-03 16:47:15,087 - root - INFO - Step 4, Validation Loss= 0.2610, Validation Accuracy= 0.923
2018-01-03 16:47:16,919 : INFO : Step 5, Minibatch Loss= 0.0399, Training Accuracy= 0.990
2018-01-03 16:47:16,919 - root - INFO - Step 5, Minibatch Loss= 0.0399, Training Accuracy= 0.990
2018-01-03 16:47:16,919 - root - INFO - Step 5, Minibatch Loss= 0.0399, Training Accuracy= 0.990
2018-01-03 16:47:16,974 : INFO : Step 5, Validation Loss= 0.3031, Validation Accuracy= 0.901
2018-01-03 16:47:16,974 - root - INFO - Step 5, Validation Loss= 0.3031, Validation Accuracy= 0.901
2018-01-03 16:47:16,974 - root - INFO - Step 5, Validation Loss= 0.3031, Validation Accuracy= 0.901
2018-01-03 16:47:16,974 : INFO : starting fold 2 in 10-fold CV
2018-01-03 16:47:16,974 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 16:47:16,974 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 16:47:24,349 : INFO : Step 1, Minibatch Loss= 0.5284, Training Accuracy= 0.745
2018-01-03 16:47:24,349 - root - INFO - Step 1, Minibatch Loss= 0.5284, Training Accuracy= 0.745
2018-01-03 16:47:24,349 - root - INFO - Step 1, Minibatch Loss= 0.5284, Training Accuracy= 0.745
2018-01-03 16:47:24,400 : INFO : Step 1, Validation Loss= 0.8970, Validation Accuracy= 0.471
2018-01-03 16:47:24,400 - root - INFO - Step 1, Validation Loss= 0.8970, Validation Accuracy= 0.471
2018-01-03 16:47:24,400 - root - INFO - Step 1, Validation Loss= 0.8970, Validation Accuracy= 0.471
2018-01-03 16:47:26,310 : INFO : Step 2, Minibatch Loss= 0.1889, Training Accuracy= 0.913
2018-01-03 16:47:26,310 - root - INFO - Step 2, Minibatch Loss= 0.1889, Training Accuracy= 0.913
2018-01-03 16:47:26,310 - root - INFO - Step 2, Minibatch Loss= 0.1889, Training Accuracy= 0.913
2018-01-03 16:47:26,362 : INFO : Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.809
2018-01-03 16:47:26,362 - root - INFO - Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.809
2018-01-03 16:47:26,362 - root - INFO - Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.809
2018-01-03 16:47:28,344 : INFO : Step 3, Minibatch Loss= 0.1119, Training Accuracy= 0.959
2018-01-03 16:47:28,344 - root - INFO - Step 3, Minibatch Loss= 0.1119, Training Accuracy= 0.959
2018-01-03 16:47:28,344 - root - INFO - Step 3, Minibatch Loss= 0.1119, Training Accuracy= 0.959
2018-01-03 16:47:28,398 : INFO : Step 3, Validation Loss= 0.1689, Validation Accuracy= 0.925
2018-01-03 16:47:28,398 - root - INFO - Step 3, Validation Loss= 0.1689, Validation Accuracy= 0.925
2018-01-03 16:47:28,398 - root - INFO - Step 3, Validation Loss= 0.1689, Validation Accuracy= 0.925
2018-01-03 16:47:30,357 : INFO : Step 4, Minibatch Loss= 0.0665, Training Accuracy= 0.976
2018-01-03 16:47:30,357 - root - INFO - Step 4, Minibatch Loss= 0.0665, Training Accuracy= 0.976
2018-01-03 16:47:30,357 - root - INFO - Step 4, Minibatch Loss= 0.0665, Training Accuracy= 0.976
2018-01-03 16:47:30,416 : INFO : Step 4, Validation Loss= 0.2616, Validation Accuracy= 0.899
2018-01-03 16:47:30,416 - root - INFO - Step 4, Validation Loss= 0.2616, Validation Accuracy= 0.899
2018-01-03 16:47:30,416 - root - INFO - Step 4, Validation Loss= 0.2616, Validation Accuracy= 0.899
2018-01-03 16:47:30,416 : INFO : starting fold 3 in 10-fold CV
2018-01-03 16:47:30,416 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 16:47:30,416 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 16:47:37,399 : INFO : Step 1, Minibatch Loss= 0.4492, Training Accuracy= 0.848
2018-01-03 16:47:37,399 - root - INFO - Step 1, Minibatch Loss= 0.4492, Training Accuracy= 0.848
2018-01-03 16:47:37,399 - root - INFO - Step 1, Minibatch Loss= 0.4492, Training Accuracy= 0.848
2018-01-03 16:47:37,465 : INFO : Step 1, Validation Loss= 0.4190, Validation Accuracy= 0.843
2018-01-03 16:47:37,465 - root - INFO - Step 1, Validation Loss= 0.4190, Validation Accuracy= 0.843
2018-01-03 16:47:37,465 - root - INFO - Step 1, Validation Loss= 0.4190, Validation Accuracy= 0.843
2018-01-03 16:47:39,417 : INFO : Step 2, Minibatch Loss= 0.1344, Training Accuracy= 0.959
2018-01-03 16:47:39,417 - root - INFO - Step 2, Minibatch Loss= 0.1344, Training Accuracy= 0.959
2018-01-03 16:47:39,417 - root - INFO - Step 2, Minibatch Loss= 0.1344, Training Accuracy= 0.959
2018-01-03 16:47:39,473 : INFO : Step 2, Validation Loss= 0.1606, Validation Accuracy= 0.948
2018-01-03 16:47:39,473 - root - INFO - Step 2, Validation Loss= 0.1606, Validation Accuracy= 0.948
2018-01-03 16:47:39,473 - root - INFO - Step 2, Validation Loss= 0.1606, Validation Accuracy= 0.948
2018-01-03 16:47:41,332 : INFO : Step 3, Minibatch Loss= 0.0800, Training Accuracy= 0.979
2018-01-03 16:47:41,332 - root - INFO - Step 3, Minibatch Loss= 0.0800, Training Accuracy= 0.979
2018-01-03 16:47:41,332 - root - INFO - Step 3, Minibatch Loss= 0.0800, Training Accuracy= 0.979
2018-01-03 16:47:41,385 : INFO : Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.938
2018-01-03 16:47:41,385 - root - INFO - Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.938
2018-01-03 16:47:41,385 - root - INFO - Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.938
2018-01-03 16:47:41,385 : INFO : starting fold 4 in 10-fold CV
2018-01-03 16:47:41,385 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 16:47:41,385 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 16:47:48,930 : INFO : Step 1, Minibatch Loss= 0.3390, Training Accuracy= 0.888
2018-01-03 16:47:48,930 - root - INFO - Step 1, Minibatch Loss= 0.3390, Training Accuracy= 0.888
2018-01-03 16:47:48,930 - root - INFO - Step 1, Minibatch Loss= 0.3390, Training Accuracy= 0.888
2018-01-03 16:47:48,987 : INFO : Step 1, Validation Loss= 0.3536, Validation Accuracy= 0.901
2018-01-03 16:47:48,987 - root - INFO - Step 1, Validation Loss= 0.3536, Validation Accuracy= 0.901
2018-01-03 16:47:48,987 - root - INFO - Step 1, Validation Loss= 0.3536, Validation Accuracy= 0.901
2018-01-03 16:47:50,934 : INFO : Step 2, Minibatch Loss= 0.1140, Training Accuracy= 0.965
2018-01-03 16:47:50,934 - root - INFO - Step 2, Minibatch Loss= 0.1140, Training Accuracy= 0.965
2018-01-03 16:47:50,934 - root - INFO - Step 2, Minibatch Loss= 0.1140, Training Accuracy= 0.965
2018-01-03 16:47:50,987 : INFO : Step 2, Validation Loss= 0.1699, Validation Accuracy= 0.959
2018-01-03 16:47:50,987 - root - INFO - Step 2, Validation Loss= 0.1699, Validation Accuracy= 0.959
2018-01-03 16:47:50,987 - root - INFO - Step 2, Validation Loss= 0.1699, Validation Accuracy= 0.959
2018-01-03 16:47:52,904 : INFO : Step 3, Minibatch Loss= 0.0696, Training Accuracy= 0.980
2018-01-03 16:47:52,904 - root - INFO - Step 3, Minibatch Loss= 0.0696, Training Accuracy= 0.980
2018-01-03 16:47:52,904 - root - INFO - Step 3, Minibatch Loss= 0.0696, Training Accuracy= 0.980
2018-01-03 16:47:52,956 : INFO : Step 3, Validation Loss= 0.1161, Validation Accuracy= 0.959
2018-01-03 16:47:52,956 - root - INFO - Step 3, Validation Loss= 0.1161, Validation Accuracy= 0.959
2018-01-03 16:47:52,956 - root - INFO - Step 3, Validation Loss= 0.1161, Validation Accuracy= 0.959
2018-01-03 16:47:54,906 : INFO : Step 4, Minibatch Loss= 0.0387, Training Accuracy= 0.989
2018-01-03 16:47:54,906 - root - INFO - Step 4, Minibatch Loss= 0.0387, Training Accuracy= 0.989
2018-01-03 16:47:54,906 - root - INFO - Step 4, Minibatch Loss= 0.0387, Training Accuracy= 0.989
2018-01-03 16:47:54,957 : INFO : Step 4, Validation Loss= 0.1655, Validation Accuracy= 0.959
2018-01-03 16:47:54,957 - root - INFO - Step 4, Validation Loss= 0.1655, Validation Accuracy= 0.959
2018-01-03 16:47:54,957 - root - INFO - Step 4, Validation Loss= 0.1655, Validation Accuracy= 0.959
2018-01-03 16:47:56,986 : INFO : Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.993
2018-01-03 16:47:56,986 - root - INFO - Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.993
2018-01-03 16:47:56,986 - root - INFO - Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.993
2018-01-03 16:47:57,042 : INFO : Step 5, Validation Loss= 0.1465, Validation Accuracy= 0.966
2018-01-03 16:47:57,042 - root - INFO - Step 5, Validation Loss= 0.1465, Validation Accuracy= 0.966
2018-01-03 16:47:57,042 - root - INFO - Step 5, Validation Loss= 0.1465, Validation Accuracy= 0.966
2018-01-03 16:47:59,039 : INFO : Step 6, Minibatch Loss= 0.0248, Training Accuracy= 0.992
2018-01-03 16:47:59,039 - root - INFO - Step 6, Minibatch Loss= 0.0248, Training Accuracy= 0.992
2018-01-03 16:47:59,039 - root - INFO - Step 6, Minibatch Loss= 0.0248, Training Accuracy= 0.992
2018-01-03 16:47:59,092 : INFO : Step 6, Validation Loss= 0.1394, Validation Accuracy= 0.959
2018-01-03 16:47:59,092 - root - INFO - Step 6, Validation Loss= 0.1394, Validation Accuracy= 0.959
2018-01-03 16:47:59,092 - root - INFO - Step 6, Validation Loss= 0.1394, Validation Accuracy= 0.959
2018-01-03 16:47:59,093 : INFO : starting fold 5 in 10-fold CV
2018-01-03 16:47:59,093 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 16:47:59,093 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 16:48:06,012 : INFO : Step 1, Minibatch Loss= 0.2905, Training Accuracy= 0.920
2018-01-03 16:48:06,012 - root - INFO - Step 1, Minibatch Loss= 0.2905, Training Accuracy= 0.920
2018-01-03 16:48:06,012 - root - INFO - Step 1, Minibatch Loss= 0.2905, Training Accuracy= 0.920
2018-01-03 16:48:06,069 : INFO : Step 1, Validation Loss= 0.3700, Validation Accuracy= 0.843
2018-01-03 16:48:06,069 - root - INFO - Step 1, Validation Loss= 0.3700, Validation Accuracy= 0.843
2018-01-03 16:48:06,069 - root - INFO - Step 1, Validation Loss= 0.3700, Validation Accuracy= 0.843
2018-01-03 16:48:07,946 : INFO : Step 2, Minibatch Loss= 0.1188, Training Accuracy= 0.970
2018-01-03 16:48:07,946 - root - INFO - Step 2, Minibatch Loss= 0.1188, Training Accuracy= 0.970
2018-01-03 16:48:07,946 - root - INFO - Step 2, Minibatch Loss= 0.1188, Training Accuracy= 0.970
2018-01-03 16:48:08,000 : INFO : Step 2, Validation Loss= 0.2880, Validation Accuracy= 0.899
2018-01-03 16:48:08,000 - root - INFO - Step 2, Validation Loss= 0.2880, Validation Accuracy= 0.899
2018-01-03 16:48:08,000 - root - INFO - Step 2, Validation Loss= 0.2880, Validation Accuracy= 0.899
2018-01-03 16:48:09,975 : INFO : Step 3, Minibatch Loss= 0.0604, Training Accuracy= 0.985
2018-01-03 16:48:09,975 - root - INFO - Step 3, Minibatch Loss= 0.0604, Training Accuracy= 0.985
2018-01-03 16:48:09,975 - root - INFO - Step 3, Minibatch Loss= 0.0604, Training Accuracy= 0.985
2018-01-03 16:48:10,034 : INFO : Step 3, Validation Loss= 0.3537, Validation Accuracy= 0.899
2018-01-03 16:48:10,034 - root - INFO - Step 3, Validation Loss= 0.3537, Validation Accuracy= 0.899
2018-01-03 16:48:10,034 - root - INFO - Step 3, Validation Loss= 0.3537, Validation Accuracy= 0.899
2018-01-03 16:48:12,009 : INFO : Step 4, Minibatch Loss= 0.0354, Training Accuracy= 0.992
2018-01-03 16:48:12,009 - root - INFO - Step 4, Minibatch Loss= 0.0354, Training Accuracy= 0.992
2018-01-03 16:48:12,009 - root - INFO - Step 4, Minibatch Loss= 0.0354, Training Accuracy= 0.992
2018-01-03 16:48:12,066 : INFO : Step 4, Validation Loss= 0.2727, Validation Accuracy= 0.923
2018-01-03 16:48:12,066 - root - INFO - Step 4, Validation Loss= 0.2727, Validation Accuracy= 0.923
2018-01-03 16:48:12,066 - root - INFO - Step 4, Validation Loss= 0.2727, Validation Accuracy= 0.923
2018-01-03 16:48:13,955 : INFO : Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.997
2018-01-03 16:48:13,955 - root - INFO - Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.997
2018-01-03 16:48:13,955 - root - INFO - Step 5, Minibatch Loss= 0.0220, Training Accuracy= 0.997
2018-01-03 16:48:14,003 : INFO : Step 5, Validation Loss= 0.2810, Validation Accuracy= 0.923
2018-01-03 16:48:14,003 - root - INFO - Step 5, Validation Loss= 0.2810, Validation Accuracy= 0.923
2018-01-03 16:48:14,003 - root - INFO - Step 5, Validation Loss= 0.2810, Validation Accuracy= 0.923
2018-01-03 16:48:15,884 : INFO : Step 6, Minibatch Loss= 0.0152, Training Accuracy= 0.997
2018-01-03 16:48:15,884 - root - INFO - Step 6, Minibatch Loss= 0.0152, Training Accuracy= 0.997
2018-01-03 16:48:15,884 - root - INFO - Step 6, Minibatch Loss= 0.0152, Training Accuracy= 0.997
2018-01-03 16:48:15,936 : INFO : Step 6, Validation Loss= 0.3692, Validation Accuracy= 0.914
2018-01-03 16:48:15,936 - root - INFO - Step 6, Validation Loss= 0.3692, Validation Accuracy= 0.914
2018-01-03 16:48:15,936 - root - INFO - Step 6, Validation Loss= 0.3692, Validation Accuracy= 0.914
2018-01-03 16:48:15,937 : INFO : starting fold 6 in 10-fold CV
2018-01-03 16:48:15,937 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 16:48:15,937 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 16:48:23,437 : INFO : Step 1, Minibatch Loss= 0.3034, Training Accuracy= 0.922
2018-01-03 16:48:23,437 - root - INFO - Step 1, Minibatch Loss= 0.3034, Training Accuracy= 0.922
2018-01-03 16:48:23,437 - root - INFO - Step 1, Minibatch Loss= 0.3034, Training Accuracy= 0.922
2018-01-03 16:48:23,492 : INFO : Step 1, Validation Loss= 0.3736, Validation Accuracy= 0.869
2018-01-03 16:48:23,492 - root - INFO - Step 1, Validation Loss= 0.3736, Validation Accuracy= 0.869
2018-01-03 16:48:23,492 - root - INFO - Step 1, Validation Loss= 0.3736, Validation Accuracy= 0.869
2018-01-03 16:48:25,440 : INFO : Step 2, Minibatch Loss= 0.1109, Training Accuracy= 0.968
2018-01-03 16:48:25,440 - root - INFO - Step 2, Minibatch Loss= 0.1109, Training Accuracy= 0.968
2018-01-03 16:48:25,440 - root - INFO - Step 2, Minibatch Loss= 0.1109, Training Accuracy= 0.968
2018-01-03 16:48:25,491 : INFO : Step 2, Validation Loss= 0.2217, Validation Accuracy= 0.912
2018-01-03 16:48:25,491 - root - INFO - Step 2, Validation Loss= 0.2217, Validation Accuracy= 0.912
2018-01-03 16:48:25,491 - root - INFO - Step 2, Validation Loss= 0.2217, Validation Accuracy= 0.912
2018-01-03 16:48:27,448 : INFO : Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.979
2018-01-03 16:48:27,448 - root - INFO - Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.979
2018-01-03 16:48:27,448 - root - INFO - Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.979
2018-01-03 16:48:27,500 : INFO : Step 3, Validation Loss= 0.2989, Validation Accuracy= 0.903
2018-01-03 16:48:27,500 - root - INFO - Step 3, Validation Loss= 0.2989, Validation Accuracy= 0.903
2018-01-03 16:48:27,500 - root - INFO - Step 3, Validation Loss= 0.2989, Validation Accuracy= 0.903
2018-01-03 16:48:27,501 : INFO : starting fold 7 in 10-fold CV
2018-01-03 16:48:27,501 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 16:48:27,501 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 16:48:34,328 : INFO : Step 1, Minibatch Loss= 0.4281, Training Accuracy= 0.856
2018-01-03 16:48:34,328 - root - INFO - Step 1, Minibatch Loss= 0.4281, Training Accuracy= 0.856
2018-01-03 16:48:34,328 - root - INFO - Step 1, Minibatch Loss= 0.4281, Training Accuracy= 0.856
2018-01-03 16:48:34,385 : INFO : Step 1, Validation Loss= 0.4656, Validation Accuracy= 0.869
2018-01-03 16:48:34,385 - root - INFO - Step 1, Validation Loss= 0.4656, Validation Accuracy= 0.869
2018-01-03 16:48:34,385 - root - INFO - Step 1, Validation Loss= 0.4656, Validation Accuracy= 0.869
2018-01-03 16:48:36,324 : INFO : Step 2, Minibatch Loss= 0.1364, Training Accuracy= 0.949
2018-01-03 16:48:36,324 - root - INFO - Step 2, Minibatch Loss= 0.1364, Training Accuracy= 0.949
2018-01-03 16:48:36,324 - root - INFO - Step 2, Minibatch Loss= 0.1364, Training Accuracy= 0.949
2018-01-03 16:48:36,379 : INFO : Step 2, Validation Loss= 0.2273, Validation Accuracy= 0.923
2018-01-03 16:48:36,379 - root - INFO - Step 2, Validation Loss= 0.2273, Validation Accuracy= 0.923
2018-01-03 16:48:36,379 - root - INFO - Step 2, Validation Loss= 0.2273, Validation Accuracy= 0.923
2018-01-03 16:48:38,331 : INFO : Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 16:48:38,331 - root - INFO - Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 16:48:38,331 - root - INFO - Step 3, Minibatch Loss= 0.0784, Training Accuracy= 0.977
2018-01-03 16:48:38,384 : INFO : Step 3, Validation Loss= 0.2709, Validation Accuracy= 0.899
2018-01-03 16:48:38,384 - root - INFO - Step 3, Validation Loss= 0.2709, Validation Accuracy= 0.899
2018-01-03 16:48:38,384 - root - INFO - Step 3, Validation Loss= 0.2709, Validation Accuracy= 0.899
2018-01-03 16:48:38,385 : INFO : starting fold 8 in 10-fold CV
2018-01-03 16:48:38,385 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 16:48:38,385 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 16:48:45,848 : INFO : Step 1, Minibatch Loss= 0.5763, Training Accuracy= 0.700
2018-01-03 16:48:45,848 - root - INFO - Step 1, Minibatch Loss= 0.5763, Training Accuracy= 0.700
2018-01-03 16:48:45,848 - root - INFO - Step 1, Minibatch Loss= 0.5763, Training Accuracy= 0.700
2018-01-03 16:48:45,904 : INFO : Step 1, Validation Loss= 0.5606, Validation Accuracy= 0.735
2018-01-03 16:48:45,904 - root - INFO - Step 1, Validation Loss= 0.5606, Validation Accuracy= 0.735
2018-01-03 16:48:45,904 - root - INFO - Step 1, Validation Loss= 0.5606, Validation Accuracy= 0.735
2018-01-03 16:48:47,825 : INFO : Step 2, Minibatch Loss= 0.1857, Training Accuracy= 0.927
2018-01-03 16:48:47,825 - root - INFO - Step 2, Minibatch Loss= 0.1857, Training Accuracy= 0.927
2018-01-03 16:48:47,825 - root - INFO - Step 2, Minibatch Loss= 0.1857, Training Accuracy= 0.927
2018-01-03 16:48:47,882 : INFO : Step 2, Validation Loss= 0.3423, Validation Accuracy= 0.845
2018-01-03 16:48:47,882 - root - INFO - Step 2, Validation Loss= 0.3423, Validation Accuracy= 0.845
2018-01-03 16:48:47,882 - root - INFO - Step 2, Validation Loss= 0.3423, Validation Accuracy= 0.845
2018-01-03 16:48:49,837 : INFO : Step 3, Minibatch Loss= 0.1036, Training Accuracy= 0.968
2018-01-03 16:48:49,837 - root - INFO - Step 3, Minibatch Loss= 0.1036, Training Accuracy= 0.968
2018-01-03 16:48:49,837 - root - INFO - Step 3, Minibatch Loss= 0.1036, Training Accuracy= 0.968
2018-01-03 16:48:49,892 : INFO : Step 3, Validation Loss= 0.2895, Validation Accuracy= 0.892
2018-01-03 16:48:49,892 - root - INFO - Step 3, Validation Loss= 0.2895, Validation Accuracy= 0.892
2018-01-03 16:48:49,892 - root - INFO - Step 3, Validation Loss= 0.2895, Validation Accuracy= 0.892
2018-01-03 16:48:51,811 : INFO : Step 4, Minibatch Loss= 0.0783, Training Accuracy= 0.972
2018-01-03 16:48:51,811 - root - INFO - Step 4, Minibatch Loss= 0.0783, Training Accuracy= 0.972
2018-01-03 16:48:51,811 - root - INFO - Step 4, Minibatch Loss= 0.0783, Training Accuracy= 0.972
2018-01-03 16:48:51,867 : INFO : Step 4, Validation Loss= 0.3054, Validation Accuracy= 0.895
2018-01-03 16:48:51,867 - root - INFO - Step 4, Validation Loss= 0.3054, Validation Accuracy= 0.895
2018-01-03 16:48:51,867 - root - INFO - Step 4, Validation Loss= 0.3054, Validation Accuracy= 0.895
2018-01-03 16:48:53,770 : INFO : Step 5, Minibatch Loss= 0.0408, Training Accuracy= 0.988
2018-01-03 16:48:53,770 - root - INFO - Step 5, Minibatch Loss= 0.0408, Training Accuracy= 0.988
2018-01-03 16:48:53,770 - root - INFO - Step 5, Minibatch Loss= 0.0408, Training Accuracy= 0.988
2018-01-03 16:48:53,825 : INFO : Step 5, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 16:48:53,825 - root - INFO - Step 5, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 16:48:53,825 - root - INFO - Step 5, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 16:48:55,765 : INFO : Step 6, Minibatch Loss= 0.0356, Training Accuracy= 0.989
2018-01-03 16:48:55,765 - root - INFO - Step 6, Minibatch Loss= 0.0356, Training Accuracy= 0.989
2018-01-03 16:48:55,765 - root - INFO - Step 6, Minibatch Loss= 0.0356, Training Accuracy= 0.989
2018-01-03 16:48:55,823 : INFO : Step 6, Validation Loss= 0.3146, Validation Accuracy= 0.908
2018-01-03 16:48:55,823 - root - INFO - Step 6, Validation Loss= 0.3146, Validation Accuracy= 0.908
2018-01-03 16:48:55,823 - root - INFO - Step 6, Validation Loss= 0.3146, Validation Accuracy= 0.908
2018-01-03 16:48:57,763 : INFO : Step 7, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 16:48:57,763 - root - INFO - Step 7, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 16:48:57,763 - root - INFO - Step 7, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 16:48:57,819 : INFO : Step 7, Validation Loss= 0.2340, Validation Accuracy= 0.910
2018-01-03 16:48:57,819 - root - INFO - Step 7, Validation Loss= 0.2340, Validation Accuracy= 0.910
2018-01-03 16:48:57,819 - root - INFO - Step 7, Validation Loss= 0.2340, Validation Accuracy= 0.910
2018-01-03 16:48:59,755 : INFO : Step 8, Minibatch Loss= 0.0209, Training Accuracy= 0.994
2018-01-03 16:48:59,755 - root - INFO - Step 8, Minibatch Loss= 0.0209, Training Accuracy= 0.994
2018-01-03 16:48:59,755 - root - INFO - Step 8, Minibatch Loss= 0.0209, Training Accuracy= 0.994
2018-01-03 16:48:59,806 : INFO : Step 8, Validation Loss= 0.3310, Validation Accuracy= 0.899
2018-01-03 16:48:59,806 - root - INFO - Step 8, Validation Loss= 0.3310, Validation Accuracy= 0.899
2018-01-03 16:48:59,806 - root - INFO - Step 8, Validation Loss= 0.3310, Validation Accuracy= 0.899
2018-01-03 16:48:59,807 : INFO : starting fold 9 in 10-fold CV
2018-01-03 16:48:59,807 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 16:48:59,807 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 16:49:06,541 : INFO : Step 1, Minibatch Loss= 0.4325, Training Accuracy= 0.821
2018-01-03 16:49:06,541 - root - INFO - Step 1, Minibatch Loss= 0.4325, Training Accuracy= 0.821
2018-01-03 16:49:06,541 - root - INFO - Step 1, Minibatch Loss= 0.4325, Training Accuracy= 0.821
2018-01-03 16:49:06,591 : INFO : Step 1, Validation Loss= 0.5095, Validation Accuracy= 0.783
2018-01-03 16:49:06,591 - root - INFO - Step 1, Validation Loss= 0.5095, Validation Accuracy= 0.783
2018-01-03 16:49:06,591 - root - INFO - Step 1, Validation Loss= 0.5095, Validation Accuracy= 0.783
2018-01-03 16:49:08,511 : INFO : Step 2, Minibatch Loss= 0.1354, Training Accuracy= 0.950
2018-01-03 16:49:08,511 - root - INFO - Step 2, Minibatch Loss= 0.1354, Training Accuracy= 0.950
2018-01-03 16:49:08,511 - root - INFO - Step 2, Minibatch Loss= 0.1354, Training Accuracy= 0.950
2018-01-03 16:49:08,559 : INFO : Step 2, Validation Loss= 0.2629, Validation Accuracy= 0.890
2018-01-03 16:49:08,559 - root - INFO - Step 2, Validation Loss= 0.2629, Validation Accuracy= 0.890
2018-01-03 16:49:08,559 - root - INFO - Step 2, Validation Loss= 0.2629, Validation Accuracy= 0.890
2018-01-03 16:49:10,490 : INFO : Step 3, Minibatch Loss= 0.0841, Training Accuracy= 0.968
2018-01-03 16:49:10,490 - root - INFO - Step 3, Minibatch Loss= 0.0841, Training Accuracy= 0.968
2018-01-03 16:49:10,490 - root - INFO - Step 3, Minibatch Loss= 0.0841, Training Accuracy= 0.968
2018-01-03 16:49:10,544 : INFO : Step 3, Validation Loss= 0.2921, Validation Accuracy= 0.897
2018-01-03 16:49:10,544 - root - INFO - Step 3, Validation Loss= 0.2921, Validation Accuracy= 0.897
2018-01-03 16:49:10,544 - root - INFO - Step 3, Validation Loss= 0.2921, Validation Accuracy= 0.897
2018-01-03 16:49:12,447 : INFO : Step 4, Minibatch Loss= 0.0496, Training Accuracy= 0.984
2018-01-03 16:49:12,447 - root - INFO - Step 4, Minibatch Loss= 0.0496, Training Accuracy= 0.984
2018-01-03 16:49:12,447 - root - INFO - Step 4, Minibatch Loss= 0.0496, Training Accuracy= 0.984
2018-01-03 16:49:12,497 : INFO : Step 4, Validation Loss= 0.2684, Validation Accuracy= 0.918
2018-01-03 16:49:12,497 - root - INFO - Step 4, Validation Loss= 0.2684, Validation Accuracy= 0.918
2018-01-03 16:49:12,497 - root - INFO - Step 4, Validation Loss= 0.2684, Validation Accuracy= 0.918
2018-01-03 16:49:14,438 : INFO : Step 5, Minibatch Loss= 0.0375, Training Accuracy= 0.988
2018-01-03 16:49:14,438 - root - INFO - Step 5, Minibatch Loss= 0.0375, Training Accuracy= 0.988
2018-01-03 16:49:14,438 - root - INFO - Step 5, Minibatch Loss= 0.0375, Training Accuracy= 0.988
2018-01-03 16:49:14,487 : INFO : Step 5, Validation Loss= 0.2079, Validation Accuracy= 0.938
2018-01-03 16:49:14,487 - root - INFO - Step 5, Validation Loss= 0.2079, Validation Accuracy= 0.938
2018-01-03 16:49:14,487 - root - INFO - Step 5, Validation Loss= 0.2079, Validation Accuracy= 0.938
2018-01-03 16:49:16,418 : INFO : Step 6, Minibatch Loss= 0.0271, Training Accuracy= 0.993
2018-01-03 16:49:16,418 - root - INFO - Step 6, Minibatch Loss= 0.0271, Training Accuracy= 0.993
2018-01-03 16:49:16,418 - root - INFO - Step 6, Minibatch Loss= 0.0271, Training Accuracy= 0.993
2018-01-03 16:49:16,471 : INFO : Step 6, Validation Loss= 0.2737, Validation Accuracy= 0.942
2018-01-03 16:49:16,471 - root - INFO - Step 6, Validation Loss= 0.2737, Validation Accuracy= 0.942
2018-01-03 16:49:16,471 - root - INFO - Step 6, Validation Loss= 0.2737, Validation Accuracy= 0.942
2018-01-03 16:49:18,375 : INFO : Step 7, Minibatch Loss= 0.0235, Training Accuracy= 0.995
2018-01-03 16:49:18,375 - root - INFO - Step 7, Minibatch Loss= 0.0235, Training Accuracy= 0.995
2018-01-03 16:49:18,375 - root - INFO - Step 7, Minibatch Loss= 0.0235, Training Accuracy= 0.995
2018-01-03 16:49:18,425 : INFO : Step 7, Validation Loss= 0.2515, Validation Accuracy= 0.927
2018-01-03 16:49:18,425 - root - INFO - Step 7, Validation Loss= 0.2515, Validation Accuracy= 0.927
2018-01-03 16:49:18,425 - root - INFO - Step 7, Validation Loss= 0.2515, Validation Accuracy= 0.927
2018-01-03 16:49:18,426 : INFO : starting fold 10 in 10-fold CV
2018-01-03 16:49:18,426 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 16:49:18,426 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 16:49:25,158 : INFO : Step 1, Minibatch Loss= 0.3811, Training Accuracy= 0.871
2018-01-03 16:49:25,158 - root - INFO - Step 1, Minibatch Loss= 0.3811, Training Accuracy= 0.871
2018-01-03 16:49:25,158 - root - INFO - Step 1, Minibatch Loss= 0.3811, Training Accuracy= 0.871
2018-01-03 16:49:25,212 : INFO : Step 1, Validation Loss= 0.4709, Validation Accuracy= 0.834
2018-01-03 16:49:25,212 - root - INFO - Step 1, Validation Loss= 0.4709, Validation Accuracy= 0.834
2018-01-03 16:49:25,212 - root - INFO - Step 1, Validation Loss= 0.4709, Validation Accuracy= 0.834
2018-01-03 16:49:27,266 : INFO : Step 2, Minibatch Loss= 0.1127, Training Accuracy= 0.962
2018-01-03 16:49:27,266 - root - INFO - Step 2, Minibatch Loss= 0.1127, Training Accuracy= 0.962
2018-01-03 16:49:27,266 - root - INFO - Step 2, Minibatch Loss= 0.1127, Training Accuracy= 0.962
2018-01-03 16:49:27,331 : INFO : Step 2, Validation Loss= 0.2678, Validation Accuracy= 0.905
2018-01-03 16:49:27,331 - root - INFO - Step 2, Validation Loss= 0.2678, Validation Accuracy= 0.905
2018-01-03 16:49:27,331 - root - INFO - Step 2, Validation Loss= 0.2678, Validation Accuracy= 0.905
2018-01-03 16:49:29,365 : INFO : Step 3, Minibatch Loss= 0.0813, Training Accuracy= 0.973
2018-01-03 16:49:29,365 - root - INFO - Step 3, Minibatch Loss= 0.0813, Training Accuracy= 0.973
2018-01-03 16:49:29,365 - root - INFO - Step 3, Minibatch Loss= 0.0813, Training Accuracy= 0.973
2018-01-03 16:49:29,420 : INFO : Step 3, Validation Loss= 0.2315, Validation Accuracy= 0.927
2018-01-03 16:49:29,420 - root - INFO - Step 3, Validation Loss= 0.2315, Validation Accuracy= 0.927
2018-01-03 16:49:29,420 - root - INFO - Step 3, Validation Loss= 0.2315, Validation Accuracy= 0.927
2018-01-03 16:49:31,388 : INFO : Step 4, Minibatch Loss= 0.0456, Training Accuracy= 0.988
2018-01-03 16:49:31,388 - root - INFO - Step 4, Minibatch Loss= 0.0456, Training Accuracy= 0.988
2018-01-03 16:49:31,388 - root - INFO - Step 4, Minibatch Loss= 0.0456, Training Accuracy= 0.988
2018-01-03 16:49:31,438 : INFO : Step 4, Validation Loss= 0.3629, Validation Accuracy= 0.884
2018-01-03 16:49:31,438 - root - INFO - Step 4, Validation Loss= 0.3629, Validation Accuracy= 0.884
2018-01-03 16:49:31,438 - root - INFO - Step 4, Validation Loss= 0.3629, Validation Accuracy= 0.884
2018-01-03 16:49:31,439 : INFO : Average accuracy is 0.929677 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:49:31,439 - root - INFO - Average accuracy is 0.929677 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:49:31,439 - root - INFO - Average accuracy is 0.929677 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 16:49:31,439 : INFO : This 10-fold CV run-time: 150.21984195709229 seconds
2018-01-03 16:49:31,439 - root - INFO - This 10-fold CV run-time: 150.21984195709229 seconds
2018-01-03 16:49:31,439 - root - INFO - This 10-fold CV run-time: 150.21984195709229 seconds
2018-01-03 16:49:31,600 : INFO : Code run-time: 171.00956797599792 seconds
2018-01-03 16:49:31,600 - root - INFO - Code run-time: 171.00956797599792 seconds
2018-01-03 16:49:31,600 - root - INFO - Code run-time: 171.00956797599792 seconds
2018-01-03 16:53:39,206 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:53:39,206 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:53:39,206 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 16:53:39,206 : INFO : collecting all words and their counts
2018-01-03 16:53:39,206 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:53:39,206 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 16:53:39,207 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:53:39,207 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:53:39,207 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 16:53:39,254 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:53:39,254 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:53:39,254 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 16:53:39,255 : INFO : Loading a fresh vocabulary
2018-01-03 16:53:39,255 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:53:39,255 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 16:53:39,305 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:53:39,305 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:53:39,305 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 16:53:39,306 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:53:39,306 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:53:39,306 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 16:53:39,339 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 16:53:39,339 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:53:39,339 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 16:53:39,340 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 16:53:39,340 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:53:39,340 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 16:53:39,340 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:53:39,340 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:53:39,340 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 16:53:39,341 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:53:39,341 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:53:39,341 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 16:53:39,376 : INFO : resetting layer weights
2018-01-03 16:53:39,376 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:53:39,376 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 16:53:39,478 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:39,478 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:39,478 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:39,951 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:39,951 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:39,951 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:39,954 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:39,954 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:39,954 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:39,956 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:39,956 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:39,956 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:39,957 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1191645 effective words/s
2018-01-03 16:53:39,957 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1191645 effective words/s
2018-01-03 16:53:39,957 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1191645 effective words/s
2018-01-03 16:53:39,957 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:39,957 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:39,957 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 16:53:40,422 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:40,422 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:40,422 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 16:53:40,426 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:40,426 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:40,426 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 16:53:40,428 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:40,428 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:40,428 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 16:53:40,429 : INFO : training on 797984 raw words (558821 effective words) took 0.5s, 1197349 effective words/s
2018-01-03 16:53:40,429 - gensim.models.word2vec - INFO - training on 797984 raw words (558821 effective words) took 0.5s, 1197349 effective words/s
2018-01-03 16:53:40,429 - gensim.models.word2vec - INFO - training on 797984 raw words (558821 effective words) took 0.5s, 1197349 effective words/s
2018-01-03 17:07:32,383 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:07:32,383 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:07:32,383 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:07:32,384 : INFO : collecting all words and their counts
2018-01-03 17:07:32,384 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:07:32,384 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:07:32,384 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:07:32,384 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:07:32,384 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:07:32,412 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:07:32,412 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:07:32,412 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:07:32,412 : INFO : Loading a fresh vocabulary
2018-01-03 17:07:32,412 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:07:32,412 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:07:32,433 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:07:32,433 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:07:32,433 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:07:32,433 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:07:32,433 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:07:32,433 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:07:32,463 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:07:32,463 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:07:32,463 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:07:32,464 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:07:32,464 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:07:32,464 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:07:32,464 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:07:32,478 : INFO : resetting layer weights
2018-01-03 17:07:32,478 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:07:32,478 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:07:32,555 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:32,555 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:32,555 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:33,077 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,077 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,077 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,080 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,080 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,080 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,085 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,085 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,085 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,085 : INFO : training on 797984 raw words (558607 effective words) took 0.5s, 1062413 effective words/s
2018-01-03 17:07:33,085 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1062413 effective words/s
2018-01-03 17:07:33,085 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1062413 effective words/s
2018-01-03 17:07:33,086 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:33,086 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:33,086 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:07:33,767 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,767 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,767 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:07:33,789 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,789 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,789 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:07:33,791 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,791 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,791 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:07:33,791 : INFO : training on 797984 raw words (558276 effective words) took 0.7s, 796736 effective words/s
2018-01-03 17:07:33,791 - gensim.models.word2vec - INFO - training on 797984 raw words (558276 effective words) took 0.7s, 796736 effective words/s
2018-01-03 17:07:33,791 - gensim.models.word2vec - INFO - training on 797984 raw words (558276 effective words) took 0.7s, 796736 effective words/s
2018-01-03 17:12:06,210 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:12:06,210 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:12:06,210 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:12:06,211 : INFO : collecting all words and their counts
2018-01-03 17:12:06,211 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:12:06,211 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:12:06,211 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:12:06,211 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:12:06,211 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:12:06,235 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:12:06,235 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:12:06,235 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:12:06,236 : INFO : Loading a fresh vocabulary
2018-01-03 17:12:06,236 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:12:06,236 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:12:06,259 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:12:06,259 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:12:06,259 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:12:06,261 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:12:06,261 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:12:06,261 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:12:06,295 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:12:06,295 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:12:06,295 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:12:06,295 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:12:06,296 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:12:06,296 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:12:06,296 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:12:06,310 : INFO : resetting layer weights
2018-01-03 17:12:06,310 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:12:06,310 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:12:06,391 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:06,391 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:06,391 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:06,869 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:06,869 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:06,869 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:06,873 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:06,873 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:06,873 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:06,877 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:06,877 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:06,877 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:06,878 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1161335 effective words/s
2018-01-03 17:12:06,878 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1161335 effective words/s
2018-01-03 17:12:06,878 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1161335 effective words/s
2018-01-03 17:12:06,878 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:06,878 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:06,878 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:12:07,487 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:07,487 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:07,487 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:12:07,489 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:07,489 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:07,489 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:12:07,492 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:07,492 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:07,492 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:12:07,493 : INFO : training on 797984 raw words (558464 effective words) took 0.6s, 915221 effective words/s
2018-01-03 17:12:07,493 - gensim.models.word2vec - INFO - training on 797984 raw words (558464 effective words) took 0.6s, 915221 effective words/s
2018-01-03 17:12:07,493 - gensim.models.word2vec - INFO - training on 797984 raw words (558464 effective words) took 0.6s, 915221 effective words/s
2018-01-03 17:12:28,525 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:12:28,525 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:12:28,525 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:12:28,526 : INFO : starting fold 1 in 10-fold CV
2018-01-03 17:12:28,526 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:12:28,526 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:12:38,158 : INFO : Step 1, Minibatch Loss= 0.3702, Training Accuracy= 0.872
2018-01-03 17:12:38,158 - root - INFO - Step 1, Minibatch Loss= 0.3702, Training Accuracy= 0.872
2018-01-03 17:12:38,158 - root - INFO - Step 1, Minibatch Loss= 0.3702, Training Accuracy= 0.872
2018-01-03 17:12:38,244 : INFO : Step 1, Validation Loss= 0.5001, Validation Accuracy= 0.755
2018-01-03 17:12:38,244 - root - INFO - Step 1, Validation Loss= 0.5001, Validation Accuracy= 0.755
2018-01-03 17:12:38,244 - root - INFO - Step 1, Validation Loss= 0.5001, Validation Accuracy= 0.755
2018-01-03 17:12:40,400 : INFO : Step 2, Minibatch Loss= 0.1258, Training Accuracy= 0.963
2018-01-03 17:12:40,400 - root - INFO - Step 2, Minibatch Loss= 0.1258, Training Accuracy= 0.963
2018-01-03 17:12:40,400 - root - INFO - Step 2, Minibatch Loss= 0.1258, Training Accuracy= 0.963
2018-01-03 17:12:40,456 : INFO : Step 2, Validation Loss= 0.3215, Validation Accuracy= 0.925
2018-01-03 17:12:40,456 - root - INFO - Step 2, Validation Loss= 0.3215, Validation Accuracy= 0.925
2018-01-03 17:12:40,456 - root - INFO - Step 2, Validation Loss= 0.3215, Validation Accuracy= 0.925
2018-01-03 17:12:42,401 : INFO : Step 3, Minibatch Loss= 0.0692, Training Accuracy= 0.981
2018-01-03 17:12:42,401 - root - INFO - Step 3, Minibatch Loss= 0.0692, Training Accuracy= 0.981
2018-01-03 17:12:42,401 - root - INFO - Step 3, Minibatch Loss= 0.0692, Training Accuracy= 0.981
2018-01-03 17:12:42,454 : INFO : Step 3, Validation Loss= 0.2591, Validation Accuracy= 0.923
2018-01-03 17:12:42,454 - root - INFO - Step 3, Validation Loss= 0.2591, Validation Accuracy= 0.923
2018-01-03 17:12:42,454 - root - INFO - Step 3, Validation Loss= 0.2591, Validation Accuracy= 0.923
2018-01-03 17:12:42,454 : INFO : starting fold 2 in 10-fold CV
2018-01-03 17:12:42,454 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:12:42,454 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:12:49,760 : INFO : Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.887
2018-01-03 17:12:49,760 - root - INFO - Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.887
2018-01-03 17:12:49,760 - root - INFO - Step 1, Minibatch Loss= 0.3067, Training Accuracy= 0.887
2018-01-03 17:12:49,815 : INFO : Step 1, Validation Loss= 0.3474, Validation Accuracy= 0.826
2018-01-03 17:12:49,815 - root - INFO - Step 1, Validation Loss= 0.3474, Validation Accuracy= 0.826
2018-01-03 17:12:49,815 - root - INFO - Step 1, Validation Loss= 0.3474, Validation Accuracy= 0.826
2018-01-03 17:12:51,718 : INFO : Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.964
2018-01-03 17:12:51,718 - root - INFO - Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.964
2018-01-03 17:12:51,718 - root - INFO - Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.964
2018-01-03 17:12:51,772 : INFO : Step 2, Validation Loss= 0.1583, Validation Accuracy= 0.931
2018-01-03 17:12:51,772 - root - INFO - Step 2, Validation Loss= 0.1583, Validation Accuracy= 0.931
2018-01-03 17:12:51,772 - root - INFO - Step 2, Validation Loss= 0.1583, Validation Accuracy= 0.931
2018-01-03 17:12:53,656 : INFO : Step 3, Minibatch Loss= 0.0694, Training Accuracy= 0.975
2018-01-03 17:12:53,656 - root - INFO - Step 3, Minibatch Loss= 0.0694, Training Accuracy= 0.975
2018-01-03 17:12:53,656 - root - INFO - Step 3, Minibatch Loss= 0.0694, Training Accuracy= 0.975
2018-01-03 17:12:53,709 : INFO : Step 3, Validation Loss= 0.2467, Validation Accuracy= 0.895
2018-01-03 17:12:53,709 - root - INFO - Step 3, Validation Loss= 0.2467, Validation Accuracy= 0.895
2018-01-03 17:12:53,709 - root - INFO - Step 3, Validation Loss= 0.2467, Validation Accuracy= 0.895
2018-01-03 17:12:53,710 : INFO : starting fold 3 in 10-fold CV
2018-01-03 17:12:53,710 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:12:53,710 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:13:00,779 : INFO : Step 1, Minibatch Loss= 0.5812, Training Accuracy= 0.715
2018-01-03 17:13:00,779 - root - INFO - Step 1, Minibatch Loss= 0.5812, Training Accuracy= 0.715
2018-01-03 17:13:00,779 - root - INFO - Step 1, Minibatch Loss= 0.5812, Training Accuracy= 0.715
2018-01-03 17:13:00,840 : INFO : Step 1, Validation Loss= 0.6913, Validation Accuracy= 0.624
2018-01-03 17:13:00,840 - root - INFO - Step 1, Validation Loss= 0.6913, Validation Accuracy= 0.624
2018-01-03 17:13:00,840 - root - INFO - Step 1, Validation Loss= 0.6913, Validation Accuracy= 0.624
2018-01-03 17:13:02,682 : INFO : Step 2, Minibatch Loss= 0.1675, Training Accuracy= 0.926
2018-01-03 17:13:02,682 - root - INFO - Step 2, Minibatch Loss= 0.1675, Training Accuracy= 0.926
2018-01-03 17:13:02,682 - root - INFO - Step 2, Minibatch Loss= 0.1675, Training Accuracy= 0.926
2018-01-03 17:13:02,737 : INFO : Step 2, Validation Loss= 0.2367, Validation Accuracy= 0.884
2018-01-03 17:13:02,737 - root - INFO - Step 2, Validation Loss= 0.2367, Validation Accuracy= 0.884
2018-01-03 17:13:02,737 - root - INFO - Step 2, Validation Loss= 0.2367, Validation Accuracy= 0.884
2018-01-03 17:13:04,624 : INFO : Step 3, Minibatch Loss= 0.0992, Training Accuracy= 0.963
2018-01-03 17:13:04,624 - root - INFO - Step 3, Minibatch Loss= 0.0992, Training Accuracy= 0.963
2018-01-03 17:13:04,624 - root - INFO - Step 3, Minibatch Loss= 0.0992, Training Accuracy= 0.963
2018-01-03 17:13:04,678 : INFO : Step 3, Validation Loss= 0.1925, Validation Accuracy= 0.918
2018-01-03 17:13:04,678 - root - INFO - Step 3, Validation Loss= 0.1925, Validation Accuracy= 0.918
2018-01-03 17:13:04,678 - root - INFO - Step 3, Validation Loss= 0.1925, Validation Accuracy= 0.918
2018-01-03 17:13:06,566 : INFO : Step 4, Minibatch Loss= 0.0601, Training Accuracy= 0.982
2018-01-03 17:13:06,566 - root - INFO - Step 4, Minibatch Loss= 0.0601, Training Accuracy= 0.982
2018-01-03 17:13:06,566 - root - INFO - Step 4, Minibatch Loss= 0.0601, Training Accuracy= 0.982
2018-01-03 17:13:06,615 : INFO : Step 4, Validation Loss= 0.2360, Validation Accuracy= 0.912
2018-01-03 17:13:06,615 - root - INFO - Step 4, Validation Loss= 0.2360, Validation Accuracy= 0.912
2018-01-03 17:13:06,615 - root - INFO - Step 4, Validation Loss= 0.2360, Validation Accuracy= 0.912
2018-01-03 17:13:06,616 : INFO : starting fold 4 in 10-fold CV
2018-01-03 17:13:06,616 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:13:06,616 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:13:13,750 : INFO : Step 1, Minibatch Loss= 0.4301, Training Accuracy= 0.814
2018-01-03 17:13:13,750 - root - INFO - Step 1, Minibatch Loss= 0.4301, Training Accuracy= 0.814
2018-01-03 17:13:13,750 - root - INFO - Step 1, Minibatch Loss= 0.4301, Training Accuracy= 0.814
2018-01-03 17:13:13,807 : INFO : Step 1, Validation Loss= 0.4334, Validation Accuracy= 0.819
2018-01-03 17:13:13,807 - root - INFO - Step 1, Validation Loss= 0.4334, Validation Accuracy= 0.819
2018-01-03 17:13:13,807 - root - INFO - Step 1, Validation Loss= 0.4334, Validation Accuracy= 0.819
2018-01-03 17:13:15,642 : INFO : Step 2, Minibatch Loss= 0.1312, Training Accuracy= 0.951
2018-01-03 17:13:15,642 - root - INFO - Step 2, Minibatch Loss= 0.1312, Training Accuracy= 0.951
2018-01-03 17:13:15,642 - root - INFO - Step 2, Minibatch Loss= 0.1312, Training Accuracy= 0.951
2018-01-03 17:13:15,694 : INFO : Step 2, Validation Loss= 0.2418, Validation Accuracy= 0.912
2018-01-03 17:13:15,694 - root - INFO - Step 2, Validation Loss= 0.2418, Validation Accuracy= 0.912
2018-01-03 17:13:15,694 - root - INFO - Step 2, Validation Loss= 0.2418, Validation Accuracy= 0.912
2018-01-03 17:13:17,553 : INFO : Step 3, Minibatch Loss= 0.0817, Training Accuracy= 0.973
2018-01-03 17:13:17,553 - root - INFO - Step 3, Minibatch Loss= 0.0817, Training Accuracy= 0.973
2018-01-03 17:13:17,553 - root - INFO - Step 3, Minibatch Loss= 0.0817, Training Accuracy= 0.973
2018-01-03 17:13:17,603 : INFO : Step 3, Validation Loss= 0.1314, Validation Accuracy= 0.957
2018-01-03 17:13:17,603 - root - INFO - Step 3, Validation Loss= 0.1314, Validation Accuracy= 0.957
2018-01-03 17:13:17,603 - root - INFO - Step 3, Validation Loss= 0.1314, Validation Accuracy= 0.957
2018-01-03 17:13:19,474 : INFO : Step 4, Minibatch Loss= 0.0539, Training Accuracy= 0.984
2018-01-03 17:13:19,474 - root - INFO - Step 4, Minibatch Loss= 0.0539, Training Accuracy= 0.984
2018-01-03 17:13:19,474 - root - INFO - Step 4, Minibatch Loss= 0.0539, Training Accuracy= 0.984
2018-01-03 17:13:19,525 : INFO : Step 4, Validation Loss= 0.1019, Validation Accuracy= 0.961
2018-01-03 17:13:19,525 - root - INFO - Step 4, Validation Loss= 0.1019, Validation Accuracy= 0.961
2018-01-03 17:13:19,525 - root - INFO - Step 4, Validation Loss= 0.1019, Validation Accuracy= 0.961
2018-01-03 17:13:21,415 : INFO : Step 5, Minibatch Loss= 0.0299, Training Accuracy= 0.992
2018-01-03 17:13:21,415 - root - INFO - Step 5, Minibatch Loss= 0.0299, Training Accuracy= 0.992
2018-01-03 17:13:21,415 - root - INFO - Step 5, Minibatch Loss= 0.0299, Training Accuracy= 0.992
2018-01-03 17:13:21,474 : INFO : Step 5, Validation Loss= 0.1934, Validation Accuracy= 0.944
2018-01-03 17:13:21,474 - root - INFO - Step 5, Validation Loss= 0.1934, Validation Accuracy= 0.944
2018-01-03 17:13:21,474 - root - INFO - Step 5, Validation Loss= 0.1934, Validation Accuracy= 0.944
2018-01-03 17:13:21,474 : INFO : starting fold 5 in 10-fold CV
2018-01-03 17:13:21,474 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:13:21,474 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:13:28,644 : INFO : Step 1, Minibatch Loss= 0.2404, Training Accuracy= 0.929
2018-01-03 17:13:28,644 - root - INFO - Step 1, Minibatch Loss= 0.2404, Training Accuracy= 0.929
2018-01-03 17:13:28,644 - root - INFO - Step 1, Minibatch Loss= 0.2404, Training Accuracy= 0.929
2018-01-03 17:13:28,708 : INFO : Step 1, Validation Loss= 0.3358, Validation Accuracy= 0.871
2018-01-03 17:13:28,708 - root - INFO - Step 1, Validation Loss= 0.3358, Validation Accuracy= 0.871
2018-01-03 17:13:28,708 - root - INFO - Step 1, Validation Loss= 0.3358, Validation Accuracy= 0.871
2018-01-03 17:13:30,681 : INFO : Step 2, Minibatch Loss= 0.1040, Training Accuracy= 0.964
2018-01-03 17:13:30,681 - root - INFO - Step 2, Minibatch Loss= 0.1040, Training Accuracy= 0.964
2018-01-03 17:13:30,681 - root - INFO - Step 2, Minibatch Loss= 0.1040, Training Accuracy= 0.964
2018-01-03 17:13:30,735 : INFO : Step 2, Validation Loss= 0.2363, Validation Accuracy= 0.923
2018-01-03 17:13:30,735 - root - INFO - Step 2, Validation Loss= 0.2363, Validation Accuracy= 0.923
2018-01-03 17:13:30,735 - root - INFO - Step 2, Validation Loss= 0.2363, Validation Accuracy= 0.923
2018-01-03 17:13:32,882 : INFO : Step 3, Minibatch Loss= 0.0641, Training Accuracy= 0.981
2018-01-03 17:13:32,882 - root - INFO - Step 3, Minibatch Loss= 0.0641, Training Accuracy= 0.981
2018-01-03 17:13:32,882 - root - INFO - Step 3, Minibatch Loss= 0.0641, Training Accuracy= 0.981
2018-01-03 17:13:32,937 : INFO : Step 3, Validation Loss= 0.2930, Validation Accuracy= 0.901
2018-01-03 17:13:32,937 - root - INFO - Step 3, Validation Loss= 0.2930, Validation Accuracy= 0.901
2018-01-03 17:13:32,937 - root - INFO - Step 3, Validation Loss= 0.2930, Validation Accuracy= 0.901
2018-01-03 17:13:32,938 : INFO : starting fold 6 in 10-fold CV
2018-01-03 17:13:32,938 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:13:32,938 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:13:40,739 : INFO : Step 1, Minibatch Loss= 0.3010, Training Accuracy= 0.906
2018-01-03 17:13:40,739 - root - INFO - Step 1, Minibatch Loss= 0.3010, Training Accuracy= 0.906
2018-01-03 17:13:40,739 - root - INFO - Step 1, Minibatch Loss= 0.3010, Training Accuracy= 0.906
2018-01-03 17:13:40,798 : INFO : Step 1, Validation Loss= 0.3198, Validation Accuracy= 0.916
2018-01-03 17:13:40,798 - root - INFO - Step 1, Validation Loss= 0.3198, Validation Accuracy= 0.916
2018-01-03 17:13:40,798 - root - INFO - Step 1, Validation Loss= 0.3198, Validation Accuracy= 0.916
2018-01-03 17:13:42,894 : INFO : Step 2, Minibatch Loss= 0.0892, Training Accuracy= 0.975
2018-01-03 17:13:42,894 - root - INFO - Step 2, Minibatch Loss= 0.0892, Training Accuracy= 0.975
2018-01-03 17:13:42,894 - root - INFO - Step 2, Minibatch Loss= 0.0892, Training Accuracy= 0.975
2018-01-03 17:13:42,945 : INFO : Step 2, Validation Loss= 0.1531, Validation Accuracy= 0.944
2018-01-03 17:13:42,945 - root - INFO - Step 2, Validation Loss= 0.1531, Validation Accuracy= 0.944
2018-01-03 17:13:42,945 - root - INFO - Step 2, Validation Loss= 0.1531, Validation Accuracy= 0.944
2018-01-03 17:13:44,818 : INFO : Step 3, Minibatch Loss= 0.0567, Training Accuracy= 0.984
2018-01-03 17:13:44,818 - root - INFO - Step 3, Minibatch Loss= 0.0567, Training Accuracy= 0.984
2018-01-03 17:13:44,818 - root - INFO - Step 3, Minibatch Loss= 0.0567, Training Accuracy= 0.984
2018-01-03 17:13:44,872 : INFO : Step 3, Validation Loss= 0.1769, Validation Accuracy= 0.940
2018-01-03 17:13:44,872 - root - INFO - Step 3, Validation Loss= 0.1769, Validation Accuracy= 0.940
2018-01-03 17:13:44,872 - root - INFO - Step 3, Validation Loss= 0.1769, Validation Accuracy= 0.940
2018-01-03 17:13:44,872 : INFO : starting fold 7 in 10-fold CV
2018-01-03 17:13:44,872 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:13:44,872 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:13:52,350 : INFO : Step 1, Minibatch Loss= 0.3551, Training Accuracy= 0.872
2018-01-03 17:13:52,350 - root - INFO - Step 1, Minibatch Loss= 0.3551, Training Accuracy= 0.872
2018-01-03 17:13:52,350 - root - INFO - Step 1, Minibatch Loss= 0.3551, Training Accuracy= 0.872
2018-01-03 17:13:52,411 : INFO : Step 1, Validation Loss= 0.4173, Validation Accuracy= 0.809
2018-01-03 17:13:52,411 - root - INFO - Step 1, Validation Loss= 0.4173, Validation Accuracy= 0.809
2018-01-03 17:13:52,411 - root - INFO - Step 1, Validation Loss= 0.4173, Validation Accuracy= 0.809
2018-01-03 17:13:54,289 : INFO : Step 2, Minibatch Loss= 0.1144, Training Accuracy= 0.962
2018-01-03 17:13:54,289 - root - INFO - Step 2, Minibatch Loss= 0.1144, Training Accuracy= 0.962
2018-01-03 17:13:54,289 - root - INFO - Step 2, Minibatch Loss= 0.1144, Training Accuracy= 0.962
2018-01-03 17:13:54,344 : INFO : Step 2, Validation Loss= 0.2311, Validation Accuracy= 0.892
2018-01-03 17:13:54,344 - root - INFO - Step 2, Validation Loss= 0.2311, Validation Accuracy= 0.892
2018-01-03 17:13:54,344 - root - INFO - Step 2, Validation Loss= 0.2311, Validation Accuracy= 0.892
2018-01-03 17:13:56,291 : INFO : Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-03 17:13:56,291 - root - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-03 17:13:56,291 - root - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-03 17:13:56,344 : INFO : Step 3, Validation Loss= 0.2188, Validation Accuracy= 0.899
2018-01-03 17:13:56,344 - root - INFO - Step 3, Validation Loss= 0.2188, Validation Accuracy= 0.899
2018-01-03 17:13:56,344 - root - INFO - Step 3, Validation Loss= 0.2188, Validation Accuracy= 0.899
2018-01-03 17:13:58,257 : INFO : Step 4, Minibatch Loss= 0.0371, Training Accuracy= 0.989
2018-01-03 17:13:58,257 - root - INFO - Step 4, Minibatch Loss= 0.0371, Training Accuracy= 0.989
2018-01-03 17:13:58,257 - root - INFO - Step 4, Minibatch Loss= 0.0371, Training Accuracy= 0.989
2018-01-03 17:13:58,309 : INFO : Step 4, Validation Loss= 0.2468, Validation Accuracy= 0.912
2018-01-03 17:13:58,309 - root - INFO - Step 4, Validation Loss= 0.2468, Validation Accuracy= 0.912
2018-01-03 17:13:58,309 - root - INFO - Step 4, Validation Loss= 0.2468, Validation Accuracy= 0.912
2018-01-03 17:14:00,115 : INFO : Step 5, Minibatch Loss= 0.0225, Training Accuracy= 0.994
2018-01-03 17:14:00,115 - root - INFO - Step 5, Minibatch Loss= 0.0225, Training Accuracy= 0.994
2018-01-03 17:14:00,115 - root - INFO - Step 5, Minibatch Loss= 0.0225, Training Accuracy= 0.994
2018-01-03 17:14:00,170 : INFO : Step 5, Validation Loss= 0.1493, Validation Accuracy= 0.938
2018-01-03 17:14:00,170 - root - INFO - Step 5, Validation Loss= 0.1493, Validation Accuracy= 0.938
2018-01-03 17:14:00,170 - root - INFO - Step 5, Validation Loss= 0.1493, Validation Accuracy= 0.938
2018-01-03 17:14:02,031 : INFO : Step 6, Minibatch Loss= 0.0208, Training Accuracy= 0.993
2018-01-03 17:14:02,031 - root - INFO - Step 6, Minibatch Loss= 0.0208, Training Accuracy= 0.993
2018-01-03 17:14:02,031 - root - INFO - Step 6, Minibatch Loss= 0.0208, Training Accuracy= 0.993
2018-01-03 17:14:02,084 : INFO : Step 6, Validation Loss= 0.1765, Validation Accuracy= 0.935
2018-01-03 17:14:02,084 - root - INFO - Step 6, Validation Loss= 0.1765, Validation Accuracy= 0.935
2018-01-03 17:14:02,084 - root - INFO - Step 6, Validation Loss= 0.1765, Validation Accuracy= 0.935
2018-01-03 17:14:02,084 : INFO : starting fold 8 in 10-fold CV
2018-01-03 17:14:02,084 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:14:02,084 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:14:09,282 : INFO : Step 1, Minibatch Loss= 0.3910, Training Accuracy= 0.865
2018-01-03 17:14:09,282 - root - INFO - Step 1, Minibatch Loss= 0.3910, Training Accuracy= 0.865
2018-01-03 17:14:09,282 - root - INFO - Step 1, Minibatch Loss= 0.3910, Training Accuracy= 0.865
2018-01-03 17:14:09,352 : INFO : Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.813
2018-01-03 17:14:09,352 - root - INFO - Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.813
2018-01-03 17:14:09,352 - root - INFO - Step 1, Validation Loss= 0.4434, Validation Accuracy= 0.813
2018-01-03 17:14:11,253 : INFO : Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.960
2018-01-03 17:14:11,253 - root - INFO - Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.960
2018-01-03 17:14:11,253 - root - INFO - Step 2, Minibatch Loss= 0.1180, Training Accuracy= 0.960
2018-01-03 17:14:11,308 : INFO : Step 2, Validation Loss= 0.2427, Validation Accuracy= 0.890
2018-01-03 17:14:11,308 - root - INFO - Step 2, Validation Loss= 0.2427, Validation Accuracy= 0.890
2018-01-03 17:14:11,308 - root - INFO - Step 2, Validation Loss= 0.2427, Validation Accuracy= 0.890
2018-01-03 17:14:13,211 : INFO : Step 3, Minibatch Loss= 0.0659, Training Accuracy= 0.979
2018-01-03 17:14:13,211 - root - INFO - Step 3, Minibatch Loss= 0.0659, Training Accuracy= 0.979
2018-01-03 17:14:13,211 - root - INFO - Step 3, Minibatch Loss= 0.0659, Training Accuracy= 0.979
2018-01-03 17:14:13,267 : INFO : Step 3, Validation Loss= 0.2073, Validation Accuracy= 0.912
2018-01-03 17:14:13,267 - root - INFO - Step 3, Validation Loss= 0.2073, Validation Accuracy= 0.912
2018-01-03 17:14:13,267 - root - INFO - Step 3, Validation Loss= 0.2073, Validation Accuracy= 0.912
2018-01-03 17:14:15,172 : INFO : Step 4, Minibatch Loss= 0.0460, Training Accuracy= 0.985
2018-01-03 17:14:15,172 - root - INFO - Step 4, Minibatch Loss= 0.0460, Training Accuracy= 0.985
2018-01-03 17:14:15,172 - root - INFO - Step 4, Minibatch Loss= 0.0460, Training Accuracy= 0.985
2018-01-03 17:14:15,224 : INFO : Step 4, Validation Loss= 0.1661, Validation Accuracy= 0.923
2018-01-03 17:14:15,224 - root - INFO - Step 4, Validation Loss= 0.1661, Validation Accuracy= 0.923
2018-01-03 17:14:15,224 - root - INFO - Step 4, Validation Loss= 0.1661, Validation Accuracy= 0.923
2018-01-03 17:14:17,128 : INFO : Step 5, Minibatch Loss= 0.0290, Training Accuracy= 0.993
2018-01-03 17:14:17,128 - root - INFO - Step 5, Minibatch Loss= 0.0290, Training Accuracy= 0.993
2018-01-03 17:14:17,128 - root - INFO - Step 5, Minibatch Loss= 0.0290, Training Accuracy= 0.993
2018-01-03 17:14:17,196 : INFO : Step 5, Validation Loss= 0.2059, Validation Accuracy= 0.918
2018-01-03 17:14:17,196 - root - INFO - Step 5, Validation Loss= 0.2059, Validation Accuracy= 0.918
2018-01-03 17:14:17,196 - root - INFO - Step 5, Validation Loss= 0.2059, Validation Accuracy= 0.918
2018-01-03 17:14:17,196 : INFO : starting fold 9 in 10-fold CV
2018-01-03 17:14:17,196 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:14:17,196 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:14:24,454 : INFO : Step 1, Minibatch Loss= 0.3556, Training Accuracy= 0.878
2018-01-03 17:14:24,454 - root - INFO - Step 1, Minibatch Loss= 0.3556, Training Accuracy= 0.878
2018-01-03 17:14:24,454 - root - INFO - Step 1, Minibatch Loss= 0.3556, Training Accuracy= 0.878
2018-01-03 17:14:24,507 : INFO : Step 1, Validation Loss= 0.4188, Validation Accuracy= 0.843
2018-01-03 17:14:24,507 - root - INFO - Step 1, Validation Loss= 0.4188, Validation Accuracy= 0.843
2018-01-03 17:14:24,507 - root - INFO - Step 1, Validation Loss= 0.4188, Validation Accuracy= 0.843
2018-01-03 17:14:26,426 : INFO : Step 2, Minibatch Loss= 0.1182, Training Accuracy= 0.960
2018-01-03 17:14:26,426 - root - INFO - Step 2, Minibatch Loss= 0.1182, Training Accuracy= 0.960
2018-01-03 17:14:26,426 - root - INFO - Step 2, Minibatch Loss= 0.1182, Training Accuracy= 0.960
2018-01-03 17:14:26,476 : INFO : Step 2, Validation Loss= 0.2990, Validation Accuracy= 0.901
2018-01-03 17:14:26,476 - root - INFO - Step 2, Validation Loss= 0.2990, Validation Accuracy= 0.901
2018-01-03 17:14:26,476 - root - INFO - Step 2, Validation Loss= 0.2990, Validation Accuracy= 0.901
2018-01-03 17:14:28,411 : INFO : Step 3, Minibatch Loss= 0.0710, Training Accuracy= 0.981
2018-01-03 17:14:28,411 - root - INFO - Step 3, Minibatch Loss= 0.0710, Training Accuracy= 0.981
2018-01-03 17:14:28,411 - root - INFO - Step 3, Minibatch Loss= 0.0710, Training Accuracy= 0.981
2018-01-03 17:14:28,462 : INFO : Step 3, Validation Loss= 0.3248, Validation Accuracy= 0.916
2018-01-03 17:14:28,462 - root - INFO - Step 3, Validation Loss= 0.3248, Validation Accuracy= 0.916
2018-01-03 17:14:28,462 - root - INFO - Step 3, Validation Loss= 0.3248, Validation Accuracy= 0.916
2018-01-03 17:14:30,342 : INFO : Step 4, Minibatch Loss= 0.0488, Training Accuracy= 0.989
2018-01-03 17:14:30,342 - root - INFO - Step 4, Minibatch Loss= 0.0488, Training Accuracy= 0.989
2018-01-03 17:14:30,342 - root - INFO - Step 4, Minibatch Loss= 0.0488, Training Accuracy= 0.989
2018-01-03 17:14:30,397 : INFO : Step 4, Validation Loss= 0.3170, Validation Accuracy= 0.912
2018-01-03 17:14:30,397 - root - INFO - Step 4, Validation Loss= 0.3170, Validation Accuracy= 0.912
2018-01-03 17:14:30,397 - root - INFO - Step 4, Validation Loss= 0.3170, Validation Accuracy= 0.912
2018-01-03 17:14:30,398 : INFO : starting fold 10 in 10-fold CV
2018-01-03 17:14:30,398 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:14:30,398 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:14:37,643 : INFO : Step 1, Minibatch Loss= 0.2584, Training Accuracy= 0.918
2018-01-03 17:14:37,643 - root - INFO - Step 1, Minibatch Loss= 0.2584, Training Accuracy= 0.918
2018-01-03 17:14:37,643 - root - INFO - Step 1, Minibatch Loss= 0.2584, Training Accuracy= 0.918
2018-01-03 17:14:37,693 : INFO : Step 1, Validation Loss= 0.3233, Validation Accuracy= 0.877
2018-01-03 17:14:37,693 - root - INFO - Step 1, Validation Loss= 0.3233, Validation Accuracy= 0.877
2018-01-03 17:14:37,693 - root - INFO - Step 1, Validation Loss= 0.3233, Validation Accuracy= 0.877
2018-01-03 17:14:39,536 : INFO : Step 2, Minibatch Loss= 0.1087, Training Accuracy= 0.962
2018-01-03 17:14:39,536 - root - INFO - Step 2, Minibatch Loss= 0.1087, Training Accuracy= 0.962
2018-01-03 17:14:39,536 - root - INFO - Step 2, Minibatch Loss= 0.1087, Training Accuracy= 0.962
2018-01-03 17:14:39,589 : INFO : Step 2, Validation Loss= 0.2435, Validation Accuracy= 0.916
2018-01-03 17:14:39,589 - root - INFO - Step 2, Validation Loss= 0.2435, Validation Accuracy= 0.916
2018-01-03 17:14:39,589 - root - INFO - Step 2, Validation Loss= 0.2435, Validation Accuracy= 0.916
2018-01-03 17:14:41,417 : INFO : Step 3, Minibatch Loss= 0.0570, Training Accuracy= 0.982
2018-01-03 17:14:41,417 - root - INFO - Step 3, Minibatch Loss= 0.0570, Training Accuracy= 0.982
2018-01-03 17:14:41,417 - root - INFO - Step 3, Minibatch Loss= 0.0570, Training Accuracy= 0.982
2018-01-03 17:14:41,472 : INFO : Step 3, Validation Loss= 0.2901, Validation Accuracy= 0.912
2018-01-03 17:14:41,472 - root - INFO - Step 3, Validation Loss= 0.2901, Validation Accuracy= 0.912
2018-01-03 17:14:41,472 - root - INFO - Step 3, Validation Loss= 0.2901, Validation Accuracy= 0.912
2018-01-03 17:14:41,473 : INFO : Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:14:41,473 - root - INFO - Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:14:41,473 - root - INFO - Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:14:41,473 : INFO : This 10-fold CV run-time: 132.94746017456055 seconds
2018-01-03 17:14:41,473 - root - INFO - This 10-fold CV run-time: 132.94746017456055 seconds
2018-01-03 17:14:41,473 - root - INFO - This 10-fold CV run-time: 132.94746017456055 seconds
2018-01-03 17:14:41,634 : INFO : Code run-time: 155.91906118392944 seconds
2018-01-03 17:14:41,634 - root - INFO - Code run-time: 155.91906118392944 seconds
2018-01-03 17:14:41,634 - root - INFO - Code run-time: 155.91906118392944 seconds
2018-01-03 17:17:10,844 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:17:10,844 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:17:10,844 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:17:10,845 : INFO : collecting all words and their counts
2018-01-03 17:17:10,845 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:17:10,845 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:17:10,845 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:17:10,845 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:17:10,845 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:17:10,879 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:17:10,879 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:17:10,879 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:17:10,879 : INFO : Loading a fresh vocabulary
2018-01-03 17:17:10,879 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:17:10,879 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:17:10,896 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:17:10,896 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:17:10,896 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:17:10,896 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:17:10,896 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:17:10,896 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:17:10,913 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:17:10,913 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:17:10,913 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:17:10,914 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:17:10,914 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:17:10,914 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:17:10,914 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:17:10,931 : INFO : resetting layer weights
2018-01-03 17:17:10,931 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:17:10,931 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:17:11,008 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,008 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,008 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,503 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,503 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,503 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,507 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,507 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,507 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,508 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,508 : INFO : training on 797984 raw words (558607 effective words) took 0.5s, 1128399 effective words/s
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1128399 effective words/s
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1128399 effective words/s
2018-01-03 17:17:11,508 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,508 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:17:11,965 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,965 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,965 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:17:11,969 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,969 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,969 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:17:11,972 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,972 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,972 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:17:11,972 : INFO : training on 797984 raw words (558138 effective words) took 0.5s, 1214461 effective words/s
2018-01-03 17:17:11,972 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1214461 effective words/s
2018-01-03 17:17:11,972 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1214461 effective words/s
2018-01-03 17:18:42,856 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:18:42,856 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:18:42,856 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:18:42,856 : INFO : collecting all words and their counts
2018-01-03 17:18:42,856 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:18:42,856 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:18:42,857 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:18:42,857 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:18:42,857 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:18:42,880 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:18:42,880 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:18:42,880 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:18:42,880 : INFO : Loading a fresh vocabulary
2018-01-03 17:18:42,880 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:18:42,880 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:18:42,900 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:18:42,900 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:18:42,900 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:18:42,900 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:18:42,900 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:18:42,900 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:18:42,921 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:18:42,921 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:18:42,921 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:18:42,921 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:18:42,921 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:18:42,921 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:18:42,922 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:18:42,922 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:18:42,922 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:18:42,922 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:18:42,922 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:18:42,922 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:18:42,937 : INFO : resetting layer weights
2018-01-03 17:18:42,937 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:18:42,937 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:18:43,020 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:43,020 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:43,020 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:43,519 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:43,519 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:43,519 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:43,522 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:43,522 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:43,522 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:43,523 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:43,523 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1122139 effective words/s
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1122139 effective words/s
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1122139 effective words/s
2018-01-03 17:18:43,523 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:43,523 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:18:44,069 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:44,069 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:44,069 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:18:44,074 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:44,074 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:44,074 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:18:44,077 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:44,077 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:44,077 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:18:44,077 : INFO : training on 797984 raw words (558758 effective words) took 0.5s, 1029443 effective words/s
2018-01-03 17:18:44,077 - gensim.models.word2vec - INFO - training on 797984 raw words (558758 effective words) took 0.5s, 1029443 effective words/s
2018-01-03 17:18:44,077 - gensim.models.word2vec - INFO - training on 797984 raw words (558758 effective words) took 0.5s, 1029443 effective words/s
2018-01-03 17:20:35,949 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:20:35,949 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:20:35,949 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:20:35,950 : INFO : collecting all words and their counts
2018-01-03 17:20:35,950 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:20:35,950 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:20:35,950 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:20:35,950 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:20:35,950 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:20:35,983 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:20:35,983 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:20:35,983 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:20:35,983 : INFO : Loading a fresh vocabulary
2018-01-03 17:20:35,983 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:20:35,983 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:20:35,999 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:20:35,999 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:20:35,999 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:20:35,999 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:20:35,999 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:20:35,999 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:20:36,021 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:20:36,021 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:20:36,021 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:20:36,022 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:20:36,022 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:20:36,022 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:20:36,022 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:20:36,036 : INFO : resetting layer weights
2018-01-03 17:20:36,036 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:20:36,036 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:20:36,113 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:36,113 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:36,113 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:36,758 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:36,758 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:36,758 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:36,760 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:36,760 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:36,760 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:36,768 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:36,768 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:36,768 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:36,768 : INFO : training on 797984 raw words (558968 effective words) took 0.7s, 858071 effective words/s
2018-01-03 17:20:36,768 - gensim.models.word2vec - INFO - training on 797984 raw words (558968 effective words) took 0.7s, 858071 effective words/s
2018-01-03 17:20:36,768 - gensim.models.word2vec - INFO - training on 797984 raw words (558968 effective words) took 0.7s, 858071 effective words/s
2018-01-03 17:20:36,769 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:36,769 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:36,769 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:20:37,376 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:37,376 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:37,376 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:20:37,379 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:37,379 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:37,379 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:20:37,383 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:37,383 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:37,383 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:20:37,383 : INFO : training on 797984 raw words (559063 effective words) took 0.6s, 916948 effective words/s
2018-01-03 17:20:37,383 - gensim.models.word2vec - INFO - training on 797984 raw words (559063 effective words) took 0.6s, 916948 effective words/s
2018-01-03 17:20:37,383 - gensim.models.word2vec - INFO - training on 797984 raw words (559063 effective words) took 0.6s, 916948 effective words/s
2018-01-03 17:20:56,305 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:20:56,305 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:20:56,305 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 17:20:56,305 : INFO : starting fold 1 in 10-fold CV
2018-01-03 17:20:56,305 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:20:56,305 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:21:05,079 : INFO : Step 1, Minibatch Loss= 0.3641, Training Accuracy= 0.875
2018-01-03 17:21:05,079 - root - INFO - Step 1, Minibatch Loss= 0.3641, Training Accuracy= 0.875
2018-01-03 17:21:05,079 - root - INFO - Step 1, Minibatch Loss= 0.3641, Training Accuracy= 0.875
2018-01-03 17:21:05,143 : INFO : Step 1, Validation Loss= 0.4698, Validation Accuracy= 0.794
2018-01-03 17:21:05,143 - root - INFO - Step 1, Validation Loss= 0.4698, Validation Accuracy= 0.794
2018-01-03 17:21:05,143 - root - INFO - Step 1, Validation Loss= 0.4698, Validation Accuracy= 0.794
2018-01-03 17:21:07,002 : INFO : Step 2, Minibatch Loss= 0.1091, Training Accuracy= 0.968
2018-01-03 17:21:07,002 - root - INFO - Step 2, Minibatch Loss= 0.1091, Training Accuracy= 0.968
2018-01-03 17:21:07,002 - root - INFO - Step 2, Minibatch Loss= 0.1091, Training Accuracy= 0.968
2018-01-03 17:21:07,065 : INFO : Step 2, Validation Loss= 0.3182, Validation Accuracy= 0.918
2018-01-03 17:21:07,065 - root - INFO - Step 2, Validation Loss= 0.3182, Validation Accuracy= 0.918
2018-01-03 17:21:07,065 - root - INFO - Step 2, Validation Loss= 0.3182, Validation Accuracy= 0.918
2018-01-03 17:21:08,999 : INFO : Step 3, Minibatch Loss= 0.0619, Training Accuracy= 0.983
2018-01-03 17:21:08,999 - root - INFO - Step 3, Minibatch Loss= 0.0619, Training Accuracy= 0.983
2018-01-03 17:21:08,999 - root - INFO - Step 3, Minibatch Loss= 0.0619, Training Accuracy= 0.983
2018-01-03 17:21:09,052 : INFO : Step 3, Validation Loss= 0.2795, Validation Accuracy= 0.918
2018-01-03 17:21:09,052 - root - INFO - Step 3, Validation Loss= 0.2795, Validation Accuracy= 0.918
2018-01-03 17:21:09,052 - root - INFO - Step 3, Validation Loss= 0.2795, Validation Accuracy= 0.918
2018-01-03 17:21:11,087 : INFO : Step 4, Minibatch Loss= 0.0477, Training Accuracy= 0.984
2018-01-03 17:21:11,087 - root - INFO - Step 4, Minibatch Loss= 0.0477, Training Accuracy= 0.984
2018-01-03 17:21:11,087 - root - INFO - Step 4, Minibatch Loss= 0.0477, Training Accuracy= 0.984
2018-01-03 17:21:11,140 : INFO : Step 4, Validation Loss= 0.3455, Validation Accuracy= 0.890
2018-01-03 17:21:11,140 - root - INFO - Step 4, Validation Loss= 0.3455, Validation Accuracy= 0.890
2018-01-03 17:21:11,140 - root - INFO - Step 4, Validation Loss= 0.3455, Validation Accuracy= 0.890
2018-01-03 17:21:11,140 : INFO : starting fold 2 in 10-fold CV
2018-01-03 17:21:11,140 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:21:11,140 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:21:18,548 : INFO : Step 1, Minibatch Loss= 0.2856, Training Accuracy= 0.925
2018-01-03 17:21:18,548 - root - INFO - Step 1, Minibatch Loss= 0.2856, Training Accuracy= 0.925
2018-01-03 17:21:18,548 - root - INFO - Step 1, Minibatch Loss= 0.2856, Training Accuracy= 0.925
2018-01-03 17:21:18,603 : INFO : Step 1, Validation Loss= 0.3847, Validation Accuracy= 0.871
2018-01-03 17:21:18,603 - root - INFO - Step 1, Validation Loss= 0.3847, Validation Accuracy= 0.871
2018-01-03 17:21:18,603 - root - INFO - Step 1, Validation Loss= 0.3847, Validation Accuracy= 0.871
2018-01-03 17:21:20,483 : INFO : Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.968
2018-01-03 17:21:20,483 - root - INFO - Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.968
2018-01-03 17:21:20,483 - root - INFO - Step 2, Minibatch Loss= 0.1072, Training Accuracy= 0.968
2018-01-03 17:21:20,544 : INFO : Step 2, Validation Loss= 0.4462, Validation Accuracy= 0.882
2018-01-03 17:21:20,544 - root - INFO - Step 2, Validation Loss= 0.4462, Validation Accuracy= 0.882
2018-01-03 17:21:20,544 - root - INFO - Step 2, Validation Loss= 0.4462, Validation Accuracy= 0.882
2018-01-03 17:21:22,379 : INFO : Step 3, Minibatch Loss= 0.0690, Training Accuracy= 0.980
2018-01-03 17:21:22,379 - root - INFO - Step 3, Minibatch Loss= 0.0690, Training Accuracy= 0.980
2018-01-03 17:21:22,379 - root - INFO - Step 3, Minibatch Loss= 0.0690, Training Accuracy= 0.980
2018-01-03 17:21:22,432 : INFO : Step 3, Validation Loss= 0.2596, Validation Accuracy= 0.925
2018-01-03 17:21:22,432 - root - INFO - Step 3, Validation Loss= 0.2596, Validation Accuracy= 0.925
2018-01-03 17:21:22,432 - root - INFO - Step 3, Validation Loss= 0.2596, Validation Accuracy= 0.925
2018-01-03 17:21:24,310 : INFO : Step 4, Minibatch Loss= 0.0370, Training Accuracy= 0.992
2018-01-03 17:21:24,310 - root - INFO - Step 4, Minibatch Loss= 0.0370, Training Accuracy= 0.992
2018-01-03 17:21:24,310 - root - INFO - Step 4, Minibatch Loss= 0.0370, Training Accuracy= 0.992
2018-01-03 17:21:24,369 : INFO : Step 4, Validation Loss= 0.2416, Validation Accuracy= 0.914
2018-01-03 17:21:24,369 - root - INFO - Step 4, Validation Loss= 0.2416, Validation Accuracy= 0.914
2018-01-03 17:21:24,369 - root - INFO - Step 4, Validation Loss= 0.2416, Validation Accuracy= 0.914
2018-01-03 17:21:24,370 : INFO : starting fold 3 in 10-fold CV
2018-01-03 17:21:24,370 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:21:24,370 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:21:31,843 : INFO : Step 1, Minibatch Loss= 0.3664, Training Accuracy= 0.879
2018-01-03 17:21:31,843 - root - INFO - Step 1, Minibatch Loss= 0.3664, Training Accuracy= 0.879
2018-01-03 17:21:31,843 - root - INFO - Step 1, Minibatch Loss= 0.3664, Training Accuracy= 0.879
2018-01-03 17:21:31,902 : INFO : Step 1, Validation Loss= 0.3651, Validation Accuracy= 0.875
2018-01-03 17:21:31,902 - root - INFO - Step 1, Validation Loss= 0.3651, Validation Accuracy= 0.875
2018-01-03 17:21:31,902 - root - INFO - Step 1, Validation Loss= 0.3651, Validation Accuracy= 0.875
2018-01-03 17:21:33,873 : INFO : Step 2, Minibatch Loss= 0.1339, Training Accuracy= 0.951
2018-01-03 17:21:33,873 - root - INFO - Step 2, Minibatch Loss= 0.1339, Training Accuracy= 0.951
2018-01-03 17:21:33,873 - root - INFO - Step 2, Minibatch Loss= 0.1339, Training Accuracy= 0.951
2018-01-03 17:21:33,927 : INFO : Step 2, Validation Loss= 0.1931, Validation Accuracy= 0.933
2018-01-03 17:21:33,927 - root - INFO - Step 2, Validation Loss= 0.1931, Validation Accuracy= 0.933
2018-01-03 17:21:33,927 - root - INFO - Step 2, Validation Loss= 0.1931, Validation Accuracy= 0.933
2018-01-03 17:21:35,872 : INFO : Step 3, Minibatch Loss= 0.0847, Training Accuracy= 0.973
2018-01-03 17:21:35,872 - root - INFO - Step 3, Minibatch Loss= 0.0847, Training Accuracy= 0.973
2018-01-03 17:21:35,872 - root - INFO - Step 3, Minibatch Loss= 0.0847, Training Accuracy= 0.973
2018-01-03 17:21:35,925 : INFO : Step 3, Validation Loss= 0.1864, Validation Accuracy= 0.923
2018-01-03 17:21:35,925 - root - INFO - Step 3, Validation Loss= 0.1864, Validation Accuracy= 0.923
2018-01-03 17:21:35,925 - root - INFO - Step 3, Validation Loss= 0.1864, Validation Accuracy= 0.923
2018-01-03 17:21:35,926 : INFO : starting fold 4 in 10-fold CV
2018-01-03 17:21:35,926 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:21:35,926 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:21:43,019 : INFO : Step 1, Minibatch Loss= 0.3160, Training Accuracy= 0.912
2018-01-03 17:21:43,019 - root - INFO - Step 1, Minibatch Loss= 0.3160, Training Accuracy= 0.912
2018-01-03 17:21:43,019 - root - INFO - Step 1, Minibatch Loss= 0.3160, Training Accuracy= 0.912
2018-01-03 17:21:43,069 : INFO : Step 1, Validation Loss= 0.3247, Validation Accuracy= 0.903
2018-01-03 17:21:43,069 - root - INFO - Step 1, Validation Loss= 0.3247, Validation Accuracy= 0.903
2018-01-03 17:21:43,069 - root - INFO - Step 1, Validation Loss= 0.3247, Validation Accuracy= 0.903
2018-01-03 17:21:47,951 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:21:47,951 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:21:47,951 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:21:47,951 : INFO : collecting all words and their counts
2018-01-03 17:21:47,951 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:21:47,951 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:21:47,952 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:21:47,952 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:21:47,952 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:21:47,974 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:21:47,974 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:21:47,974 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:21:47,974 : INFO : Loading a fresh vocabulary
2018-01-03 17:21:47,974 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:21:47,974 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:21:47,988 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:21:47,988 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:21:47,988 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:21:47,989 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:21:47,989 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:21:47,989 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:21:48,008 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:21:48,008 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:21:48,008 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:21:48,009 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:21:48,009 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:21:48,009 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:21:48,009 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:21:48,025 : INFO : resetting layer weights
2018-01-03 17:21:48,025 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:21:48,025 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:21:48,104 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:48,104 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:48,104 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:48,589 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:48,589 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:48,589 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:48,591 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:48,591 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:48,591 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:48,595 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:48,595 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:48,595 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:48,596 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1145930 effective words/s
2018-01-03 17:21:48,596 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1145930 effective words/s
2018-01-03 17:21:48,596 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1145930 effective words/s
2018-01-03 17:21:48,596 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:48,596 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:48,596 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:21:49,069 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:49,069 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:49,069 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:21:49,073 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:49,073 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:49,073 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:21:49,074 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:49,074 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:49,074 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:21:49,074 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1192377 effective words/s
2018-01-03 17:21:49,074 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1192377 effective words/s
2018-01-03 17:21:49,074 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1192377 effective words/s
2018-01-03 17:22:06,207 : INFO : {}
2018-01-03 17:22:06,207 - root - INFO - {}
2018-01-03 17:22:06,207 - root - INFO - {}
2018-01-03 17:22:06,208 : INFO : Code run-time: 0.0006120204925537109 seconds
2018-01-03 17:22:06,208 - root - INFO - Code run-time: 0.0006120204925537109 seconds
2018-01-03 17:22:06,208 - root - INFO - Code run-time: 0.0006120204925537109 seconds
2018-01-03 17:22:16,032 : INFO : {}
2018-01-03 17:22:16,032 - root - INFO - {}
2018-01-03 17:22:16,032 - root - INFO - {}
2018-01-03 17:22:16,033 : INFO : Code run-time: 0.001828908920288086 seconds
2018-01-03 17:22:16,033 - root - INFO - Code run-time: 0.001828908920288086 seconds
2018-01-03 17:22:16,033 - root - INFO - Code run-time: 0.001828908920288086 seconds
2018-01-03 17:22:21,564 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:22:21,564 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:22:21,564 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:22:21,565 : INFO : collecting all words and their counts
2018-01-03 17:22:21,565 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:22:21,565 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:22:21,565 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:22:21,565 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:22:21,565 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:22:21,601 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:22:21,601 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:22:21,601 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:22:21,601 : INFO : Loading a fresh vocabulary
2018-01-03 17:22:21,601 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:22:21,601 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:22:21,617 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:22:21,617 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:22:21,617 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:22:21,617 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:22:21,617 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:22:21,617 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:22:21,634 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:22:21,634 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:22:21,634 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:22:21,635 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:22:21,635 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:22:21,635 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:22:21,635 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:22:21,648 : INFO : resetting layer weights
2018-01-03 17:22:21,648 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:22:21,648 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:22:21,728 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:21,728 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:21,728 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:22,176 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,181 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,186 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,186 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,186 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,187 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1229246 effective words/s
2018-01-03 17:22:22,187 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1229246 effective words/s
2018-01-03 17:22:22,187 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1229246 effective words/s
2018-01-03 17:22:22,187 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:22,187 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:22,187 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:22:22,642 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,642 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:22:22,648 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,648 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:22:22,650 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,650 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,650 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:22:22,650 : INFO : training on 797984 raw words (558138 effective words) took 0.5s, 1217090 effective words/s
2018-01-03 17:22:22,650 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1217090 effective words/s
2018-01-03 17:22:22,650 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1217090 effective words/s
2018-01-03 17:22:41,812 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:22:41,812 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:22:41,812 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:22:41,815 : INFO : starting fold 1 in 10-fold CV
2018-01-03 17:22:41,815 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:22:41,815 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:22:51,301 : INFO : Step 1, Minibatch Loss= 0.3401, Training Accuracy= 0.881
2018-01-03 17:22:51,301 - root - INFO - Step 1, Minibatch Loss= 0.3401, Training Accuracy= 0.881
2018-01-03 17:22:51,301 - root - INFO - Step 1, Minibatch Loss= 0.3401, Training Accuracy= 0.881
2018-01-03 17:22:51,377 : INFO : Step 1, Validation Loss= 0.5616, Validation Accuracy= 0.718
2018-01-03 17:22:51,377 - root - INFO - Step 1, Validation Loss= 0.5616, Validation Accuracy= 0.718
2018-01-03 17:22:51,377 - root - INFO - Step 1, Validation Loss= 0.5616, Validation Accuracy= 0.718
2018-01-03 17:22:53,739 : INFO : Step 2, Minibatch Loss= 0.1088, Training Accuracy= 0.967
2018-01-03 17:22:53,739 - root - INFO - Step 2, Minibatch Loss= 0.1088, Training Accuracy= 0.967
2018-01-03 17:22:53,739 - root - INFO - Step 2, Minibatch Loss= 0.1088, Training Accuracy= 0.967
2018-01-03 17:22:53,810 : INFO : Step 2, Validation Loss= 0.2879, Validation Accuracy= 0.897
2018-01-03 17:22:53,810 - root - INFO - Step 2, Validation Loss= 0.2879, Validation Accuracy= 0.897
2018-01-03 17:22:53,810 - root - INFO - Step 2, Validation Loss= 0.2879, Validation Accuracy= 0.897
2018-01-03 17:22:56,189 : INFO : Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.981
2018-01-03 17:22:56,189 - root - INFO - Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.981
2018-01-03 17:22:56,189 - root - INFO - Step 3, Minibatch Loss= 0.0645, Training Accuracy= 0.981
2018-01-03 17:22:56,262 : INFO : Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.914
2018-01-03 17:22:56,262 - root - INFO - Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.914
2018-01-03 17:22:56,262 - root - INFO - Step 3, Validation Loss= 0.1884, Validation Accuracy= 0.914
2018-01-03 17:22:58,537 : INFO : Step 4, Minibatch Loss= 0.0308, Training Accuracy= 0.991
2018-01-03 17:22:58,537 - root - INFO - Step 4, Minibatch Loss= 0.0308, Training Accuracy= 0.991
2018-01-03 17:22:58,537 - root - INFO - Step 4, Minibatch Loss= 0.0308, Training Accuracy= 0.991
2018-01-03 17:22:58,607 : INFO : Step 4, Validation Loss= 0.3101, Validation Accuracy= 0.892
2018-01-03 17:22:58,607 - root - INFO - Step 4, Validation Loss= 0.3101, Validation Accuracy= 0.892
2018-01-03 17:22:58,607 - root - INFO - Step 4, Validation Loss= 0.3101, Validation Accuracy= 0.892
2018-01-03 17:22:58,608 : INFO : starting fold 2 in 10-fold CV
2018-01-03 17:22:58,608 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:22:58,608 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:23:06,422 : INFO : Step 1, Minibatch Loss= 0.3083, Training Accuracy= 0.903
2018-01-03 17:23:06,422 - root - INFO - Step 1, Minibatch Loss= 0.3083, Training Accuracy= 0.903
2018-01-03 17:23:06,422 - root - INFO - Step 1, Minibatch Loss= 0.3083, Training Accuracy= 0.903
2018-01-03 17:23:06,498 : INFO : Step 1, Validation Loss= 0.3765, Validation Accuracy= 0.862
2018-01-03 17:23:06,498 - root - INFO - Step 1, Validation Loss= 0.3765, Validation Accuracy= 0.862
2018-01-03 17:23:06,498 - root - INFO - Step 1, Validation Loss= 0.3765, Validation Accuracy= 0.862
2018-01-03 17:23:08,762 : INFO : Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.971
2018-01-03 17:23:08,762 - root - INFO - Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.971
2018-01-03 17:23:08,762 - root - INFO - Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.971
2018-01-03 17:23:08,830 : INFO : Step 2, Validation Loss= 0.2530, Validation Accuracy= 0.903
2018-01-03 17:23:08,830 - root - INFO - Step 2, Validation Loss= 0.2530, Validation Accuracy= 0.903
2018-01-03 17:23:08,830 - root - INFO - Step 2, Validation Loss= 0.2530, Validation Accuracy= 0.903
2018-01-03 17:23:11,145 : INFO : Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.985
2018-01-03 17:23:11,145 - root - INFO - Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.985
2018-01-03 17:23:11,145 - root - INFO - Step 3, Minibatch Loss= 0.0474, Training Accuracy= 0.985
2018-01-03 17:23:11,219 : INFO : Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.923
2018-01-03 17:23:11,219 - root - INFO - Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.923
2018-01-03 17:23:11,219 - root - INFO - Step 3, Validation Loss= 0.2006, Validation Accuracy= 0.923
2018-01-03 17:23:13,547 : INFO : Step 4, Minibatch Loss= 0.0325, Training Accuracy= 0.988
2018-01-03 17:23:13,547 - root - INFO - Step 4, Minibatch Loss= 0.0325, Training Accuracy= 0.988
2018-01-03 17:23:13,547 - root - INFO - Step 4, Minibatch Loss= 0.0325, Training Accuracy= 0.988
2018-01-03 17:23:13,628 : INFO : Step 4, Validation Loss= 0.2177, Validation Accuracy= 0.938
2018-01-03 17:23:13,628 - root - INFO - Step 4, Validation Loss= 0.2177, Validation Accuracy= 0.938
2018-01-03 17:23:13,628 - root - INFO - Step 4, Validation Loss= 0.2177, Validation Accuracy= 0.938
2018-01-03 17:23:15,896 : INFO : Step 5, Minibatch Loss= 0.0194, Training Accuracy= 0.995
2018-01-03 17:23:15,896 - root - INFO - Step 5, Minibatch Loss= 0.0194, Training Accuracy= 0.995
2018-01-03 17:23:15,896 - root - INFO - Step 5, Minibatch Loss= 0.0194, Training Accuracy= 0.995
2018-01-03 17:23:15,963 : INFO : Step 5, Validation Loss= 0.2453, Validation Accuracy= 0.940
2018-01-03 17:23:15,963 - root - INFO - Step 5, Validation Loss= 0.2453, Validation Accuracy= 0.940
2018-01-03 17:23:15,963 - root - INFO - Step 5, Validation Loss= 0.2453, Validation Accuracy= 0.940
2018-01-03 17:23:18,291 : INFO : Step 6, Minibatch Loss= 0.0084, Training Accuracy= 0.999
2018-01-03 17:23:18,291 - root - INFO - Step 6, Minibatch Loss= 0.0084, Training Accuracy= 0.999
2018-01-03 17:23:18,291 - root - INFO - Step 6, Minibatch Loss= 0.0084, Training Accuracy= 0.999
2018-01-03 17:23:18,355 : INFO : Step 6, Validation Loss= 0.3889, Validation Accuracy= 0.912
2018-01-03 17:23:18,355 - root - INFO - Step 6, Validation Loss= 0.3889, Validation Accuracy= 0.912
2018-01-03 17:23:18,355 - root - INFO - Step 6, Validation Loss= 0.3889, Validation Accuracy= 0.912
2018-01-03 17:23:18,356 : INFO : starting fold 3 in 10-fold CV
2018-01-03 17:23:18,356 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:23:18,356 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:23:25,579 : INFO : Step 1, Minibatch Loss= 0.3929, Training Accuracy= 0.838
2018-01-03 17:23:25,579 - root - INFO - Step 1, Minibatch Loss= 0.3929, Training Accuracy= 0.838
2018-01-03 17:23:25,579 - root - INFO - Step 1, Minibatch Loss= 0.3929, Training Accuracy= 0.838
2018-01-03 17:23:25,645 : INFO : Step 1, Validation Loss= 0.3808, Validation Accuracy= 0.847
2018-01-03 17:23:25,645 - root - INFO - Step 1, Validation Loss= 0.3808, Validation Accuracy= 0.847
2018-01-03 17:23:25,645 - root - INFO - Step 1, Validation Loss= 0.3808, Validation Accuracy= 0.847
2018-01-03 17:23:27,981 : INFO : Step 2, Minibatch Loss= 0.0943, Training Accuracy= 0.968
2018-01-03 17:23:27,981 - root - INFO - Step 2, Minibatch Loss= 0.0943, Training Accuracy= 0.968
2018-01-03 17:23:27,981 - root - INFO - Step 2, Minibatch Loss= 0.0943, Training Accuracy= 0.968
2018-01-03 17:23:28,050 : INFO : Step 2, Validation Loss= 0.1787, Validation Accuracy= 0.951
2018-01-03 17:23:28,050 - root - INFO - Step 2, Validation Loss= 0.1787, Validation Accuracy= 0.951
2018-01-03 17:23:28,050 - root - INFO - Step 2, Validation Loss= 0.1787, Validation Accuracy= 0.951
2018-01-03 17:23:30,316 : INFO : Step 3, Minibatch Loss= 0.0753, Training Accuracy= 0.973
2018-01-03 17:23:30,316 - root - INFO - Step 3, Minibatch Loss= 0.0753, Training Accuracy= 0.973
2018-01-03 17:23:30,316 - root - INFO - Step 3, Minibatch Loss= 0.0753, Training Accuracy= 0.973
2018-01-03 17:23:30,386 : INFO : Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.892
2018-01-03 17:23:30,386 - root - INFO - Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.892
2018-01-03 17:23:30,386 - root - INFO - Step 3, Validation Loss= 0.2580, Validation Accuracy= 0.892
2018-01-03 17:23:30,387 : INFO : starting fold 4 in 10-fold CV
2018-01-03 17:23:30,387 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:23:30,387 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:23:38,040 : INFO : Step 1, Minibatch Loss= 0.4259, Training Accuracy= 0.803
2018-01-03 17:23:38,040 - root - INFO - Step 1, Minibatch Loss= 0.4259, Training Accuracy= 0.803
2018-01-03 17:23:38,040 - root - INFO - Step 1, Minibatch Loss= 0.4259, Training Accuracy= 0.803
2018-01-03 17:23:38,115 : INFO : Step 1, Validation Loss= 0.4362, Validation Accuracy= 0.791
2018-01-03 17:23:38,115 - root - INFO - Step 1, Validation Loss= 0.4362, Validation Accuracy= 0.791
2018-01-03 17:23:38,115 - root - INFO - Step 1, Validation Loss= 0.4362, Validation Accuracy= 0.791
2018-01-03 17:23:40,493 : INFO : Step 2, Minibatch Loss= 0.1365, Training Accuracy= 0.949
2018-01-03 17:23:40,493 - root - INFO - Step 2, Minibatch Loss= 0.1365, Training Accuracy= 0.949
2018-01-03 17:23:40,493 - root - INFO - Step 2, Minibatch Loss= 0.1365, Training Accuracy= 0.949
2018-01-03 17:23:40,561 : INFO : Step 2, Validation Loss= 0.1443, Validation Accuracy= 0.946
2018-01-03 17:23:40,561 - root - INFO - Step 2, Validation Loss= 0.1443, Validation Accuracy= 0.946
2018-01-03 17:23:40,561 - root - INFO - Step 2, Validation Loss= 0.1443, Validation Accuracy= 0.946
2018-01-03 17:23:42,903 : INFO : Step 3, Minibatch Loss= 0.0834, Training Accuracy= 0.968
2018-01-03 17:23:42,903 - root - INFO - Step 3, Minibatch Loss= 0.0834, Training Accuracy= 0.968
2018-01-03 17:23:42,903 - root - INFO - Step 3, Minibatch Loss= 0.0834, Training Accuracy= 0.968
2018-01-03 17:23:42,969 : INFO : Step 3, Validation Loss= 0.2000, Validation Accuracy= 0.914
2018-01-03 17:23:42,969 - root - INFO - Step 3, Validation Loss= 0.2000, Validation Accuracy= 0.914
2018-01-03 17:23:42,969 - root - INFO - Step 3, Validation Loss= 0.2000, Validation Accuracy= 0.914
2018-01-03 17:23:42,969 : INFO : starting fold 5 in 10-fold CV
2018-01-03 17:23:42,969 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:23:42,969 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:23:50,644 : INFO : Step 1, Minibatch Loss= 0.2179, Training Accuracy= 0.936
2018-01-03 17:23:50,644 - root - INFO - Step 1, Minibatch Loss= 0.2179, Training Accuracy= 0.936
2018-01-03 17:23:50,644 - root - INFO - Step 1, Minibatch Loss= 0.2179, Training Accuracy= 0.936
2018-01-03 17:23:50,718 : INFO : Step 1, Validation Loss= 0.2810, Validation Accuracy= 0.897
2018-01-03 17:23:50,718 - root - INFO - Step 1, Validation Loss= 0.2810, Validation Accuracy= 0.897
2018-01-03 17:23:50,718 - root - INFO - Step 1, Validation Loss= 0.2810, Validation Accuracy= 0.897
2018-01-03 17:23:52,960 : INFO : Step 2, Minibatch Loss= 0.0855, Training Accuracy= 0.972
2018-01-03 17:23:52,960 - root - INFO - Step 2, Minibatch Loss= 0.0855, Training Accuracy= 0.972
2018-01-03 17:23:52,960 - root - INFO - Step 2, Minibatch Loss= 0.0855, Training Accuracy= 0.972
2018-01-03 17:23:53,025 : INFO : Step 2, Validation Loss= 0.3203, Validation Accuracy= 0.918
2018-01-03 17:23:53,025 - root - INFO - Step 2, Validation Loss= 0.3203, Validation Accuracy= 0.918
2018-01-03 17:23:53,025 - root - INFO - Step 2, Validation Loss= 0.3203, Validation Accuracy= 0.918
2018-01-03 17:23:55,284 : INFO : Step 3, Minibatch Loss= 0.0558, Training Accuracy= 0.985
2018-01-03 17:23:55,284 - root - INFO - Step 3, Minibatch Loss= 0.0558, Training Accuracy= 0.985
2018-01-03 17:23:55,284 - root - INFO - Step 3, Minibatch Loss= 0.0558, Training Accuracy= 0.985
2018-01-03 17:23:55,355 : INFO : Step 3, Validation Loss= 0.2813, Validation Accuracy= 0.880
2018-01-03 17:23:55,355 - root - INFO - Step 3, Validation Loss= 0.2813, Validation Accuracy= 0.880
2018-01-03 17:23:55,355 - root - INFO - Step 3, Validation Loss= 0.2813, Validation Accuracy= 0.880
2018-01-03 17:23:55,355 : INFO : starting fold 6 in 10-fold CV
2018-01-03 17:23:55,355 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:23:55,355 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:24:03,171 : INFO : Step 1, Minibatch Loss= 0.3107, Training Accuracy= 0.894
2018-01-03 17:24:03,171 - root - INFO - Step 1, Minibatch Loss= 0.3107, Training Accuracy= 0.894
2018-01-03 17:24:03,171 - root - INFO - Step 1, Minibatch Loss= 0.3107, Training Accuracy= 0.894
2018-01-03 17:24:03,243 : INFO : Step 1, Validation Loss= 0.3243, Validation Accuracy= 0.888
2018-01-03 17:24:03,243 - root - INFO - Step 1, Validation Loss= 0.3243, Validation Accuracy= 0.888
2018-01-03 17:24:03,243 - root - INFO - Step 1, Validation Loss= 0.3243, Validation Accuracy= 0.888
2018-01-03 17:24:05,693 : INFO : Step 2, Minibatch Loss= 0.1173, Training Accuracy= 0.965
2018-01-03 17:24:05,693 - root - INFO - Step 2, Minibatch Loss= 0.1173, Training Accuracy= 0.965
2018-01-03 17:24:05,693 - root - INFO - Step 2, Minibatch Loss= 0.1173, Training Accuracy= 0.965
2018-01-03 17:24:05,764 : INFO : Step 2, Validation Loss= 0.1750, Validation Accuracy= 0.929
2018-01-03 17:24:05,764 - root - INFO - Step 2, Validation Loss= 0.1750, Validation Accuracy= 0.929
2018-01-03 17:24:05,764 - root - INFO - Step 2, Validation Loss= 0.1750, Validation Accuracy= 0.929
2018-01-03 17:24:08,426 : INFO : Step 3, Minibatch Loss= 0.0534, Training Accuracy= 0.986
2018-01-03 17:24:08,426 - root - INFO - Step 3, Minibatch Loss= 0.0534, Training Accuracy= 0.986
2018-01-03 17:24:08,426 - root - INFO - Step 3, Minibatch Loss= 0.0534, Training Accuracy= 0.986
2018-01-03 17:24:08,500 : INFO : Step 3, Validation Loss= 0.2025, Validation Accuracy= 0.931
2018-01-03 17:24:08,500 - root - INFO - Step 3, Validation Loss= 0.2025, Validation Accuracy= 0.931
2018-01-03 17:24:08,500 - root - INFO - Step 3, Validation Loss= 0.2025, Validation Accuracy= 0.931
2018-01-03 17:24:10,959 : INFO : Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.988
2018-01-03 17:24:10,959 - root - INFO - Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.988
2018-01-03 17:24:10,959 - root - INFO - Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.988
2018-01-03 17:24:11,021 : INFO : Step 4, Validation Loss= 0.3136, Validation Accuracy= 0.903
2018-01-03 17:24:11,021 - root - INFO - Step 4, Validation Loss= 0.3136, Validation Accuracy= 0.903
2018-01-03 17:24:11,021 - root - INFO - Step 4, Validation Loss= 0.3136, Validation Accuracy= 0.903
2018-01-03 17:24:11,021 : INFO : starting fold 7 in 10-fold CV
2018-01-03 17:24:11,021 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:24:11,021 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:24:18,327 : INFO : Step 1, Minibatch Loss= 0.1688, Training Accuracy= 0.940
2018-01-03 17:24:18,327 - root - INFO - Step 1, Minibatch Loss= 0.1688, Training Accuracy= 0.940
2018-01-03 17:24:18,327 - root - INFO - Step 1, Minibatch Loss= 0.1688, Training Accuracy= 0.940
2018-01-03 17:24:18,404 : INFO : Step 1, Validation Loss= 0.2798, Validation Accuracy= 0.880
2018-01-03 17:24:18,404 - root - INFO - Step 1, Validation Loss= 0.2798, Validation Accuracy= 0.880
2018-01-03 17:24:18,404 - root - INFO - Step 1, Validation Loss= 0.2798, Validation Accuracy= 0.880
2018-01-03 17:24:20,803 : INFO : Step 2, Minibatch Loss= 0.0726, Training Accuracy= 0.980
2018-01-03 17:24:20,803 - root - INFO - Step 2, Minibatch Loss= 0.0726, Training Accuracy= 0.980
2018-01-03 17:24:20,803 - root - INFO - Step 2, Minibatch Loss= 0.0726, Training Accuracy= 0.980
2018-01-03 17:24:20,876 : INFO : Step 2, Validation Loss= 0.1542, Validation Accuracy= 0.946
2018-01-03 17:24:20,876 - root - INFO - Step 2, Validation Loss= 0.1542, Validation Accuracy= 0.946
2018-01-03 17:24:20,876 - root - INFO - Step 2, Validation Loss= 0.1542, Validation Accuracy= 0.946
2018-01-03 17:24:23,192 : INFO : Step 3, Minibatch Loss= 0.0428, Training Accuracy= 0.987
2018-01-03 17:24:23,192 - root - INFO - Step 3, Minibatch Loss= 0.0428, Training Accuracy= 0.987
2018-01-03 17:24:23,192 - root - INFO - Step 3, Minibatch Loss= 0.0428, Training Accuracy= 0.987
2018-01-03 17:24:23,257 : INFO : Step 3, Validation Loss= 0.1703, Validation Accuracy= 0.935
2018-01-03 17:24:23,257 - root - INFO - Step 3, Validation Loss= 0.1703, Validation Accuracy= 0.935
2018-01-03 17:24:23,257 - root - INFO - Step 3, Validation Loss= 0.1703, Validation Accuracy= 0.935
2018-01-03 17:24:23,258 : INFO : starting fold 8 in 10-fold CV
2018-01-03 17:24:23,258 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:24:23,258 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:24:31,003 : INFO : Step 1, Minibatch Loss= 0.2364, Training Accuracy= 0.919
2018-01-03 17:24:31,003 - root - INFO - Step 1, Minibatch Loss= 0.2364, Training Accuracy= 0.919
2018-01-03 17:24:31,003 - root - INFO - Step 1, Minibatch Loss= 0.2364, Training Accuracy= 0.919
2018-01-03 17:24:31,077 : INFO : Step 1, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 17:24:31,077 - root - INFO - Step 1, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 17:24:31,077 - root - INFO - Step 1, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 17:24:33,372 : INFO : Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.968
2018-01-03 17:24:33,372 - root - INFO - Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.968
2018-01-03 17:24:33,372 - root - INFO - Step 2, Minibatch Loss= 0.0944, Training Accuracy= 0.968
2018-01-03 17:24:33,449 : INFO : Step 2, Validation Loss= 0.2033, Validation Accuracy= 0.920
2018-01-03 17:24:33,449 - root - INFO - Step 2, Validation Loss= 0.2033, Validation Accuracy= 0.920
2018-01-03 17:24:33,449 - root - INFO - Step 2, Validation Loss= 0.2033, Validation Accuracy= 0.920
2018-01-03 17:24:35,699 : INFO : Step 3, Minibatch Loss= 0.0458, Training Accuracy= 0.984
2018-01-03 17:24:35,699 - root - INFO - Step 3, Minibatch Loss= 0.0458, Training Accuracy= 0.984
2018-01-03 17:24:35,699 - root - INFO - Step 3, Minibatch Loss= 0.0458, Training Accuracy= 0.984
2018-01-03 17:24:35,770 : INFO : Step 3, Validation Loss= 0.2007, Validation Accuracy= 0.920
2018-01-03 17:24:35,770 - root - INFO - Step 3, Validation Loss= 0.2007, Validation Accuracy= 0.920
2018-01-03 17:24:35,770 - root - INFO - Step 3, Validation Loss= 0.2007, Validation Accuracy= 0.920
2018-01-03 17:24:38,143 : INFO : Step 4, Minibatch Loss= 0.0306, Training Accuracy= 0.991
2018-01-03 17:24:38,143 - root - INFO - Step 4, Minibatch Loss= 0.0306, Training Accuracy= 0.991
2018-01-03 17:24:38,143 - root - INFO - Step 4, Minibatch Loss= 0.0306, Training Accuracy= 0.991
2018-01-03 17:24:38,234 : INFO : Step 4, Validation Loss= 0.2268, Validation Accuracy= 0.910
2018-01-03 17:24:38,234 - root - INFO - Step 4, Validation Loss= 0.2268, Validation Accuracy= 0.910
2018-01-03 17:24:38,234 - root - INFO - Step 4, Validation Loss= 0.2268, Validation Accuracy= 0.910
2018-01-03 17:24:38,235 : INFO : starting fold 9 in 10-fold CV
2018-01-03 17:24:38,235 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:24:38,235 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:24:46,032 : INFO : Step 1, Minibatch Loss= 0.1866, Training Accuracy= 0.934
2018-01-03 17:24:46,032 - root - INFO - Step 1, Minibatch Loss= 0.1866, Training Accuracy= 0.934
2018-01-03 17:24:46,032 - root - INFO - Step 1, Minibatch Loss= 0.1866, Training Accuracy= 0.934
2018-01-03 17:24:46,111 : INFO : Step 1, Validation Loss= 0.2987, Validation Accuracy= 0.903
2018-01-03 17:24:46,111 - root - INFO - Step 1, Validation Loss= 0.2987, Validation Accuracy= 0.903
2018-01-03 17:24:46,111 - root - INFO - Step 1, Validation Loss= 0.2987, Validation Accuracy= 0.903
2018-01-03 17:24:48,408 : INFO : Step 2, Minibatch Loss= 0.0817, Training Accuracy= 0.971
2018-01-03 17:24:48,408 - root - INFO - Step 2, Minibatch Loss= 0.0817, Training Accuracy= 0.971
2018-01-03 17:24:48,408 - root - INFO - Step 2, Minibatch Loss= 0.0817, Training Accuracy= 0.971
2018-01-03 17:24:48,471 : INFO : Step 2, Validation Loss= 0.1562, Validation Accuracy= 0.938
2018-01-03 17:24:48,471 - root - INFO - Step 2, Validation Loss= 0.1562, Validation Accuracy= 0.938
2018-01-03 17:24:48,471 - root - INFO - Step 2, Validation Loss= 0.1562, Validation Accuracy= 0.938
2018-01-03 17:24:50,783 : INFO : Step 3, Minibatch Loss= 0.0573, Training Accuracy= 0.983
2018-01-03 17:24:50,783 - root - INFO - Step 3, Minibatch Loss= 0.0573, Training Accuracy= 0.983
2018-01-03 17:24:50,783 - root - INFO - Step 3, Minibatch Loss= 0.0573, Training Accuracy= 0.983
2018-01-03 17:24:50,846 : INFO : Step 3, Validation Loss= 0.2174, Validation Accuracy= 0.938
2018-01-03 17:24:50,846 - root - INFO - Step 3, Validation Loss= 0.2174, Validation Accuracy= 0.938
2018-01-03 17:24:50,846 - root - INFO - Step 3, Validation Loss= 0.2174, Validation Accuracy= 0.938
2018-01-03 17:24:50,847 : INFO : starting fold 10 in 10-fold CV
2018-01-03 17:24:50,847 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:24:50,847 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:24:58,164 : INFO : Step 1, Minibatch Loss= 0.3582, Training Accuracy= 0.864
2018-01-03 17:24:58,164 - root - INFO - Step 1, Minibatch Loss= 0.3582, Training Accuracy= 0.864
2018-01-03 17:24:58,164 - root - INFO - Step 1, Minibatch Loss= 0.3582, Training Accuracy= 0.864
2018-01-03 17:24:58,237 : INFO : Step 1, Validation Loss= 0.4941, Validation Accuracy= 0.770
2018-01-03 17:24:58,237 - root - INFO - Step 1, Validation Loss= 0.4941, Validation Accuracy= 0.770
2018-01-03 17:24:58,237 - root - INFO - Step 1, Validation Loss= 0.4941, Validation Accuracy= 0.770
2018-01-03 17:25:00,637 : INFO : Step 2, Minibatch Loss= 0.1220, Training Accuracy= 0.952
2018-01-03 17:25:00,637 - root - INFO - Step 2, Minibatch Loss= 0.1220, Training Accuracy= 0.952
2018-01-03 17:25:00,637 - root - INFO - Step 2, Minibatch Loss= 0.1220, Training Accuracy= 0.952
2018-01-03 17:25:00,705 : INFO : Step 2, Validation Loss= 0.3114, Validation Accuracy= 0.890
2018-01-03 17:25:00,705 - root - INFO - Step 2, Validation Loss= 0.3114, Validation Accuracy= 0.890
2018-01-03 17:25:00,705 - root - INFO - Step 2, Validation Loss= 0.3114, Validation Accuracy= 0.890
2018-01-03 17:25:03,157 : INFO : Step 3, Minibatch Loss= 0.0790, Training Accuracy= 0.973
2018-01-03 17:25:03,157 - root - INFO - Step 3, Minibatch Loss= 0.0790, Training Accuracy= 0.973
2018-01-03 17:25:03,157 - root - INFO - Step 3, Minibatch Loss= 0.0790, Training Accuracy= 0.973
2018-01-03 17:25:03,221 : INFO : Step 3, Validation Loss= 0.4613, Validation Accuracy= 0.873
2018-01-03 17:25:03,221 - root - INFO - Step 3, Validation Loss= 0.4613, Validation Accuracy= 0.873
2018-01-03 17:25:03,221 - root - INFO - Step 3, Validation Loss= 0.4613, Validation Accuracy= 0.873
2018-01-03 17:25:03,222 : INFO : Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:25:03,222 - root - INFO - Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:25:03,222 - root - INFO - Average accuracy is 0.929462 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:25:03,222 : INFO : This 10-fold CV run-time: 141.4095070362091 seconds
2018-01-03 17:25:03,222 - root - INFO - This 10-fold CV run-time: 141.4095070362091 seconds
2018-01-03 17:25:03,222 - root - INFO - This 10-fold CV run-time: 141.4095070362091 seconds
2018-01-03 17:25:03,377 : INFO : current best: accuracy=0.929462, num_hidden=20, dropout=0.0
2018-01-03 17:25:03,377 - root - INFO - current best: accuracy=0.929462, num_hidden=20, dropout=0.0
2018-01-03 17:25:03,377 - root - INFO - current best: accuracy=0.929462, num_hidden=20, dropout=0.0
2018-01-03 17:25:03,377 : INFO : {(20, 0.0): 0.92946231}
2018-01-03 17:25:03,377 - root - INFO - {(20, 0.0): 0.92946231}
2018-01-03 17:25:03,377 - root - INFO - {(20, 0.0): 0.92946231}
2018-01-03 17:25:03,378 : INFO : Code run-time: 162.3116490840912 seconds
2018-01-03 17:25:03,378 - root - INFO - Code run-time: 162.3116490840912 seconds
2018-01-03 17:25:03,378 - root - INFO - Code run-time: 162.3116490840912 seconds
2018-01-03 17:26:37,328 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:26:37,328 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:26:37,328 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:26:37,328 : INFO : collecting all words and their counts
2018-01-03 17:26:37,328 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:26:37,328 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:26:37,329 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:26:37,329 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:26:37,329 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:26:37,358 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:26:37,358 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:26:37,358 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:26:37,358 : INFO : Loading a fresh vocabulary
2018-01-03 17:26:37,358 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:26:37,358 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:26:37,374 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:26:37,374 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:26:37,374 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:26:37,374 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:26:37,374 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:26:37,374 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:26:37,391 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:26:37,391 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:26:37,391 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:26:37,392 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:26:37,392 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:26:37,392 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:26:37,392 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:26:37,404 : INFO : resetting layer weights
2018-01-03 17:26:37,404 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:26:37,404 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:26:37,478 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:37,478 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:37,478 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:37,940 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:37,940 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:37,940 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:37,944 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:37,944 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:37,944 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:37,947 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:37,947 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1201807 effective words/s
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1201807 effective words/s
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1201807 effective words/s
2018-01-03 17:26:37,947 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:37,947 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:26:38,411 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:38,411 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:38,411 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:26:38,413 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:38,413 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:38,413 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:26:38,419 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:38,419 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:38,419 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:26:38,419 : INFO : training on 797984 raw words (558138 effective words) took 0.5s, 1196104 effective words/s
2018-01-03 17:26:38,419 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1196104 effective words/s
2018-01-03 17:26:38,419 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.5s, 1196104 effective words/s
2018-01-03 17:26:57,805 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:26:57,805 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:26:57,805 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:26:57,805 : INFO : starting fold 1 in 10-fold CV
2018-01-03 17:26:57,805 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:26:57,805 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 17:27:06,026 : INFO : Step 1, Minibatch Loss= 0.2959, Training Accuracy= 0.903
2018-01-03 17:27:06,026 - root - INFO - Step 1, Minibatch Loss= 0.2959, Training Accuracy= 0.903
2018-01-03 17:27:06,026 - root - INFO - Step 1, Minibatch Loss= 0.2959, Training Accuracy= 0.903
2018-01-03 17:27:06,107 : INFO : Step 1, Validation Loss= 0.3309, Validation Accuracy= 0.824
2018-01-03 17:27:06,107 - root - INFO - Step 1, Validation Loss= 0.3309, Validation Accuracy= 0.824
2018-01-03 17:27:06,107 - root - INFO - Step 1, Validation Loss= 0.3309, Validation Accuracy= 0.824
2018-01-03 17:27:08,657 : INFO : Step 2, Minibatch Loss= 0.1028, Training Accuracy= 0.962
2018-01-03 17:27:08,657 - root - INFO - Step 2, Minibatch Loss= 0.1028, Training Accuracy= 0.962
2018-01-03 17:27:08,657 - root - INFO - Step 2, Minibatch Loss= 0.1028, Training Accuracy= 0.962
2018-01-03 17:27:08,723 : INFO : Step 2, Validation Loss= 0.2945, Validation Accuracy= 0.867
2018-01-03 17:27:08,723 - root - INFO - Step 2, Validation Loss= 0.2945, Validation Accuracy= 0.867
2018-01-03 17:27:08,723 - root - INFO - Step 2, Validation Loss= 0.2945, Validation Accuracy= 0.867
2018-01-03 17:27:11,141 : INFO : Step 3, Minibatch Loss= 0.0628, Training Accuracy= 0.980
2018-01-03 17:27:11,141 - root - INFO - Step 3, Minibatch Loss= 0.0628, Training Accuracy= 0.980
2018-01-03 17:27:11,141 - root - INFO - Step 3, Minibatch Loss= 0.0628, Training Accuracy= 0.980
2018-01-03 17:27:11,212 : INFO : Step 3, Validation Loss= 0.2897, Validation Accuracy= 0.862
2018-01-03 17:27:11,212 - root - INFO - Step 3, Validation Loss= 0.2897, Validation Accuracy= 0.862
2018-01-03 17:27:11,212 - root - INFO - Step 3, Validation Loss= 0.2897, Validation Accuracy= 0.862
2018-01-03 17:27:11,213 : INFO : starting fold 2 in 10-fold CV
2018-01-03 17:27:11,213 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:27:11,213 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 17:27:18,926 : INFO : Step 1, Minibatch Loss= 0.2467, Training Accuracy= 0.926
2018-01-03 17:27:18,926 - root - INFO - Step 1, Minibatch Loss= 0.2467, Training Accuracy= 0.926
2018-01-03 17:27:18,926 - root - INFO - Step 1, Minibatch Loss= 0.2467, Training Accuracy= 0.926
2018-01-03 17:27:19,000 : INFO : Step 1, Validation Loss= 0.4183, Validation Accuracy= 0.832
2018-01-03 17:27:19,000 - root - INFO - Step 1, Validation Loss= 0.4183, Validation Accuracy= 0.832
2018-01-03 17:27:19,000 - root - INFO - Step 1, Validation Loss= 0.4183, Validation Accuracy= 0.832
2018-01-03 17:27:21,260 : INFO : Step 2, Minibatch Loss= 0.0950, Training Accuracy= 0.968
2018-01-03 17:27:21,260 - root - INFO - Step 2, Minibatch Loss= 0.0950, Training Accuracy= 0.968
2018-01-03 17:27:21,260 - root - INFO - Step 2, Minibatch Loss= 0.0950, Training Accuracy= 0.968
2018-01-03 17:27:21,326 : INFO : Step 2, Validation Loss= 0.2794, Validation Accuracy= 0.929
2018-01-03 17:27:21,326 - root - INFO - Step 2, Validation Loss= 0.2794, Validation Accuracy= 0.929
2018-01-03 17:27:21,326 - root - INFO - Step 2, Validation Loss= 0.2794, Validation Accuracy= 0.929
2018-01-03 17:27:23,605 : INFO : Step 3, Minibatch Loss= 0.0538, Training Accuracy= 0.980
2018-01-03 17:27:23,605 - root - INFO - Step 3, Minibatch Loss= 0.0538, Training Accuracy= 0.980
2018-01-03 17:27:23,605 - root - INFO - Step 3, Minibatch Loss= 0.0538, Training Accuracy= 0.980
2018-01-03 17:27:23,673 : INFO : Step 3, Validation Loss= 0.2565, Validation Accuracy= 0.933
2018-01-03 17:27:23,673 - root - INFO - Step 3, Validation Loss= 0.2565, Validation Accuracy= 0.933
2018-01-03 17:27:23,673 - root - INFO - Step 3, Validation Loss= 0.2565, Validation Accuracy= 0.933
2018-01-03 17:27:26,041 : INFO : Step 4, Minibatch Loss= 0.0391, Training Accuracy= 0.988
2018-01-03 17:27:26,041 - root - INFO - Step 4, Minibatch Loss= 0.0391, Training Accuracy= 0.988
2018-01-03 17:27:26,041 - root - INFO - Step 4, Minibatch Loss= 0.0391, Training Accuracy= 0.988
2018-01-03 17:27:26,115 : INFO : Step 4, Validation Loss= 0.3895, Validation Accuracy= 0.916
2018-01-03 17:27:26,115 - root - INFO - Step 4, Validation Loss= 0.3895, Validation Accuracy= 0.916
2018-01-03 17:27:26,115 - root - INFO - Step 4, Validation Loss= 0.3895, Validation Accuracy= 0.916
2018-01-03 17:27:26,116 : INFO : starting fold 3 in 10-fold CV
2018-01-03 17:27:26,116 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:27:26,116 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 17:27:33,783 : INFO : Step 1, Minibatch Loss= 0.1883, Training Accuracy= 0.931
2018-01-03 17:27:33,783 - root - INFO - Step 1, Minibatch Loss= 0.1883, Training Accuracy= 0.931
2018-01-03 17:27:33,783 - root - INFO - Step 1, Minibatch Loss= 0.1883, Training Accuracy= 0.931
2018-01-03 17:27:33,856 : INFO : Step 1, Validation Loss= 0.2075, Validation Accuracy= 0.916
2018-01-03 17:27:33,856 - root - INFO - Step 1, Validation Loss= 0.2075, Validation Accuracy= 0.916
2018-01-03 17:27:33,856 - root - INFO - Step 1, Validation Loss= 0.2075, Validation Accuracy= 0.916
2018-01-03 17:27:36,181 : INFO : Step 2, Minibatch Loss= 0.0800, Training Accuracy= 0.977
2018-01-03 17:27:36,181 - root - INFO - Step 2, Minibatch Loss= 0.0800, Training Accuracy= 0.977
2018-01-03 17:27:36,181 - root - INFO - Step 2, Minibatch Loss= 0.0800, Training Accuracy= 0.977
2018-01-03 17:27:36,250 : INFO : Step 2, Validation Loss= 0.1714, Validation Accuracy= 0.938
2018-01-03 17:27:36,250 - root - INFO - Step 2, Validation Loss= 0.1714, Validation Accuracy= 0.938
2018-01-03 17:27:36,250 - root - INFO - Step 2, Validation Loss= 0.1714, Validation Accuracy= 0.938
2018-01-03 17:27:38,597 : INFO : Step 3, Minibatch Loss= 0.0518, Training Accuracy= 0.984
2018-01-03 17:27:38,597 - root - INFO - Step 3, Minibatch Loss= 0.0518, Training Accuracy= 0.984
2018-01-03 17:27:38,597 - root - INFO - Step 3, Minibatch Loss= 0.0518, Training Accuracy= 0.984
2018-01-03 17:27:38,666 : INFO : Step 3, Validation Loss= 0.1809, Validation Accuracy= 0.933
2018-01-03 17:27:38,666 - root - INFO - Step 3, Validation Loss= 0.1809, Validation Accuracy= 0.933
2018-01-03 17:27:38,666 - root - INFO - Step 3, Validation Loss= 0.1809, Validation Accuracy= 0.933
2018-01-03 17:27:38,666 : INFO : starting fold 4 in 10-fold CV
2018-01-03 17:27:38,666 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:27:38,666 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 17:27:45,859 : INFO : Step 1, Minibatch Loss= 0.2073, Training Accuracy= 0.921
2018-01-03 17:27:45,859 - root - INFO - Step 1, Minibatch Loss= 0.2073, Training Accuracy= 0.921
2018-01-03 17:27:45,859 - root - INFO - Step 1, Minibatch Loss= 0.2073, Training Accuracy= 0.921
2018-01-03 17:27:45,930 : INFO : Step 1, Validation Loss= 0.3089, Validation Accuracy= 0.901
2018-01-03 17:27:45,930 - root - INFO - Step 1, Validation Loss= 0.3089, Validation Accuracy= 0.901
2018-01-03 17:27:45,930 - root - INFO - Step 1, Validation Loss= 0.3089, Validation Accuracy= 0.901
2018-01-03 17:27:48,250 : INFO : Step 2, Minibatch Loss= 0.0820, Training Accuracy= 0.972
2018-01-03 17:27:48,250 - root - INFO - Step 2, Minibatch Loss= 0.0820, Training Accuracy= 0.972
2018-01-03 17:27:48,250 - root - INFO - Step 2, Minibatch Loss= 0.0820, Training Accuracy= 0.972
2018-01-03 17:27:48,317 : INFO : Step 2, Validation Loss= 0.1462, Validation Accuracy= 0.940
2018-01-03 17:27:48,317 - root - INFO - Step 2, Validation Loss= 0.1462, Validation Accuracy= 0.940
2018-01-03 17:27:48,317 - root - INFO - Step 2, Validation Loss= 0.1462, Validation Accuracy= 0.940
2018-01-03 17:27:50,668 : INFO : Step 3, Minibatch Loss= 0.0527, Training Accuracy= 0.984
2018-01-03 17:27:50,668 - root - INFO - Step 3, Minibatch Loss= 0.0527, Training Accuracy= 0.984
2018-01-03 17:27:50,668 - root - INFO - Step 3, Minibatch Loss= 0.0527, Training Accuracy= 0.984
2018-01-03 17:27:50,733 : INFO : Step 3, Validation Loss= 0.1315, Validation Accuracy= 0.953
2018-01-03 17:27:50,733 - root - INFO - Step 3, Validation Loss= 0.1315, Validation Accuracy= 0.953
2018-01-03 17:27:50,733 - root - INFO - Step 3, Validation Loss= 0.1315, Validation Accuracy= 0.953
2018-01-03 17:27:53,114 : INFO : Step 4, Minibatch Loss= 0.0423, Training Accuracy= 0.989
2018-01-03 17:27:53,114 - root - INFO - Step 4, Minibatch Loss= 0.0423, Training Accuracy= 0.989
2018-01-03 17:27:53,114 - root - INFO - Step 4, Minibatch Loss= 0.0423, Training Accuracy= 0.989
2018-01-03 17:27:53,183 : INFO : Step 4, Validation Loss= 0.1791, Validation Accuracy= 0.933
2018-01-03 17:27:53,183 - root - INFO - Step 4, Validation Loss= 0.1791, Validation Accuracy= 0.933
2018-01-03 17:27:53,183 - root - INFO - Step 4, Validation Loss= 0.1791, Validation Accuracy= 0.933
2018-01-03 17:27:53,184 : INFO : starting fold 5 in 10-fold CV
2018-01-03 17:27:53,184 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:27:53,184 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 17:28:00,906 : INFO : Step 1, Minibatch Loss= 0.1957, Training Accuracy= 0.934
2018-01-03 17:28:00,906 - root - INFO - Step 1, Minibatch Loss= 0.1957, Training Accuracy= 0.934
2018-01-03 17:28:00,906 - root - INFO - Step 1, Minibatch Loss= 0.1957, Training Accuracy= 0.934
2018-01-03 17:28:00,991 : INFO : Step 1, Validation Loss= 0.2804, Validation Accuracy= 0.884
2018-01-03 17:28:00,991 - root - INFO - Step 1, Validation Loss= 0.2804, Validation Accuracy= 0.884
2018-01-03 17:28:00,991 - root - INFO - Step 1, Validation Loss= 0.2804, Validation Accuracy= 0.884
2018-01-03 17:28:03,331 : INFO : Step 2, Minibatch Loss= 0.0830, Training Accuracy= 0.969
2018-01-03 17:28:03,331 - root - INFO - Step 2, Minibatch Loss= 0.0830, Training Accuracy= 0.969
2018-01-03 17:28:03,331 - root - INFO - Step 2, Minibatch Loss= 0.0830, Training Accuracy= 0.969
2018-01-03 17:28:03,394 : INFO : Step 2, Validation Loss= 0.2639, Validation Accuracy= 0.899
2018-01-03 17:28:03,394 - root - INFO - Step 2, Validation Loss= 0.2639, Validation Accuracy= 0.899
2018-01-03 17:28:03,394 - root - INFO - Step 2, Validation Loss= 0.2639, Validation Accuracy= 0.899
2018-01-03 17:28:05,771 : INFO : Step 3, Minibatch Loss= 0.0382, Training Accuracy= 0.989
2018-01-03 17:28:05,771 - root - INFO - Step 3, Minibatch Loss= 0.0382, Training Accuracy= 0.989
2018-01-03 17:28:05,771 - root - INFO - Step 3, Minibatch Loss= 0.0382, Training Accuracy= 0.989
2018-01-03 17:28:05,836 : INFO : Step 3, Validation Loss= 0.2484, Validation Accuracy= 0.938
2018-01-03 17:28:05,836 - root - INFO - Step 3, Validation Loss= 0.2484, Validation Accuracy= 0.938
2018-01-03 17:28:05,836 - root - INFO - Step 3, Validation Loss= 0.2484, Validation Accuracy= 0.938
2018-01-03 17:28:08,137 : INFO : Step 4, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 17:28:08,137 - root - INFO - Step 4, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 17:28:08,137 - root - INFO - Step 4, Minibatch Loss= 0.0248, Training Accuracy= 0.993
2018-01-03 17:28:08,212 : INFO : Step 4, Validation Loss= 0.3130, Validation Accuracy= 0.905
2018-01-03 17:28:08,212 - root - INFO - Step 4, Validation Loss= 0.3130, Validation Accuracy= 0.905
2018-01-03 17:28:08,212 - root - INFO - Step 4, Validation Loss= 0.3130, Validation Accuracy= 0.905
2018-01-03 17:28:08,212 : INFO : starting fold 6 in 10-fold CV
2018-01-03 17:28:08,212 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:28:08,212 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 17:28:15,865 : INFO : Step 1, Minibatch Loss= 0.3594, Training Accuracy= 0.858
2018-01-03 17:28:15,865 - root - INFO - Step 1, Minibatch Loss= 0.3594, Training Accuracy= 0.858
2018-01-03 17:28:15,865 - root - INFO - Step 1, Minibatch Loss= 0.3594, Training Accuracy= 0.858
2018-01-03 17:28:15,934 : INFO : Step 1, Validation Loss= 0.3892, Validation Accuracy= 0.832
2018-01-03 17:28:15,934 - root - INFO - Step 1, Validation Loss= 0.3892, Validation Accuracy= 0.832
2018-01-03 17:28:15,934 - root - INFO - Step 1, Validation Loss= 0.3892, Validation Accuracy= 0.832
2018-01-03 17:28:18,307 : INFO : Step 2, Minibatch Loss= 0.1263, Training Accuracy= 0.960
2018-01-03 17:28:18,307 - root - INFO - Step 2, Minibatch Loss= 0.1263, Training Accuracy= 0.960
2018-01-03 17:28:18,307 - root - INFO - Step 2, Minibatch Loss= 0.1263, Training Accuracy= 0.960
2018-01-03 17:28:18,378 : INFO : Step 2, Validation Loss= 0.1695, Validation Accuracy= 0.940
2018-01-03 17:28:18,378 - root - INFO - Step 2, Validation Loss= 0.1695, Validation Accuracy= 0.940
2018-01-03 17:28:18,378 - root - INFO - Step 2, Validation Loss= 0.1695, Validation Accuracy= 0.940
2018-01-03 17:28:20,752 : INFO : Step 3, Minibatch Loss= 0.0639, Training Accuracy= 0.978
2018-01-03 17:28:20,752 - root - INFO - Step 3, Minibatch Loss= 0.0639, Training Accuracy= 0.978
2018-01-03 17:28:20,752 - root - INFO - Step 3, Minibatch Loss= 0.0639, Training Accuracy= 0.978
2018-01-03 17:28:20,818 : INFO : Step 3, Validation Loss= 0.1479, Validation Accuracy= 0.940
2018-01-03 17:28:20,818 - root - INFO - Step 3, Validation Loss= 0.1479, Validation Accuracy= 0.940
2018-01-03 17:28:20,818 - root - INFO - Step 3, Validation Loss= 0.1479, Validation Accuracy= 0.940
2018-01-03 17:28:23,156 : INFO : Step 4, Minibatch Loss= 0.0478, Training Accuracy= 0.984
2018-01-03 17:28:23,156 - root - INFO - Step 4, Minibatch Loss= 0.0478, Training Accuracy= 0.984
2018-01-03 17:28:23,156 - root - INFO - Step 4, Minibatch Loss= 0.0478, Training Accuracy= 0.984
2018-01-03 17:28:23,224 : INFO : Step 4, Validation Loss= 0.1733, Validation Accuracy= 0.944
2018-01-03 17:28:23,224 - root - INFO - Step 4, Validation Loss= 0.1733, Validation Accuracy= 0.944
2018-01-03 17:28:23,224 - root - INFO - Step 4, Validation Loss= 0.1733, Validation Accuracy= 0.944
2018-01-03 17:28:25,547 : INFO : Step 5, Minibatch Loss= 0.0249, Training Accuracy= 0.992
2018-01-03 17:28:25,547 - root - INFO - Step 5, Minibatch Loss= 0.0249, Training Accuracy= 0.992
2018-01-03 17:28:25,547 - root - INFO - Step 5, Minibatch Loss= 0.0249, Training Accuracy= 0.992
2018-01-03 17:28:25,613 : INFO : Step 5, Validation Loss= 0.2577, Validation Accuracy= 0.901
2018-01-03 17:28:25,613 - root - INFO - Step 5, Validation Loss= 0.2577, Validation Accuracy= 0.901
2018-01-03 17:28:25,613 - root - INFO - Step 5, Validation Loss= 0.2577, Validation Accuracy= 0.901
2018-01-03 17:28:25,614 : INFO : starting fold 7 in 10-fold CV
2018-01-03 17:28:25,614 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:28:25,614 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 17:28:33,381 : INFO : Step 1, Minibatch Loss= 0.2067, Training Accuracy= 0.917
2018-01-03 17:28:33,381 - root - INFO - Step 1, Minibatch Loss= 0.2067, Training Accuracy= 0.917
2018-01-03 17:28:33,381 - root - INFO - Step 1, Minibatch Loss= 0.2067, Training Accuracy= 0.917
2018-01-03 17:28:33,456 : INFO : Step 1, Validation Loss= 0.2608, Validation Accuracy= 0.918
2018-01-03 17:28:33,456 - root - INFO - Step 1, Validation Loss= 0.2608, Validation Accuracy= 0.918
2018-01-03 17:28:33,456 - root - INFO - Step 1, Validation Loss= 0.2608, Validation Accuracy= 0.918
2018-01-03 17:28:35,985 : INFO : Step 2, Minibatch Loss= 0.0999, Training Accuracy= 0.962
2018-01-03 17:28:35,985 - root - INFO - Step 2, Minibatch Loss= 0.0999, Training Accuracy= 0.962
2018-01-03 17:28:35,985 - root - INFO - Step 2, Minibatch Loss= 0.0999, Training Accuracy= 0.962
2018-01-03 17:28:36,052 : INFO : Step 2, Validation Loss= 0.2472, Validation Accuracy= 0.918
2018-01-03 17:28:36,052 - root - INFO - Step 2, Validation Loss= 0.2472, Validation Accuracy= 0.918
2018-01-03 17:28:36,052 - root - INFO - Step 2, Validation Loss= 0.2472, Validation Accuracy= 0.918
2018-01-03 17:28:36,052 : INFO : starting fold 8 in 10-fold CV
2018-01-03 17:28:36,052 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:28:36,052 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 17:28:43,419 : INFO : Step 1, Minibatch Loss= 0.2149, Training Accuracy= 0.919
2018-01-03 17:28:43,419 - root - INFO - Step 1, Minibatch Loss= 0.2149, Training Accuracy= 0.919
2018-01-03 17:28:43,419 - root - INFO - Step 1, Minibatch Loss= 0.2149, Training Accuracy= 0.919
2018-01-03 17:28:43,496 : INFO : Step 1, Validation Loss= 0.3133, Validation Accuracy= 0.834
2018-01-03 17:28:43,496 - root - INFO - Step 1, Validation Loss= 0.3133, Validation Accuracy= 0.834
2018-01-03 17:28:43,496 - root - INFO - Step 1, Validation Loss= 0.3133, Validation Accuracy= 0.834
2018-01-03 17:28:45,905 : INFO : Step 2, Minibatch Loss= 0.0838, Training Accuracy= 0.971
2018-01-03 17:28:45,905 - root - INFO - Step 2, Minibatch Loss= 0.0838, Training Accuracy= 0.971
2018-01-03 17:28:45,905 - root - INFO - Step 2, Minibatch Loss= 0.0838, Training Accuracy= 0.971
2018-01-03 17:28:45,976 : INFO : Step 2, Validation Loss= 0.1982, Validation Accuracy= 0.905
2018-01-03 17:28:45,976 - root - INFO - Step 2, Validation Loss= 0.1982, Validation Accuracy= 0.905
2018-01-03 17:28:45,976 - root - INFO - Step 2, Validation Loss= 0.1982, Validation Accuracy= 0.905
2018-01-03 17:28:48,900 : INFO : Step 3, Minibatch Loss= 0.0450, Training Accuracy= 0.985
2018-01-03 17:28:48,900 - root - INFO - Step 3, Minibatch Loss= 0.0450, Training Accuracy= 0.985
2018-01-03 17:28:48,900 - root - INFO - Step 3, Minibatch Loss= 0.0450, Training Accuracy= 0.985
2018-01-03 17:28:48,996 : INFO : Step 3, Validation Loss= 0.1920, Validation Accuracy= 0.938
2018-01-03 17:28:48,996 - root - INFO - Step 3, Validation Loss= 0.1920, Validation Accuracy= 0.938
2018-01-03 17:28:48,996 - root - INFO - Step 3, Validation Loss= 0.1920, Validation Accuracy= 0.938
2018-01-03 17:28:51,432 : INFO : Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.989
2018-01-03 17:28:51,432 - root - INFO - Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.989
2018-01-03 17:28:51,432 - root - INFO - Step 4, Minibatch Loss= 0.0358, Training Accuracy= 0.989
2018-01-03 17:28:51,499 : INFO : Step 4, Validation Loss= 0.2294, Validation Accuracy= 0.925
2018-01-03 17:28:51,499 - root - INFO - Step 4, Validation Loss= 0.2294, Validation Accuracy= 0.925
2018-01-03 17:28:51,499 - root - INFO - Step 4, Validation Loss= 0.2294, Validation Accuracy= 0.925
2018-01-03 17:28:51,499 : INFO : starting fold 9 in 10-fold CV
2018-01-03 17:28:51,499 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:28:51,499 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 17:29:00,362 : INFO : Step 1, Minibatch Loss= 0.2101, Training Accuracy= 0.926
2018-01-03 17:29:00,362 - root - INFO - Step 1, Minibatch Loss= 0.2101, Training Accuracy= 0.926
2018-01-03 17:29:00,362 - root - INFO - Step 1, Minibatch Loss= 0.2101, Training Accuracy= 0.926
2018-01-03 17:29:00,442 : INFO : Step 1, Validation Loss= 0.2984, Validation Accuracy= 0.912
2018-01-03 17:29:00,442 - root - INFO - Step 1, Validation Loss= 0.2984, Validation Accuracy= 0.912
2018-01-03 17:29:00,442 - root - INFO - Step 1, Validation Loss= 0.2984, Validation Accuracy= 0.912
2018-01-03 17:29:02,805 : INFO : Step 2, Minibatch Loss= 0.0989, Training Accuracy= 0.969
2018-01-03 17:29:02,805 - root - INFO - Step 2, Minibatch Loss= 0.0989, Training Accuracy= 0.969
2018-01-03 17:29:02,805 - root - INFO - Step 2, Minibatch Loss= 0.0989, Training Accuracy= 0.969
2018-01-03 17:29:02,872 : INFO : Step 2, Validation Loss= 0.2662, Validation Accuracy= 0.927
2018-01-03 17:29:02,872 - root - INFO - Step 2, Validation Loss= 0.2662, Validation Accuracy= 0.927
2018-01-03 17:29:02,872 - root - INFO - Step 2, Validation Loss= 0.2662, Validation Accuracy= 0.927
2018-01-03 17:29:05,251 : INFO : Step 3, Minibatch Loss= 0.0491, Training Accuracy= 0.984
2018-01-03 17:29:05,251 - root - INFO - Step 3, Minibatch Loss= 0.0491, Training Accuracy= 0.984
2018-01-03 17:29:05,251 - root - INFO - Step 3, Minibatch Loss= 0.0491, Training Accuracy= 0.984
2018-01-03 17:29:05,339 : INFO : Step 3, Validation Loss= 0.1821, Validation Accuracy= 0.931
2018-01-03 17:29:05,339 - root - INFO - Step 3, Validation Loss= 0.1821, Validation Accuracy= 0.931
2018-01-03 17:29:05,339 - root - INFO - Step 3, Validation Loss= 0.1821, Validation Accuracy= 0.931
2018-01-03 17:29:07,942 : INFO : Step 4, Minibatch Loss= 0.0286, Training Accuracy= 0.991
2018-01-03 17:29:07,942 - root - INFO - Step 4, Minibatch Loss= 0.0286, Training Accuracy= 0.991
2018-01-03 17:29:07,942 - root - INFO - Step 4, Minibatch Loss= 0.0286, Training Accuracy= 0.991
2018-01-03 17:29:08,005 : INFO : Step 4, Validation Loss= 0.2618, Validation Accuracy= 0.933
2018-01-03 17:29:08,005 - root - INFO - Step 4, Validation Loss= 0.2618, Validation Accuracy= 0.933
2018-01-03 17:29:08,005 - root - INFO - Step 4, Validation Loss= 0.2618, Validation Accuracy= 0.933
2018-01-03 17:29:10,298 : INFO : Step 5, Minibatch Loss= 0.0172, Training Accuracy= 0.993
2018-01-03 17:29:10,298 - root - INFO - Step 5, Minibatch Loss= 0.0172, Training Accuracy= 0.993
2018-01-03 17:29:10,298 - root - INFO - Step 5, Minibatch Loss= 0.0172, Training Accuracy= 0.993
2018-01-03 17:29:10,365 : INFO : Step 5, Validation Loss= 0.2538, Validation Accuracy= 0.935
2018-01-03 17:29:10,365 - root - INFO - Step 5, Validation Loss= 0.2538, Validation Accuracy= 0.935
2018-01-03 17:29:10,365 - root - INFO - Step 5, Validation Loss= 0.2538, Validation Accuracy= 0.935
2018-01-03 17:29:12,773 : INFO : Step 6, Minibatch Loss= 0.0156, Training Accuracy= 0.996
2018-01-03 17:29:12,773 - root - INFO - Step 6, Minibatch Loss= 0.0156, Training Accuracy= 0.996
2018-01-03 17:29:12,773 - root - INFO - Step 6, Minibatch Loss= 0.0156, Training Accuracy= 0.996
2018-01-03 17:29:12,839 : INFO : Step 6, Validation Loss= 0.2740, Validation Accuracy= 0.927
2018-01-03 17:29:12,839 - root - INFO - Step 6, Validation Loss= 0.2740, Validation Accuracy= 0.927
2018-01-03 17:29:12,839 - root - INFO - Step 6, Validation Loss= 0.2740, Validation Accuracy= 0.927
2018-01-03 17:29:12,840 : INFO : starting fold 10 in 10-fold CV
2018-01-03 17:29:12,840 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:29:12,840 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 17:29:21,281 : INFO : Step 1, Minibatch Loss= 0.1964, Training Accuracy= 0.928
2018-01-03 17:29:21,281 - root - INFO - Step 1, Minibatch Loss= 0.1964, Training Accuracy= 0.928
2018-01-03 17:29:21,281 - root - INFO - Step 1, Minibatch Loss= 0.1964, Training Accuracy= 0.928
2018-01-03 17:29:21,402 : INFO : Step 1, Validation Loss= 0.2952, Validation Accuracy= 0.920
2018-01-03 17:29:21,402 - root - INFO - Step 1, Validation Loss= 0.2952, Validation Accuracy= 0.920
2018-01-03 17:29:21,402 - root - INFO - Step 1, Validation Loss= 0.2952, Validation Accuracy= 0.920
2018-01-03 17:29:24,743 : INFO : Step 2, Minibatch Loss= 0.0850, Training Accuracy= 0.970
2018-01-03 17:29:24,743 - root - INFO - Step 2, Minibatch Loss= 0.0850, Training Accuracy= 0.970
2018-01-03 17:29:24,743 - root - INFO - Step 2, Minibatch Loss= 0.0850, Training Accuracy= 0.970
2018-01-03 17:29:24,810 : INFO : Step 2, Validation Loss= 0.2257, Validation Accuracy= 0.912
2018-01-03 17:29:24,810 - root - INFO - Step 2, Validation Loss= 0.2257, Validation Accuracy= 0.912
2018-01-03 17:29:24,810 - root - INFO - Step 2, Validation Loss= 0.2257, Validation Accuracy= 0.912
2018-01-03 17:29:24,810 : INFO : Average accuracy is 0.928387 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:29:24,810 - root - INFO - Average accuracy is 0.928387 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:29:24,810 - root - INFO - Average accuracy is 0.928387 for training_steps=10, batch_size=93, embed_size=50, num_hidden=30
2018-01-03 17:29:24,811 : INFO : This 10-fold CV run-time: 147.00546789169312 seconds
2018-01-03 17:29:24,811 - root - INFO - This 10-fold CV run-time: 147.00546789169312 seconds
2018-01-03 17:29:24,811 - root - INFO - This 10-fold CV run-time: 147.00546789169312 seconds
2018-01-03 17:29:24,969 : INFO : current best: accuracy=0.928387, num_hidden=20, dropout=0.0
2018-01-03 17:29:24,969 - root - INFO - current best: accuracy=0.928387, num_hidden=20, dropout=0.0
2018-01-03 17:29:24,969 - root - INFO - current best: accuracy=0.928387, num_hidden=20, dropout=0.0
2018-01-03 17:29:24,970 : INFO : results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.0): 0.92838717}
2018-01-03 17:29:24,970 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.0): 0.92838717}
2018-01-03 17:29:24,970 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.0): 0.92838717}
2018-01-03 17:29:24,970 : INFO : Code run-time: 168.11618614196777 seconds
2018-01-03 17:29:24,970 - root - INFO - Code run-time: 168.11618614196777 seconds
2018-01-03 17:29:24,970 - root - INFO - Code run-time: 168.11618614196777 seconds
2018-01-03 17:33:16,801 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:33:16,801 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:33:16,801 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 17:33:16,801 : INFO : collecting all words and their counts
2018-01-03 17:33:16,801 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:33:16,801 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 17:33:16,802 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:33:16,802 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:33:16,802 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 17:33:16,825 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:33:16,825 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:33:16,825 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 17:33:16,825 : INFO : Loading a fresh vocabulary
2018-01-03 17:33:16,825 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:33:16,825 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 17:33:16,839 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:33:16,839 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:33:16,839 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 17:33:16,839 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:33:16,839 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:33:16,839 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 17:33:16,858 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 17:33:16,858 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:33:16,858 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 17:33:16,859 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 17:33:16,859 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:33:16,859 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 17:33:16,860 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:33:16,860 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:33:16,860 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 17:33:16,860 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:33:16,860 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:33:16,860 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 17:33:16,876 : INFO : resetting layer weights
2018-01-03 17:33:16,876 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:33:16,876 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 17:33:16,949 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:16,949 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:16,949 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:17,439 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,439 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,439 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,443 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,443 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,446 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,446 : INFO : training on 797984 raw words (558607 effective words) took 0.5s, 1135123 effective words/s
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1135123 effective words/s
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.5s, 1135123 effective words/s
2018-01-03 17:33:17,446 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:17,446 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 17:33:17,911 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,911 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,911 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 17:33:17,912 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,912 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,912 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 17:33:17,915 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,915 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,915 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 17:33:17,916 : INFO : training on 797984 raw words (558457 effective words) took 0.5s, 1202199 effective words/s
2018-01-03 17:33:17,916 - gensim.models.word2vec - INFO - training on 797984 raw words (558457 effective words) took 0.5s, 1202199 effective words/s
2018-01-03 17:33:17,916 - gensim.models.word2vec - INFO - training on 797984 raw words (558457 effective words) took 0.5s, 1202199 effective words/s
2018-01-03 18:32:09,749 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:32:09,749 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:32:09,749 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:32:09,750 : INFO : collecting all words and their counts
2018-01-03 18:32:09,750 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:32:09,750 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:32:09,750 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:32:09,750 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:32:09,750 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:32:09,773 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:32:09,773 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:32:09,773 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:32:09,773 : INFO : Loading a fresh vocabulary
2018-01-03 18:32:09,773 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:32:09,773 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:32:09,790 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:32:09,790 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:32:09,790 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:32:09,790 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:32:09,790 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:32:09,790 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:32:09,811 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:32:09,811 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:32:09,811 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:32:09,811 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:32:09,812 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:32:09,812 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:32:09,812 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:32:09,826 : INFO : resetting layer weights
2018-01-03 18:32:09,826 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:32:09,826 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:32:09,908 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:09,908 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:09,908 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:10,359 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,359 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,359 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,363 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,363 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,363 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,366 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,366 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,366 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,367 : INFO : training on 797984 raw words (558601 effective words) took 0.5s, 1232045 effective words/s
2018-01-03 18:32:10,367 - gensim.models.word2vec - INFO - training on 797984 raw words (558601 effective words) took 0.5s, 1232045 effective words/s
2018-01-03 18:32:10,367 - gensim.models.word2vec - INFO - training on 797984 raw words (558601 effective words) took 0.5s, 1232045 effective words/s
2018-01-03 18:32:10,367 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:10,367 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:10,367 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:32:10,798 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,798 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,798 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:32:10,803 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,803 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,803 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:32:10,804 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,804 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,804 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:32:10,804 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1288482 effective words/s
2018-01-03 18:32:10,804 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1288482 effective words/s
2018-01-03 18:32:10,804 - gensim.models.word2vec - INFO - training on 797984 raw words (558138 effective words) took 0.4s, 1288482 effective words/s
2018-01-03 18:32:29,963 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:32:29,963 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:32:29,963 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:32:29,964 : INFO : starting fold 1 in 10-fold CV
2018-01-03 18:32:29,964 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:32:29,964 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:32:37,616 : INFO : Step 1, Minibatch Loss= 0.5098, Training Accuracy= 0.792
2018-01-03 18:32:37,616 - root - INFO - Step 1, Minibatch Loss= 0.5098, Training Accuracy= 0.792
2018-01-03 18:32:37,616 - root - INFO - Step 1, Minibatch Loss= 0.5098, Training Accuracy= 0.792
2018-01-03 18:32:37,677 : INFO : Step 1, Validation Loss= 0.6077, Validation Accuracy= 0.692
2018-01-03 18:32:37,677 - root - INFO - Step 1, Validation Loss= 0.6077, Validation Accuracy= 0.692
2018-01-03 18:32:37,677 - root - INFO - Step 1, Validation Loss= 0.6077, Validation Accuracy= 0.692
2018-01-03 18:32:39,670 : INFO : Step 2, Minibatch Loss= 0.2541, Training Accuracy= 0.889
2018-01-03 18:32:39,670 - root - INFO - Step 2, Minibatch Loss= 0.2541, Training Accuracy= 0.889
2018-01-03 18:32:39,670 - root - INFO - Step 2, Minibatch Loss= 0.2541, Training Accuracy= 0.889
2018-01-03 18:32:39,725 : INFO : Step 2, Validation Loss= 0.4053, Validation Accuracy= 0.903
2018-01-03 18:32:39,725 - root - INFO - Step 2, Validation Loss= 0.4053, Validation Accuracy= 0.903
2018-01-03 18:32:39,725 - root - INFO - Step 2, Validation Loss= 0.4053, Validation Accuracy= 0.903
2018-01-03 18:32:41,576 : INFO : Step 3, Minibatch Loss= 0.1754, Training Accuracy= 0.917
2018-01-03 18:32:41,576 - root - INFO - Step 3, Minibatch Loss= 0.1754, Training Accuracy= 0.917
2018-01-03 18:32:41,576 - root - INFO - Step 3, Minibatch Loss= 0.1754, Training Accuracy= 0.917
2018-01-03 18:32:41,636 : INFO : Step 3, Validation Loss= 0.4043, Validation Accuracy= 0.903
2018-01-03 18:32:41,636 - root - INFO - Step 3, Validation Loss= 0.4043, Validation Accuracy= 0.903
2018-01-03 18:32:41,636 - root - INFO - Step 3, Validation Loss= 0.4043, Validation Accuracy= 0.903
2018-01-03 18:32:43,627 : INFO : Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.934
2018-01-03 18:32:43,627 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.934
2018-01-03 18:32:43,627 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.934
2018-01-03 18:32:43,684 : INFO : Step 4, Validation Loss= 0.3023, Validation Accuracy= 0.824
2018-01-03 18:32:43,684 - root - INFO - Step 4, Validation Loss= 0.3023, Validation Accuracy= 0.824
2018-01-03 18:32:43,684 - root - INFO - Step 4, Validation Loss= 0.3023, Validation Accuracy= 0.824
2018-01-03 18:32:43,684 : INFO : starting fold 2 in 10-fold CV
2018-01-03 18:32:43,684 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:32:43,684 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:32:50,754 : INFO : Step 1, Minibatch Loss= 0.5468, Training Accuracy= 0.723
2018-01-03 18:32:50,754 - root - INFO - Step 1, Minibatch Loss= 0.5468, Training Accuracy= 0.723
2018-01-03 18:32:50,754 - root - INFO - Step 1, Minibatch Loss= 0.5468, Training Accuracy= 0.723
2018-01-03 18:32:50,810 : INFO : Step 1, Validation Loss= 0.7492, Validation Accuracy= 0.486
2018-01-03 18:32:50,810 - root - INFO - Step 1, Validation Loss= 0.7492, Validation Accuracy= 0.486
2018-01-03 18:32:50,810 - root - INFO - Step 1, Validation Loss= 0.7492, Validation Accuracy= 0.486
2018-01-03 18:32:52,740 : INFO : Step 2, Minibatch Loss= 0.3056, Training Accuracy= 0.865
2018-01-03 18:32:52,740 - root - INFO - Step 2, Minibatch Loss= 0.3056, Training Accuracy= 0.865
2018-01-03 18:32:52,740 - root - INFO - Step 2, Minibatch Loss= 0.3056, Training Accuracy= 0.865
2018-01-03 18:32:52,793 : INFO : Step 2, Validation Loss= 0.4456, Validation Accuracy= 0.723
2018-01-03 18:32:52,793 - root - INFO - Step 2, Validation Loss= 0.4456, Validation Accuracy= 0.723
2018-01-03 18:32:52,793 - root - INFO - Step 2, Validation Loss= 0.4456, Validation Accuracy= 0.723
2018-01-03 18:32:54,653 : INFO : Step 3, Minibatch Loss= 0.2370, Training Accuracy= 0.881
2018-01-03 18:32:54,653 - root - INFO - Step 3, Minibatch Loss= 0.2370, Training Accuracy= 0.881
2018-01-03 18:32:54,653 - root - INFO - Step 3, Minibatch Loss= 0.2370, Training Accuracy= 0.881
2018-01-03 18:32:54,706 : INFO : Step 3, Validation Loss= 0.5010, Validation Accuracy= 0.708
2018-01-03 18:32:54,706 - root - INFO - Step 3, Validation Loss= 0.5010, Validation Accuracy= 0.708
2018-01-03 18:32:54,706 - root - INFO - Step 3, Validation Loss= 0.5010, Validation Accuracy= 0.708
2018-01-03 18:32:54,706 : INFO : starting fold 3 in 10-fold CV
2018-01-03 18:32:54,706 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:32:54,706 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:33:01,695 : INFO : Step 1, Minibatch Loss= 0.6312, Training Accuracy= 0.681
2018-01-03 18:33:01,695 - root - INFO - Step 1, Minibatch Loss= 0.6312, Training Accuracy= 0.681
2018-01-03 18:33:01,695 - root - INFO - Step 1, Minibatch Loss= 0.6312, Training Accuracy= 0.681
2018-01-03 18:33:01,761 : INFO : Step 1, Validation Loss= 0.7610, Validation Accuracy= 0.594
2018-01-03 18:33:01,761 - root - INFO - Step 1, Validation Loss= 0.7610, Validation Accuracy= 0.594
2018-01-03 18:33:01,761 - root - INFO - Step 1, Validation Loss= 0.7610, Validation Accuracy= 0.594
2018-01-03 18:33:03,563 : INFO : Step 2, Minibatch Loss= 0.3378, Training Accuracy= 0.858
2018-01-03 18:33:03,563 - root - INFO - Step 2, Minibatch Loss= 0.3378, Training Accuracy= 0.858
2018-01-03 18:33:03,563 - root - INFO - Step 2, Minibatch Loss= 0.3378, Training Accuracy= 0.858
2018-01-03 18:33:03,616 : INFO : Step 2, Validation Loss= 0.4945, Validation Accuracy= 0.781
2018-01-03 18:33:03,616 - root - INFO - Step 2, Validation Loss= 0.4945, Validation Accuracy= 0.781
2018-01-03 18:33:03,616 - root - INFO - Step 2, Validation Loss= 0.4945, Validation Accuracy= 0.781
2018-01-03 18:33:05,509 : INFO : Step 3, Minibatch Loss= 0.2888, Training Accuracy= 0.862
2018-01-03 18:33:05,509 - root - INFO - Step 3, Minibatch Loss= 0.2888, Training Accuracy= 0.862
2018-01-03 18:33:05,509 - root - INFO - Step 3, Minibatch Loss= 0.2888, Training Accuracy= 0.862
2018-01-03 18:33:05,561 : INFO : Step 3, Validation Loss= 0.4128, Validation Accuracy= 0.804
2018-01-03 18:33:05,561 - root - INFO - Step 3, Validation Loss= 0.4128, Validation Accuracy= 0.804
2018-01-03 18:33:05,561 - root - INFO - Step 3, Validation Loss= 0.4128, Validation Accuracy= 0.804
2018-01-03 18:33:07,536 : INFO : Step 4, Minibatch Loss= 0.2284, Training Accuracy= 0.899
2018-01-03 18:33:07,536 - root - INFO - Step 4, Minibatch Loss= 0.2284, Training Accuracy= 0.899
2018-01-03 18:33:07,536 - root - INFO - Step 4, Minibatch Loss= 0.2284, Training Accuracy= 0.899
2018-01-03 18:33:07,592 : INFO : Step 4, Validation Loss= 0.4449, Validation Accuracy= 0.813
2018-01-03 18:33:07,592 - root - INFO - Step 4, Validation Loss= 0.4449, Validation Accuracy= 0.813
2018-01-03 18:33:07,592 - root - INFO - Step 4, Validation Loss= 0.4449, Validation Accuracy= 0.813
2018-01-03 18:33:09,586 : INFO : Step 5, Minibatch Loss= 0.1759, Training Accuracy= 0.931
2018-01-03 18:33:09,586 - root - INFO - Step 5, Minibatch Loss= 0.1759, Training Accuracy= 0.931
2018-01-03 18:33:09,586 - root - INFO - Step 5, Minibatch Loss= 0.1759, Training Accuracy= 0.931
2018-01-03 18:33:09,641 : INFO : Step 5, Validation Loss= 0.4818, Validation Accuracy= 0.847
2018-01-03 18:33:09,641 - root - INFO - Step 5, Validation Loss= 0.4818, Validation Accuracy= 0.847
2018-01-03 18:33:09,641 - root - INFO - Step 5, Validation Loss= 0.4818, Validation Accuracy= 0.847
2018-01-03 18:33:11,799 : INFO : Step 6, Minibatch Loss= 0.1670, Training Accuracy= 0.928
2018-01-03 18:33:11,799 - root - INFO - Step 6, Minibatch Loss= 0.1670, Training Accuracy= 0.928
2018-01-03 18:33:11,799 - root - INFO - Step 6, Minibatch Loss= 0.1670, Training Accuracy= 0.928
2018-01-03 18:33:11,866 : INFO : Step 6, Validation Loss= 0.3830, Validation Accuracy= 0.858
2018-01-03 18:33:11,866 - root - INFO - Step 6, Validation Loss= 0.3830, Validation Accuracy= 0.858
2018-01-03 18:33:11,866 - root - INFO - Step 6, Validation Loss= 0.3830, Validation Accuracy= 0.858
2018-01-03 18:33:14,031 : INFO : Step 7, Minibatch Loss= 0.1600, Training Accuracy= 0.932
2018-01-03 18:33:14,031 - root - INFO - Step 7, Minibatch Loss= 0.1600, Training Accuracy= 0.932
2018-01-03 18:33:14,031 - root - INFO - Step 7, Minibatch Loss= 0.1600, Training Accuracy= 0.932
2018-01-03 18:33:14,094 : INFO : Step 7, Validation Loss= 0.4248, Validation Accuracy= 0.839
2018-01-03 18:33:14,094 - root - INFO - Step 7, Validation Loss= 0.4248, Validation Accuracy= 0.839
2018-01-03 18:33:14,094 - root - INFO - Step 7, Validation Loss= 0.4248, Validation Accuracy= 0.839
2018-01-03 18:33:14,095 : INFO : starting fold 4 in 10-fold CV
2018-01-03 18:33:14,095 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:33:14,095 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:33:21,384 : INFO : Step 1, Minibatch Loss= 0.5985, Training Accuracy= 0.693
2018-01-03 18:33:21,384 - root - INFO - Step 1, Minibatch Loss= 0.5985, Training Accuracy= 0.693
2018-01-03 18:33:21,384 - root - INFO - Step 1, Minibatch Loss= 0.5985, Training Accuracy= 0.693
2018-01-03 18:33:21,438 : INFO : Step 1, Validation Loss= 0.6375, Validation Accuracy= 0.673
2018-01-03 18:33:21,438 - root - INFO - Step 1, Validation Loss= 0.6375, Validation Accuracy= 0.673
2018-01-03 18:33:21,438 - root - INFO - Step 1, Validation Loss= 0.6375, Validation Accuracy= 0.673
2018-01-03 18:33:23,405 : INFO : Step 2, Minibatch Loss= 0.2994, Training Accuracy= 0.865
2018-01-03 18:33:23,405 - root - INFO - Step 2, Minibatch Loss= 0.2994, Training Accuracy= 0.865
2018-01-03 18:33:23,405 - root - INFO - Step 2, Minibatch Loss= 0.2994, Training Accuracy= 0.865
2018-01-03 18:33:23,458 : INFO : Step 2, Validation Loss= 0.3359, Validation Accuracy= 0.843
2018-01-03 18:33:23,458 - root - INFO - Step 2, Validation Loss= 0.3359, Validation Accuracy= 0.843
2018-01-03 18:33:23,458 - root - INFO - Step 2, Validation Loss= 0.3359, Validation Accuracy= 0.843
2018-01-03 18:33:25,454 : INFO : Step 3, Minibatch Loss= 0.2369, Training Accuracy= 0.893
2018-01-03 18:33:25,454 - root - INFO - Step 3, Minibatch Loss= 0.2369, Training Accuracy= 0.893
2018-01-03 18:33:25,454 - root - INFO - Step 3, Minibatch Loss= 0.2369, Training Accuracy= 0.893
2018-01-03 18:33:25,517 : INFO : Step 3, Validation Loss= 0.3167, Validation Accuracy= 0.865
2018-01-03 18:33:25,517 - root - INFO - Step 3, Validation Loss= 0.3167, Validation Accuracy= 0.865
2018-01-03 18:33:25,517 - root - INFO - Step 3, Validation Loss= 0.3167, Validation Accuracy= 0.865
2018-01-03 18:33:27,478 : INFO : Step 4, Minibatch Loss= 0.1886, Training Accuracy= 0.911
2018-01-03 18:33:27,478 - root - INFO - Step 4, Minibatch Loss= 0.1886, Training Accuracy= 0.911
2018-01-03 18:33:27,478 - root - INFO - Step 4, Minibatch Loss= 0.1886, Training Accuracy= 0.911
2018-01-03 18:33:27,529 : INFO : Step 4, Validation Loss= 0.2401, Validation Accuracy= 0.888
2018-01-03 18:33:27,529 - root - INFO - Step 4, Validation Loss= 0.2401, Validation Accuracy= 0.888
2018-01-03 18:33:27,529 - root - INFO - Step 4, Validation Loss= 0.2401, Validation Accuracy= 0.888
2018-01-03 18:33:29,591 : INFO : Step 5, Minibatch Loss= 0.1847, Training Accuracy= 0.907
2018-01-03 18:33:29,591 - root - INFO - Step 5, Minibatch Loss= 0.1847, Training Accuracy= 0.907
2018-01-03 18:33:29,591 - root - INFO - Step 5, Minibatch Loss= 0.1847, Training Accuracy= 0.907
2018-01-03 18:33:29,648 : INFO : Step 5, Validation Loss= 0.2628, Validation Accuracy= 0.880
2018-01-03 18:33:29,648 - root - INFO - Step 5, Validation Loss= 0.2628, Validation Accuracy= 0.880
2018-01-03 18:33:29,648 - root - INFO - Step 5, Validation Loss= 0.2628, Validation Accuracy= 0.880
2018-01-03 18:33:29,648 : INFO : starting fold 5 in 10-fold CV
2018-01-03 18:33:29,648 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:33:29,648 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:33:37,183 : INFO : Step 1, Minibatch Loss= 0.6006, Training Accuracy= 0.696
2018-01-03 18:33:37,183 - root - INFO - Step 1, Minibatch Loss= 0.6006, Training Accuracy= 0.696
2018-01-03 18:33:37,183 - root - INFO - Step 1, Minibatch Loss= 0.6006, Training Accuracy= 0.696
2018-01-03 18:33:37,237 : INFO : Step 1, Validation Loss= 0.7536, Validation Accuracy= 0.574
2018-01-03 18:33:37,237 - root - INFO - Step 1, Validation Loss= 0.7536, Validation Accuracy= 0.574
2018-01-03 18:33:37,237 - root - INFO - Step 1, Validation Loss= 0.7536, Validation Accuracy= 0.574
2018-01-03 18:33:39,090 : INFO : Step 2, Minibatch Loss= 0.3168, Training Accuracy= 0.866
2018-01-03 18:33:39,090 - root - INFO - Step 2, Minibatch Loss= 0.3168, Training Accuracy= 0.866
2018-01-03 18:33:39,090 - root - INFO - Step 2, Minibatch Loss= 0.3168, Training Accuracy= 0.866
2018-01-03 18:33:39,142 : INFO : Step 2, Validation Loss= 0.4369, Validation Accuracy= 0.800
2018-01-03 18:33:39,142 - root - INFO - Step 2, Validation Loss= 0.4369, Validation Accuracy= 0.800
2018-01-03 18:33:39,142 - root - INFO - Step 2, Validation Loss= 0.4369, Validation Accuracy= 0.800
2018-01-03 18:33:40,998 : INFO : Step 3, Minibatch Loss= 0.2492, Training Accuracy= 0.905
2018-01-03 18:33:40,998 - root - INFO - Step 3, Minibatch Loss= 0.2492, Training Accuracy= 0.905
2018-01-03 18:33:40,998 - root - INFO - Step 3, Minibatch Loss= 0.2492, Training Accuracy= 0.905
2018-01-03 18:33:41,054 : INFO : Step 3, Validation Loss= 0.4664, Validation Accuracy= 0.806
2018-01-03 18:33:41,054 - root - INFO - Step 3, Validation Loss= 0.4664, Validation Accuracy= 0.806
2018-01-03 18:33:41,054 - root - INFO - Step 3, Validation Loss= 0.4664, Validation Accuracy= 0.806
2018-01-03 18:33:42,879 : INFO : Step 4, Minibatch Loss= 0.2372, Training Accuracy= 0.910
2018-01-03 18:33:42,879 - root - INFO - Step 4, Minibatch Loss= 0.2372, Training Accuracy= 0.910
2018-01-03 18:33:42,879 - root - INFO - Step 4, Minibatch Loss= 0.2372, Training Accuracy= 0.910
2018-01-03 18:33:42,932 : INFO : Step 4, Validation Loss= 0.5643, Validation Accuracy= 0.828
2018-01-03 18:33:42,932 - root - INFO - Step 4, Validation Loss= 0.5643, Validation Accuracy= 0.828
2018-01-03 18:33:42,932 - root - INFO - Step 4, Validation Loss= 0.5643, Validation Accuracy= 0.828
2018-01-03 18:33:44,889 : INFO : Step 5, Minibatch Loss= 0.1991, Training Accuracy= 0.917
2018-01-03 18:33:44,889 - root - INFO - Step 5, Minibatch Loss= 0.1991, Training Accuracy= 0.917
2018-01-03 18:33:44,889 - root - INFO - Step 5, Minibatch Loss= 0.1991, Training Accuracy= 0.917
2018-01-03 18:33:44,954 : INFO : Step 5, Validation Loss= 0.4494, Validation Accuracy= 0.802
2018-01-03 18:33:44,954 - root - INFO - Step 5, Validation Loss= 0.4494, Validation Accuracy= 0.802
2018-01-03 18:33:44,954 - root - INFO - Step 5, Validation Loss= 0.4494, Validation Accuracy= 0.802
2018-01-03 18:33:44,954 : INFO : starting fold 6 in 10-fold CV
2018-01-03 18:33:44,954 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:33:44,954 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:33:50,103 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:33:50,103 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:33:50,103 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:33:50,103 : INFO : collecting all words and their counts
2018-01-03 18:33:50,103 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:33:50,103 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:33:50,104 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:33:50,104 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:33:50,104 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:33:50,129 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:33:50,129 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:33:50,129 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:33:50,129 : INFO : Loading a fresh vocabulary
2018-01-03 18:33:50,129 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:33:50,129 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:33:50,142 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:33:50,142 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:33:50,142 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:33:50,143 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:33:50,143 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:33:50,143 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:33:50,164 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 18:33:50,164 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:33:50,164 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:33:50,166 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:33:50,166 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:33:50,166 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:33:50,166 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:33:50,185 : INFO : resetting layer weights
2018-01-03 18:33:50,185 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:33:50,185 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:33:50,255 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:50,255 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:50,255 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:50,722 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:50,722 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:50,722 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:50,726 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:50,726 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:50,726 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:50,728 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:50,728 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:50,728 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:50,729 : INFO : training on 797984 raw words (559128 effective words) took 0.5s, 1195004 effective words/s
2018-01-03 18:33:50,729 - gensim.models.word2vec - INFO - training on 797984 raw words (559128 effective words) took 0.5s, 1195004 effective words/s
2018-01-03 18:33:50,729 - gensim.models.word2vec - INFO - training on 797984 raw words (559128 effective words) took 0.5s, 1195004 effective words/s
2018-01-03 18:33:50,729 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:50,729 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:50,729 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:33:51,150 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:51,150 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:51,150 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:33:51,156 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:51,156 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:51,156 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:33:51,157 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:51,157 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:51,157 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:33:51,158 : INFO : training on 797984 raw words (558848 effective words) took 0.4s, 1316653 effective words/s
2018-01-03 18:33:51,158 - gensim.models.word2vec - INFO - training on 797984 raw words (558848 effective words) took 0.4s, 1316653 effective words/s
2018-01-03 18:33:51,158 - gensim.models.word2vec - INFO - training on 797984 raw words (558848 effective words) took 0.4s, 1316653 effective words/s
2018-01-03 18:34:10,146 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:34:10,146 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:34:10,146 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:34:10,146 : INFO : starting fold 1 in 10-fold CV
2018-01-03 18:34:10,146 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:34:10,146 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:34:17,729 : INFO : Step 1, Minibatch Loss= 0.6180, Training Accuracy= 0.664
2018-01-03 18:34:17,729 - root - INFO - Step 1, Minibatch Loss= 0.6180, Training Accuracy= 0.664
2018-01-03 18:34:17,729 - root - INFO - Step 1, Minibatch Loss= 0.6180, Training Accuracy= 0.664
2018-01-03 18:34:17,783 : INFO : Step 1, Validation Loss= 0.5610, Validation Accuracy= 0.791
2018-01-03 18:34:17,783 - root - INFO - Step 1, Validation Loss= 0.5610, Validation Accuracy= 0.791
2018-01-03 18:34:17,783 - root - INFO - Step 1, Validation Loss= 0.5610, Validation Accuracy= 0.791
2018-01-03 18:34:19,658 : INFO : Step 2, Minibatch Loss= 0.3366, Training Accuracy= 0.839
2018-01-03 18:34:19,658 - root - INFO - Step 2, Minibatch Loss= 0.3366, Training Accuracy= 0.839
2018-01-03 18:34:19,658 - root - INFO - Step 2, Minibatch Loss= 0.3366, Training Accuracy= 0.839
2018-01-03 18:34:19,712 : INFO : Step 2, Validation Loss= 0.4144, Validation Accuracy= 0.920
2018-01-03 18:34:19,712 - root - INFO - Step 2, Validation Loss= 0.4144, Validation Accuracy= 0.920
2018-01-03 18:34:19,712 - root - INFO - Step 2, Validation Loss= 0.4144, Validation Accuracy= 0.920
2018-01-03 18:34:21,552 : INFO : Step 3, Minibatch Loss= 0.2374, Training Accuracy= 0.901
2018-01-03 18:34:21,552 - root - INFO - Step 3, Minibatch Loss= 0.2374, Training Accuracy= 0.901
2018-01-03 18:34:21,552 - root - INFO - Step 3, Minibatch Loss= 0.2374, Training Accuracy= 0.901
2018-01-03 18:34:21,605 : INFO : Step 3, Validation Loss= 0.4513, Validation Accuracy= 0.908
2018-01-03 18:34:21,605 - root - INFO - Step 3, Validation Loss= 0.4513, Validation Accuracy= 0.908
2018-01-03 18:34:21,605 - root - INFO - Step 3, Validation Loss= 0.4513, Validation Accuracy= 0.908
2018-01-03 18:34:21,605 : INFO : starting fold 2 in 10-fold CV
2018-01-03 18:34:21,605 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:34:21,605 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:34:29,071 : INFO : Step 1, Minibatch Loss= 0.5261, Training Accuracy= 0.744
2018-01-03 18:34:29,071 - root - INFO - Step 1, Minibatch Loss= 0.5261, Training Accuracy= 0.744
2018-01-03 18:34:29,071 - root - INFO - Step 1, Minibatch Loss= 0.5261, Training Accuracy= 0.744
2018-01-03 18:34:29,127 : INFO : Step 1, Validation Loss= 0.4542, Validation Accuracy= 0.890
2018-01-03 18:34:29,127 - root - INFO - Step 1, Validation Loss= 0.4542, Validation Accuracy= 0.890
2018-01-03 18:34:29,127 - root - INFO - Step 1, Validation Loss= 0.4542, Validation Accuracy= 0.890
2018-01-03 18:34:30,994 : INFO : Step 2, Minibatch Loss= 0.2888, Training Accuracy= 0.863
2018-01-03 18:34:30,994 - root - INFO - Step 2, Minibatch Loss= 0.2888, Training Accuracy= 0.863
2018-01-03 18:34:30,994 - root - INFO - Step 2, Minibatch Loss= 0.2888, Training Accuracy= 0.863
2018-01-03 18:34:31,048 : INFO : Step 2, Validation Loss= 0.2865, Validation Accuracy= 0.968
2018-01-03 18:34:31,048 - root - INFO - Step 2, Validation Loss= 0.2865, Validation Accuracy= 0.968
2018-01-03 18:34:31,048 - root - INFO - Step 2, Validation Loss= 0.2865, Validation Accuracy= 0.968
2018-01-03 18:34:32,885 : INFO : Step 3, Minibatch Loss= 0.2153, Training Accuracy= 0.896
2018-01-03 18:34:32,885 - root - INFO - Step 3, Minibatch Loss= 0.2153, Training Accuracy= 0.896
2018-01-03 18:34:32,885 - root - INFO - Step 3, Minibatch Loss= 0.2153, Training Accuracy= 0.896
2018-01-03 18:34:32,935 : INFO : Step 3, Validation Loss= 0.2763, Validation Accuracy= 0.944
2018-01-03 18:34:32,935 - root - INFO - Step 3, Validation Loss= 0.2763, Validation Accuracy= 0.944
2018-01-03 18:34:32,935 - root - INFO - Step 3, Validation Loss= 0.2763, Validation Accuracy= 0.944
2018-01-03 18:34:32,935 : INFO : starting fold 3 in 10-fold CV
2018-01-03 18:34:32,935 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:34:32,935 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:34:39,646 : INFO : Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.717
2018-01-03 18:34:39,646 - root - INFO - Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.717
2018-01-03 18:34:39,646 - root - INFO - Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.717
2018-01-03 18:34:39,703 : INFO : Step 1, Validation Loss= 0.5799, Validation Accuracy= 0.665
2018-01-03 18:34:39,703 - root - INFO - Step 1, Validation Loss= 0.5799, Validation Accuracy= 0.665
2018-01-03 18:34:39,703 - root - INFO - Step 1, Validation Loss= 0.5799, Validation Accuracy= 0.665
2018-01-03 18:34:41,567 : INFO : Step 2, Minibatch Loss= 0.2679, Training Accuracy= 0.888
2018-01-03 18:34:41,567 - root - INFO - Step 2, Minibatch Loss= 0.2679, Training Accuracy= 0.888
2018-01-03 18:34:41,567 - root - INFO - Step 2, Minibatch Loss= 0.2679, Training Accuracy= 0.888
2018-01-03 18:34:41,621 : INFO : Step 2, Validation Loss= 0.3233, Validation Accuracy= 0.852
2018-01-03 18:34:41,621 - root - INFO - Step 2, Validation Loss= 0.3233, Validation Accuracy= 0.852
2018-01-03 18:34:41,621 - root - INFO - Step 2, Validation Loss= 0.3233, Validation Accuracy= 0.852
2018-01-03 18:34:43,547 : INFO : Step 3, Minibatch Loss= 0.2064, Training Accuracy= 0.912
2018-01-03 18:34:43,547 - root - INFO - Step 3, Minibatch Loss= 0.2064, Training Accuracy= 0.912
2018-01-03 18:34:43,547 - root - INFO - Step 3, Minibatch Loss= 0.2064, Training Accuracy= 0.912
2018-01-03 18:34:43,600 : INFO : Step 3, Validation Loss= 0.3700, Validation Accuracy= 0.828
2018-01-03 18:34:43,600 - root - INFO - Step 3, Validation Loss= 0.3700, Validation Accuracy= 0.828
2018-01-03 18:34:43,600 - root - INFO - Step 3, Validation Loss= 0.3700, Validation Accuracy= 0.828
2018-01-03 18:34:43,600 : INFO : starting fold 4 in 10-fold CV
2018-01-03 18:34:43,600 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:34:43,600 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:34:51,239 : INFO : Step 1, Minibatch Loss= 0.4917, Training Accuracy= 0.778
2018-01-03 18:34:51,239 - root - INFO - Step 1, Minibatch Loss= 0.4917, Training Accuracy= 0.778
2018-01-03 18:34:51,239 - root - INFO - Step 1, Minibatch Loss= 0.4917, Training Accuracy= 0.778
2018-01-03 18:34:51,294 : INFO : Step 1, Validation Loss= 0.4920, Validation Accuracy= 0.796
2018-01-03 18:34:51,294 - root - INFO - Step 1, Validation Loss= 0.4920, Validation Accuracy= 0.796
2018-01-03 18:34:51,294 - root - INFO - Step 1, Validation Loss= 0.4920, Validation Accuracy= 0.796
2018-01-03 18:34:53,147 : INFO : Step 2, Minibatch Loss= 0.3019, Training Accuracy= 0.864
2018-01-03 18:34:53,147 - root - INFO - Step 2, Minibatch Loss= 0.3019, Training Accuracy= 0.864
2018-01-03 18:34:53,147 - root - INFO - Step 2, Minibatch Loss= 0.3019, Training Accuracy= 0.864
2018-01-03 18:34:53,198 : INFO : Step 2, Validation Loss= 0.3227, Validation Accuracy= 0.839
2018-01-03 18:34:53,198 - root - INFO - Step 2, Validation Loss= 0.3227, Validation Accuracy= 0.839
2018-01-03 18:34:53,198 - root - INFO - Step 2, Validation Loss= 0.3227, Validation Accuracy= 0.839
2018-01-03 18:34:55,054 : INFO : Step 3, Minibatch Loss= 0.2269, Training Accuracy= 0.892
2018-01-03 18:34:55,054 - root - INFO - Step 3, Minibatch Loss= 0.2269, Training Accuracy= 0.892
2018-01-03 18:34:55,054 - root - INFO - Step 3, Minibatch Loss= 0.2269, Training Accuracy= 0.892
2018-01-03 18:34:55,105 : INFO : Step 3, Validation Loss= 0.2556, Validation Accuracy= 0.895
2018-01-03 18:34:55,105 - root - INFO - Step 3, Validation Loss= 0.2556, Validation Accuracy= 0.895
2018-01-03 18:34:55,105 - root - INFO - Step 3, Validation Loss= 0.2556, Validation Accuracy= 0.895
2018-01-03 18:34:56,931 : INFO : Step 4, Minibatch Loss= 0.1826, Training Accuracy= 0.919
2018-01-03 18:34:56,931 - root - INFO - Step 4, Minibatch Loss= 0.1826, Training Accuracy= 0.919
2018-01-03 18:34:56,931 - root - INFO - Step 4, Minibatch Loss= 0.1826, Training Accuracy= 0.919
2018-01-03 18:34:56,983 : INFO : Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.884
2018-01-03 18:34:56,983 - root - INFO - Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.884
2018-01-03 18:34:56,983 - root - INFO - Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.884
2018-01-03 18:34:56,983 : INFO : starting fold 5 in 10-fold CV
2018-01-03 18:34:56,983 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:34:56,983 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:35:03,589 : INFO : Step 1, Minibatch Loss= 0.6899, Training Accuracy= 0.619
2018-01-03 18:35:03,589 - root - INFO - Step 1, Minibatch Loss= 0.6899, Training Accuracy= 0.619
2018-01-03 18:35:03,589 - root - INFO - Step 1, Minibatch Loss= 0.6899, Training Accuracy= 0.619
2018-01-03 18:35:03,646 : INFO : Step 1, Validation Loss= 0.6035, Validation Accuracy= 0.718
2018-01-03 18:35:03,646 - root - INFO - Step 1, Validation Loss= 0.6035, Validation Accuracy= 0.718
2018-01-03 18:35:03,646 - root - INFO - Step 1, Validation Loss= 0.6035, Validation Accuracy= 0.718
2018-01-03 18:35:05,509 : INFO : Step 2, Minibatch Loss= 0.3399, Training Accuracy= 0.836
2018-01-03 18:35:05,509 - root - INFO - Step 2, Minibatch Loss= 0.3399, Training Accuracy= 0.836
2018-01-03 18:35:05,509 - root - INFO - Step 2, Minibatch Loss= 0.3399, Training Accuracy= 0.836
2018-01-03 18:35:05,564 : INFO : Step 2, Validation Loss= 0.3431, Validation Accuracy= 0.845
2018-01-03 18:35:05,564 - root - INFO - Step 2, Validation Loss= 0.3431, Validation Accuracy= 0.845
2018-01-03 18:35:05,564 - root - INFO - Step 2, Validation Loss= 0.3431, Validation Accuracy= 0.845
2018-01-03 18:35:07,401 : INFO : Step 3, Minibatch Loss= 0.2411, Training Accuracy= 0.895
2018-01-03 18:35:07,401 - root - INFO - Step 3, Minibatch Loss= 0.2411, Training Accuracy= 0.895
2018-01-03 18:35:07,401 - root - INFO - Step 3, Minibatch Loss= 0.2411, Training Accuracy= 0.895
2018-01-03 18:35:07,455 : INFO : Step 3, Validation Loss= 0.3288, Validation Accuracy= 0.888
2018-01-03 18:35:07,455 - root - INFO - Step 3, Validation Loss= 0.3288, Validation Accuracy= 0.888
2018-01-03 18:35:07,455 - root - INFO - Step 3, Validation Loss= 0.3288, Validation Accuracy= 0.888
2018-01-03 18:35:09,292 : INFO : Step 4, Minibatch Loss= 0.2143, Training Accuracy= 0.904
2018-01-03 18:35:09,292 - root - INFO - Step 4, Minibatch Loss= 0.2143, Training Accuracy= 0.904
2018-01-03 18:35:09,292 - root - INFO - Step 4, Minibatch Loss= 0.2143, Training Accuracy= 0.904
2018-01-03 18:35:09,345 : INFO : Step 4, Validation Loss= 0.3670, Validation Accuracy= 0.873
2018-01-03 18:35:09,345 - root - INFO - Step 4, Validation Loss= 0.3670, Validation Accuracy= 0.873
2018-01-03 18:35:09,345 - root - INFO - Step 4, Validation Loss= 0.3670, Validation Accuracy= 0.873
2018-01-03 18:35:09,345 : INFO : starting fold 6 in 10-fold CV
2018-01-03 18:35:09,345 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:35:09,345 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:35:17,135 : INFO : Step 1, Minibatch Loss= 0.6400, Training Accuracy= 0.683
2018-01-03 18:35:17,135 - root - INFO - Step 1, Minibatch Loss= 0.6400, Training Accuracy= 0.683
2018-01-03 18:35:17,135 - root - INFO - Step 1, Minibatch Loss= 0.6400, Training Accuracy= 0.683
2018-01-03 18:35:17,187 : INFO : Step 1, Validation Loss= 0.6773, Validation Accuracy= 0.649
2018-01-03 18:35:17,187 - root - INFO - Step 1, Validation Loss= 0.6773, Validation Accuracy= 0.649
2018-01-03 18:35:17,187 - root - INFO - Step 1, Validation Loss= 0.6773, Validation Accuracy= 0.649
2018-01-03 18:35:19,122 : INFO : Step 2, Minibatch Loss= 0.3543, Training Accuracy= 0.835
2018-01-03 18:35:19,122 - root - INFO - Step 2, Minibatch Loss= 0.3543, Training Accuracy= 0.835
2018-01-03 18:35:19,122 - root - INFO - Step 2, Minibatch Loss= 0.3543, Training Accuracy= 0.835
2018-01-03 18:35:19,172 : INFO : Step 2, Validation Loss= 0.4765, Validation Accuracy= 0.751
2018-01-03 18:35:19,172 - root - INFO - Step 2, Validation Loss= 0.4765, Validation Accuracy= 0.751
2018-01-03 18:35:19,172 - root - INFO - Step 2, Validation Loss= 0.4765, Validation Accuracy= 0.751
2018-01-03 18:35:21,149 : INFO : Step 3, Minibatch Loss= 0.2469, Training Accuracy= 0.889
2018-01-03 18:35:21,149 - root - INFO - Step 3, Minibatch Loss= 0.2469, Training Accuracy= 0.889
2018-01-03 18:35:21,149 - root - INFO - Step 3, Minibatch Loss= 0.2469, Training Accuracy= 0.889
2018-01-03 18:35:21,203 : INFO : Step 3, Validation Loss= 0.3919, Validation Accuracy= 0.796
2018-01-03 18:35:21,203 - root - INFO - Step 3, Validation Loss= 0.3919, Validation Accuracy= 0.796
2018-01-03 18:35:21,203 - root - INFO - Step 3, Validation Loss= 0.3919, Validation Accuracy= 0.796
2018-01-03 18:35:23,150 : INFO : Step 4, Minibatch Loss= 0.2244, Training Accuracy= 0.915
2018-01-03 18:35:23,150 - root - INFO - Step 4, Minibatch Loss= 0.2244, Training Accuracy= 0.915
2018-01-03 18:35:23,150 - root - INFO - Step 4, Minibatch Loss= 0.2244, Training Accuracy= 0.915
2018-01-03 18:35:23,204 : INFO : Step 4, Validation Loss= 0.4931, Validation Accuracy= 0.819
2018-01-03 18:35:23,204 - root - INFO - Step 4, Validation Loss= 0.4931, Validation Accuracy= 0.819
2018-01-03 18:35:23,204 - root - INFO - Step 4, Validation Loss= 0.4931, Validation Accuracy= 0.819
2018-01-03 18:35:25,185 : INFO : Step 5, Minibatch Loss= 0.1927, Training Accuracy= 0.924
2018-01-03 18:35:25,185 - root - INFO - Step 5, Minibatch Loss= 0.1927, Training Accuracy= 0.924
2018-01-03 18:35:25,185 - root - INFO - Step 5, Minibatch Loss= 0.1927, Training Accuracy= 0.924
2018-01-03 18:35:25,237 : INFO : Step 5, Validation Loss= 0.3647, Validation Accuracy= 0.843
2018-01-03 18:35:25,237 - root - INFO - Step 5, Validation Loss= 0.3647, Validation Accuracy= 0.843
2018-01-03 18:35:25,237 - root - INFO - Step 5, Validation Loss= 0.3647, Validation Accuracy= 0.843
2018-01-03 18:35:27,158 : INFO : Step 6, Minibatch Loss= 0.1572, Training Accuracy= 0.937
2018-01-03 18:35:27,158 - root - INFO - Step 6, Minibatch Loss= 0.1572, Training Accuracy= 0.937
2018-01-03 18:35:27,158 - root - INFO - Step 6, Minibatch Loss= 0.1572, Training Accuracy= 0.937
2018-01-03 18:35:27,209 : INFO : Step 6, Validation Loss= 0.5254, Validation Accuracy= 0.837
2018-01-03 18:35:27,209 - root - INFO - Step 6, Validation Loss= 0.5254, Validation Accuracy= 0.837
2018-01-03 18:35:27,209 - root - INFO - Step 6, Validation Loss= 0.5254, Validation Accuracy= 0.837
2018-01-03 18:35:27,209 : INFO : starting fold 7 in 10-fold CV
2018-01-03 18:35:27,209 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:35:27,209 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:35:34,155 : INFO : Step 1, Minibatch Loss= 0.9970, Training Accuracy= 0.557
2018-01-03 18:35:34,155 - root - INFO - Step 1, Minibatch Loss= 0.9970, Training Accuracy= 0.557
2018-01-03 18:35:34,155 - root - INFO - Step 1, Minibatch Loss= 0.9970, Training Accuracy= 0.557
2018-01-03 18:35:34,213 : INFO : Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.751
2018-01-03 18:35:34,213 - root - INFO - Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.751
2018-01-03 18:35:34,213 - root - INFO - Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.751
2018-01-03 18:35:36,135 : INFO : Step 2, Minibatch Loss= 0.5444, Training Accuracy= 0.812
2018-01-03 18:35:36,135 - root - INFO - Step 2, Minibatch Loss= 0.5444, Training Accuracy= 0.812
2018-01-03 18:35:36,135 - root - INFO - Step 2, Minibatch Loss= 0.5444, Training Accuracy= 0.812
2018-01-03 18:35:36,189 : INFO : Step 2, Validation Loss= 0.4406, Validation Accuracy= 0.858
2018-01-03 18:35:36,189 - root - INFO - Step 2, Validation Loss= 0.4406, Validation Accuracy= 0.858
2018-01-03 18:35:36,189 - root - INFO - Step 2, Validation Loss= 0.4406, Validation Accuracy= 0.858
2018-01-03 18:35:38,162 : INFO : Step 3, Minibatch Loss= 0.4123, Training Accuracy= 0.846
2018-01-03 18:35:38,162 - root - INFO - Step 3, Minibatch Loss= 0.4123, Training Accuracy= 0.846
2018-01-03 18:35:38,162 - root - INFO - Step 3, Minibatch Loss= 0.4123, Training Accuracy= 0.846
2018-01-03 18:35:38,215 : INFO : Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.873
2018-01-03 18:35:38,215 - root - INFO - Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.873
2018-01-03 18:35:38,215 - root - INFO - Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.873
2018-01-03 18:35:40,142 : INFO : Step 4, Minibatch Loss= 0.3655, Training Accuracy= 0.878
2018-01-03 18:35:40,142 - root - INFO - Step 4, Minibatch Loss= 0.3655, Training Accuracy= 0.878
2018-01-03 18:35:40,142 - root - INFO - Step 4, Minibatch Loss= 0.3655, Training Accuracy= 0.878
2018-01-03 18:35:40,197 : INFO : Step 4, Validation Loss= 0.4435, Validation Accuracy= 0.895
2018-01-03 18:35:40,197 - root - INFO - Step 4, Validation Loss= 0.4435, Validation Accuracy= 0.895
2018-01-03 18:35:40,197 - root - INFO - Step 4, Validation Loss= 0.4435, Validation Accuracy= 0.895
2018-01-03 18:35:42,122 : INFO : Step 5, Minibatch Loss= 0.2925, Training Accuracy= 0.903
2018-01-03 18:35:42,122 - root - INFO - Step 5, Minibatch Loss= 0.2925, Training Accuracy= 0.903
2018-01-03 18:35:42,122 - root - INFO - Step 5, Minibatch Loss= 0.2925, Training Accuracy= 0.903
2018-01-03 18:35:42,183 : INFO : Step 5, Validation Loss= 0.4333, Validation Accuracy= 0.910
2018-01-03 18:35:42,183 - root - INFO - Step 5, Validation Loss= 0.4333, Validation Accuracy= 0.910
2018-01-03 18:35:42,183 - root - INFO - Step 5, Validation Loss= 0.4333, Validation Accuracy= 0.910
2018-01-03 18:35:44,096 : INFO : Step 6, Minibatch Loss= 0.2776, Training Accuracy= 0.911
2018-01-03 18:35:44,096 - root - INFO - Step 6, Minibatch Loss= 0.2776, Training Accuracy= 0.911
2018-01-03 18:35:44,096 - root - INFO - Step 6, Minibatch Loss= 0.2776, Training Accuracy= 0.911
2018-01-03 18:35:44,152 : INFO : Step 6, Validation Loss= 0.5359, Validation Accuracy= 0.897
2018-01-03 18:35:44,152 - root - INFO - Step 6, Validation Loss= 0.5359, Validation Accuracy= 0.897
2018-01-03 18:35:44,152 - root - INFO - Step 6, Validation Loss= 0.5359, Validation Accuracy= 0.897
2018-01-03 18:35:44,152 : INFO : starting fold 8 in 10-fold CV
2018-01-03 18:35:44,152 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:35:44,152 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:35:52,195 : INFO : Step 1, Minibatch Loss= 0.5255, Training Accuracy= 0.787
2018-01-03 18:35:52,195 - root - INFO - Step 1, Minibatch Loss= 0.5255, Training Accuracy= 0.787
2018-01-03 18:35:52,195 - root - INFO - Step 1, Minibatch Loss= 0.5255, Training Accuracy= 0.787
2018-01-03 18:35:52,258 : INFO : Step 1, Validation Loss= 0.5440, Validation Accuracy= 0.731
2018-01-03 18:35:52,258 - root - INFO - Step 1, Validation Loss= 0.5440, Validation Accuracy= 0.731
2018-01-03 18:35:52,258 - root - INFO - Step 1, Validation Loss= 0.5440, Validation Accuracy= 0.731
2018-01-03 18:35:54,194 : INFO : Step 2, Minibatch Loss= 0.2733, Training Accuracy= 0.902
2018-01-03 18:35:54,194 - root - INFO - Step 2, Minibatch Loss= 0.2733, Training Accuracy= 0.902
2018-01-03 18:35:54,194 - root - INFO - Step 2, Minibatch Loss= 0.2733, Training Accuracy= 0.902
2018-01-03 18:35:54,247 : INFO : Step 2, Validation Loss= 0.3636, Validation Accuracy= 0.817
2018-01-03 18:35:54,247 - root - INFO - Step 2, Validation Loss= 0.3636, Validation Accuracy= 0.817
2018-01-03 18:35:54,247 - root - INFO - Step 2, Validation Loss= 0.3636, Validation Accuracy= 0.817
2018-01-03 18:35:56,212 : INFO : Step 3, Minibatch Loss= 0.2202, Training Accuracy= 0.910
2018-01-03 18:35:56,212 - root - INFO - Step 3, Minibatch Loss= 0.2202, Training Accuracy= 0.910
2018-01-03 18:35:56,212 - root - INFO - Step 3, Minibatch Loss= 0.2202, Training Accuracy= 0.910
2018-01-03 18:35:56,266 : INFO : Step 3, Validation Loss= 0.4265, Validation Accuracy= 0.837
2018-01-03 18:35:56,266 - root - INFO - Step 3, Validation Loss= 0.4265, Validation Accuracy= 0.837
2018-01-03 18:35:56,266 - root - INFO - Step 3, Validation Loss= 0.4265, Validation Accuracy= 0.837
2018-01-03 18:35:58,166 : INFO : Step 4, Minibatch Loss= 0.1752, Training Accuracy= 0.917
2018-01-03 18:35:58,166 - root - INFO - Step 4, Minibatch Loss= 0.1752, Training Accuracy= 0.917
2018-01-03 18:35:58,166 - root - INFO - Step 4, Minibatch Loss= 0.1752, Training Accuracy= 0.917
2018-01-03 18:35:58,223 : INFO : Step 4, Validation Loss= 0.2543, Validation Accuracy= 0.843
2018-01-03 18:35:58,223 - root - INFO - Step 4, Validation Loss= 0.2543, Validation Accuracy= 0.843
2018-01-03 18:35:58,223 - root - INFO - Step 4, Validation Loss= 0.2543, Validation Accuracy= 0.843
2018-01-03 18:36:00,322 : INFO : Step 5, Minibatch Loss= 0.1438, Training Accuracy= 0.924
2018-01-03 18:36:00,322 - root - INFO - Step 5, Minibatch Loss= 0.1438, Training Accuracy= 0.924
2018-01-03 18:36:00,322 - root - INFO - Step 5, Minibatch Loss= 0.1438, Training Accuracy= 0.924
2018-01-03 18:36:00,386 : INFO : Step 5, Validation Loss= 0.2231, Validation Accuracy= 0.882
2018-01-03 18:36:00,386 - root - INFO - Step 5, Validation Loss= 0.2231, Validation Accuracy= 0.882
2018-01-03 18:36:00,386 - root - INFO - Step 5, Validation Loss= 0.2231, Validation Accuracy= 0.882
2018-01-03 18:36:02,397 : INFO : Step 6, Minibatch Loss= 0.1312, Training Accuracy= 0.931
2018-01-03 18:36:02,397 - root - INFO - Step 6, Minibatch Loss= 0.1312, Training Accuracy= 0.931
2018-01-03 18:36:02,397 - root - INFO - Step 6, Minibatch Loss= 0.1312, Training Accuracy= 0.931
2018-01-03 18:36:02,453 : INFO : Step 6, Validation Loss= 0.2818, Validation Accuracy= 0.862
2018-01-03 18:36:02,453 - root - INFO - Step 6, Validation Loss= 0.2818, Validation Accuracy= 0.862
2018-01-03 18:36:02,453 - root - INFO - Step 6, Validation Loss= 0.2818, Validation Accuracy= 0.862
2018-01-03 18:36:02,453 : INFO : starting fold 9 in 10-fold CV
2018-01-03 18:36:02,453 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:36:02,453 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:36:09,381 : INFO : Step 1, Minibatch Loss= 0.5289, Training Accuracy= 0.727
2018-01-03 18:36:09,381 - root - INFO - Step 1, Minibatch Loss= 0.5289, Training Accuracy= 0.727
2018-01-03 18:36:09,381 - root - INFO - Step 1, Minibatch Loss= 0.5289, Training Accuracy= 0.727
2018-01-03 18:36:09,434 : INFO : Step 1, Validation Loss= 0.5373, Validation Accuracy= 0.783
2018-01-03 18:36:09,434 - root - INFO - Step 1, Validation Loss= 0.5373, Validation Accuracy= 0.783
2018-01-03 18:36:09,434 - root - INFO - Step 1, Validation Loss= 0.5373, Validation Accuracy= 0.783
2018-01-03 18:36:11,374 : INFO : Step 2, Minibatch Loss= 0.3233, Training Accuracy= 0.857
2018-01-03 18:36:11,374 - root - INFO - Step 2, Minibatch Loss= 0.3233, Training Accuracy= 0.857
2018-01-03 18:36:11,374 - root - INFO - Step 2, Minibatch Loss= 0.3233, Training Accuracy= 0.857
2018-01-03 18:36:11,424 : INFO : Step 2, Validation Loss= 0.3596, Validation Accuracy= 0.858
2018-01-03 18:36:11,424 - root - INFO - Step 2, Validation Loss= 0.3596, Validation Accuracy= 0.858
2018-01-03 18:36:11,424 - root - INFO - Step 2, Validation Loss= 0.3596, Validation Accuracy= 0.858
2018-01-03 18:36:13,369 : INFO : Step 3, Minibatch Loss= 0.2294, Training Accuracy= 0.894
2018-01-03 18:36:13,369 - root - INFO - Step 3, Minibatch Loss= 0.2294, Training Accuracy= 0.894
2018-01-03 18:36:13,369 - root - INFO - Step 3, Minibatch Loss= 0.2294, Training Accuracy= 0.894
2018-01-03 18:36:13,418 : INFO : Step 3, Validation Loss= 0.3492, Validation Accuracy= 0.871
2018-01-03 18:36:13,418 - root - INFO - Step 3, Validation Loss= 0.3492, Validation Accuracy= 0.871
2018-01-03 18:36:13,418 - root - INFO - Step 3, Validation Loss= 0.3492, Validation Accuracy= 0.871
2018-01-03 18:36:15,353 : INFO : Step 4, Minibatch Loss= 0.2012, Training Accuracy= 0.909
2018-01-03 18:36:15,353 - root - INFO - Step 4, Minibatch Loss= 0.2012, Training Accuracy= 0.909
2018-01-03 18:36:15,353 - root - INFO - Step 4, Minibatch Loss= 0.2012, Training Accuracy= 0.909
2018-01-03 18:36:15,403 : INFO : Step 4, Validation Loss= 0.2828, Validation Accuracy= 0.899
2018-01-03 18:36:15,403 - root - INFO - Step 4, Validation Loss= 0.2828, Validation Accuracy= 0.899
2018-01-03 18:36:15,403 - root - INFO - Step 4, Validation Loss= 0.2828, Validation Accuracy= 0.899
2018-01-03 18:36:17,345 : INFO : Step 5, Minibatch Loss= 0.1552, Training Accuracy= 0.919
2018-01-03 18:36:17,345 - root - INFO - Step 5, Minibatch Loss= 0.1552, Training Accuracy= 0.919
2018-01-03 18:36:17,345 - root - INFO - Step 5, Minibatch Loss= 0.1552, Training Accuracy= 0.919
2018-01-03 18:36:17,399 : INFO : Step 5, Validation Loss= 0.3163, Validation Accuracy= 0.860
2018-01-03 18:36:17,399 - root - INFO - Step 5, Validation Loss= 0.3163, Validation Accuracy= 0.860
2018-01-03 18:36:17,399 - root - INFO - Step 5, Validation Loss= 0.3163, Validation Accuracy= 0.860
2018-01-03 18:36:17,399 : INFO : starting fold 10 in 10-fold CV
2018-01-03 18:36:17,399 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:36:17,399 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:36:24,070 : INFO : Step 1, Minibatch Loss= 0.6344, Training Accuracy= 0.655
2018-01-03 18:36:24,070 - root - INFO - Step 1, Minibatch Loss= 0.6344, Training Accuracy= 0.655
2018-01-03 18:36:24,070 - root - INFO - Step 1, Minibatch Loss= 0.6344, Training Accuracy= 0.655
2018-01-03 18:36:24,131 : INFO : Step 1, Validation Loss= 0.5351, Validation Accuracy= 0.770
2018-01-03 18:36:24,131 - root - INFO - Step 1, Validation Loss= 0.5351, Validation Accuracy= 0.770
2018-01-03 18:36:24,131 - root - INFO - Step 1, Validation Loss= 0.5351, Validation Accuracy= 0.770
2018-01-03 18:36:26,074 : INFO : Step 2, Minibatch Loss= 0.3332, Training Accuracy= 0.847
2018-01-03 18:36:26,074 - root - INFO - Step 2, Minibatch Loss= 0.3332, Training Accuracy= 0.847
2018-01-03 18:36:26,074 - root - INFO - Step 2, Minibatch Loss= 0.3332, Training Accuracy= 0.847
2018-01-03 18:36:26,129 : INFO : Step 2, Validation Loss= 0.3926, Validation Accuracy= 0.860
2018-01-03 18:36:26,129 - root - INFO - Step 2, Validation Loss= 0.3926, Validation Accuracy= 0.860
2018-01-03 18:36:26,129 - root - INFO - Step 2, Validation Loss= 0.3926, Validation Accuracy= 0.860
2018-01-03 18:36:28,080 : INFO : Step 3, Minibatch Loss= 0.2509, Training Accuracy= 0.882
2018-01-03 18:36:28,080 - root - INFO - Step 3, Minibatch Loss= 0.2509, Training Accuracy= 0.882
2018-01-03 18:36:28,080 - root - INFO - Step 3, Minibatch Loss= 0.2509, Training Accuracy= 0.882
2018-01-03 18:36:28,132 : INFO : Step 3, Validation Loss= 0.3613, Validation Accuracy= 0.869
2018-01-03 18:36:28,132 - root - INFO - Step 3, Validation Loss= 0.3613, Validation Accuracy= 0.869
2018-01-03 18:36:28,132 - root - INFO - Step 3, Validation Loss= 0.3613, Validation Accuracy= 0.869
2018-01-03 18:36:29,919 : INFO : Step 4, Minibatch Loss= 0.2363, Training Accuracy= 0.884
2018-01-03 18:36:29,919 - root - INFO - Step 4, Minibatch Loss= 0.2363, Training Accuracy= 0.884
2018-01-03 18:36:29,919 - root - INFO - Step 4, Minibatch Loss= 0.2363, Training Accuracy= 0.884
2018-01-03 18:36:29,972 : INFO : Step 4, Validation Loss= 0.3685, Validation Accuracy= 0.882
2018-01-03 18:36:29,972 - root - INFO - Step 4, Validation Loss= 0.3685, Validation Accuracy= 0.882
2018-01-03 18:36:29,972 - root - INFO - Step 4, Validation Loss= 0.3685, Validation Accuracy= 0.882
2018-01-03 18:36:31,860 : INFO : Step 5, Minibatch Loss= 0.1900, Training Accuracy= 0.904
2018-01-03 18:36:31,860 - root - INFO - Step 5, Minibatch Loss= 0.1900, Training Accuracy= 0.904
2018-01-03 18:36:31,860 - root - INFO - Step 5, Minibatch Loss= 0.1900, Training Accuracy= 0.904
2018-01-03 18:36:31,918 : INFO : Step 5, Validation Loss= 0.4147, Validation Accuracy= 0.875
2018-01-03 18:36:31,918 - root - INFO - Step 5, Validation Loss= 0.4147, Validation Accuracy= 0.875
2018-01-03 18:36:31,918 - root - INFO - Step 5, Validation Loss= 0.4147, Validation Accuracy= 0.875
2018-01-03 18:36:31,919 : INFO : Average accuracy is 0.893763 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:36:31,919 - root - INFO - Average accuracy is 0.893763 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:36:31,919 - root - INFO - Average accuracy is 0.893763 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:36:31,919 : INFO : This 10-fold CV run-time: 141.77324104309082 seconds
2018-01-03 18:36:31,919 - root - INFO - This 10-fold CV run-time: 141.77324104309082 seconds
2018-01-03 18:36:31,919 - root - INFO - This 10-fold CV run-time: 141.77324104309082 seconds
2018-01-03 18:36:32,072 : INFO : current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:36:32,072 - root - INFO - current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:36:32,072 - root - INFO - current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:36:32,552 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:36:32,552 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:36:32,552 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:36:32,552 : INFO : collecting all words and their counts
2018-01-03 18:36:32,552 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:36:32,552 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:36:32,553 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:36:32,553 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:36:32,553 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:36:32,582 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:36:32,582 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:36:32,582 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:36:32,583 : INFO : Loading a fresh vocabulary
2018-01-03 18:36:32,583 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:36:32,583 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:36:32,601 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:36:32,601 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:36:32,601 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:36:32,602 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:36:32,602 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:36:32,602 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:36:32,618 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 18:36:32,618 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:36:32,618 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:36:32,619 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:36:32,619 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:36:32,619 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:36:32,619 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:36:32,631 : INFO : resetting layer weights
2018-01-03 18:36:32,631 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:36:32,631 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:36:32,705 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:32,705 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:32,705 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:33,135 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,135 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,135 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,141 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,141 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,141 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,143 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,143 : INFO : training on 797984 raw words (558607 effective words) took 0.4s, 1286545 effective words/s
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.4s, 1286545 effective words/s
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - training on 797984 raw words (558607 effective words) took 0.4s, 1286545 effective words/s
2018-01-03 18:36:33,143 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:33,143 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:36:33,594 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,594 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,594 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:36:33,598 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,598 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,598 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:36:33,600 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,600 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,600 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:36:33,600 : INFO : training on 797984 raw words (558916 effective words) took 0.5s, 1235660 effective words/s
2018-01-03 18:36:33,600 - gensim.models.word2vec - INFO - training on 797984 raw words (558916 effective words) took 0.5s, 1235660 effective words/s
2018-01-03 18:36:33,600 - gensim.models.word2vec - INFO - training on 797984 raw words (558916 effective words) took 0.5s, 1235660 effective words/s
2018-01-03 18:36:54,269 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:36:54,269 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:36:54,269 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:36:54,269 : INFO : starting fold 1 in 10-fold CV
2018-01-03 18:36:54,269 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:36:54,269 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:37:02,344 : INFO : Step 1, Minibatch Loss= 0.9216, Training Accuracy= 0.617
2018-01-03 18:37:02,344 - root - INFO - Step 1, Minibatch Loss= 0.9216, Training Accuracy= 0.617
2018-01-03 18:37:02,344 - root - INFO - Step 1, Minibatch Loss= 0.9216, Training Accuracy= 0.617
2018-01-03 18:37:02,409 : INFO : Step 1, Validation Loss= 1.5573, Validation Accuracy= 0.301
2018-01-03 18:37:02,409 - root - INFO - Step 1, Validation Loss= 1.5573, Validation Accuracy= 0.301
2018-01-03 18:37:02,409 - root - INFO - Step 1, Validation Loss= 1.5573, Validation Accuracy= 0.301
2018-01-03 18:37:04,570 : INFO : Step 2, Minibatch Loss= 0.4595, Training Accuracy= 0.854
2018-01-03 18:37:04,570 - root - INFO - Step 2, Minibatch Loss= 0.4595, Training Accuracy= 0.854
2018-01-03 18:37:04,570 - root - INFO - Step 2, Minibatch Loss= 0.4595, Training Accuracy= 0.854
2018-01-03 18:37:04,632 : INFO : Step 2, Validation Loss= 0.8025, Validation Accuracy= 0.690
2018-01-03 18:37:04,632 - root - INFO - Step 2, Validation Loss= 0.8025, Validation Accuracy= 0.690
2018-01-03 18:37:04,632 - root - INFO - Step 2, Validation Loss= 0.8025, Validation Accuracy= 0.690
2018-01-03 18:37:06,670 : INFO : Step 3, Minibatch Loss= 0.3463, Training Accuracy= 0.883
2018-01-03 18:37:06,670 - root - INFO - Step 3, Minibatch Loss= 0.3463, Training Accuracy= 0.883
2018-01-03 18:37:06,670 - root - INFO - Step 3, Minibatch Loss= 0.3463, Training Accuracy= 0.883
2018-01-03 18:37:06,733 : INFO : Step 3, Validation Loss= 0.8572, Validation Accuracy= 0.675
2018-01-03 18:37:06,733 - root - INFO - Step 3, Validation Loss= 0.8572, Validation Accuracy= 0.675
2018-01-03 18:37:06,733 - root - INFO - Step 3, Validation Loss= 0.8572, Validation Accuracy= 0.675
2018-01-03 18:37:06,733 : INFO : starting fold 2 in 10-fold CV
2018-01-03 18:37:06,733 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:37:06,733 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:37:15,111 : INFO : Step 1, Minibatch Loss= 0.5444, Training Accuracy= 0.725
2018-01-03 18:37:15,111 - root - INFO - Step 1, Minibatch Loss= 0.5444, Training Accuracy= 0.725
2018-01-03 18:37:15,111 - root - INFO - Step 1, Minibatch Loss= 0.5444, Training Accuracy= 0.725
2018-01-03 18:37:15,171 : INFO : Step 1, Validation Loss= 0.5158, Validation Accuracy= 0.828
2018-01-03 18:37:15,171 - root - INFO - Step 1, Validation Loss= 0.5158, Validation Accuracy= 0.828
2018-01-03 18:37:15,171 - root - INFO - Step 1, Validation Loss= 0.5158, Validation Accuracy= 0.828
2018-01-03 18:37:17,431 : INFO : Step 2, Minibatch Loss= 0.2892, Training Accuracy= 0.901
2018-01-03 18:37:17,431 - root - INFO - Step 2, Minibatch Loss= 0.2892, Training Accuracy= 0.901
2018-01-03 18:37:17,431 - root - INFO - Step 2, Minibatch Loss= 0.2892, Training Accuracy= 0.901
2018-01-03 18:37:17,494 : INFO : Step 2, Validation Loss= 0.4799, Validation Accuracy= 0.905
2018-01-03 18:37:17,494 - root - INFO - Step 2, Validation Loss= 0.4799, Validation Accuracy= 0.905
2018-01-03 18:37:17,494 - root - INFO - Step 2, Validation Loss= 0.4799, Validation Accuracy= 0.905
2018-01-03 18:37:19,591 : INFO : Step 3, Minibatch Loss= 0.1951, Training Accuracy= 0.916
2018-01-03 18:37:19,591 - root - INFO - Step 3, Minibatch Loss= 0.1951, Training Accuracy= 0.916
2018-01-03 18:37:19,591 - root - INFO - Step 3, Minibatch Loss= 0.1951, Training Accuracy= 0.916
2018-01-03 18:37:19,659 : INFO : Step 3, Validation Loss= 0.3603, Validation Accuracy= 0.927
2018-01-03 18:37:19,659 - root - INFO - Step 3, Validation Loss= 0.3603, Validation Accuracy= 0.927
2018-01-03 18:37:19,659 - root - INFO - Step 3, Validation Loss= 0.3603, Validation Accuracy= 0.927
2018-01-03 18:37:21,825 : INFO : Step 4, Minibatch Loss= 0.1316, Training Accuracy= 0.941
2018-01-03 18:37:21,825 - root - INFO - Step 4, Minibatch Loss= 0.1316, Training Accuracy= 0.941
2018-01-03 18:37:21,825 - root - INFO - Step 4, Minibatch Loss= 0.1316, Training Accuracy= 0.941
2018-01-03 18:37:21,886 : INFO : Step 4, Validation Loss= 0.6042, Validation Accuracy= 0.916
2018-01-03 18:37:21,886 - root - INFO - Step 4, Validation Loss= 0.6042, Validation Accuracy= 0.916
2018-01-03 18:37:21,886 - root - INFO - Step 4, Validation Loss= 0.6042, Validation Accuracy= 0.916
2018-01-03 18:37:21,886 : INFO : starting fold 3 in 10-fold CV
2018-01-03 18:37:21,886 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:37:21,886 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:37:29,122 : INFO : Step 1, Minibatch Loss= 0.5342, Training Accuracy= 0.729
2018-01-03 18:37:29,122 - root - INFO - Step 1, Minibatch Loss= 0.5342, Training Accuracy= 0.729
2018-01-03 18:37:29,122 - root - INFO - Step 1, Minibatch Loss= 0.5342, Training Accuracy= 0.729
2018-01-03 18:37:29,184 : INFO : Step 1, Validation Loss= 0.5538, Validation Accuracy= 0.701
2018-01-03 18:37:29,184 - root - INFO - Step 1, Validation Loss= 0.5538, Validation Accuracy= 0.701
2018-01-03 18:37:29,184 - root - INFO - Step 1, Validation Loss= 0.5538, Validation Accuracy= 0.701
2018-01-03 18:37:31,393 : INFO : Step 2, Minibatch Loss= 0.2481, Training Accuracy= 0.883
2018-01-03 18:37:31,393 - root - INFO - Step 2, Minibatch Loss= 0.2481, Training Accuracy= 0.883
2018-01-03 18:37:31,393 - root - INFO - Step 2, Minibatch Loss= 0.2481, Training Accuracy= 0.883
2018-01-03 18:37:31,462 : INFO : Step 2, Validation Loss= 0.2910, Validation Accuracy= 0.875
2018-01-03 18:37:31,462 - root - INFO - Step 2, Validation Loss= 0.2910, Validation Accuracy= 0.875
2018-01-03 18:37:31,462 - root - INFO - Step 2, Validation Loss= 0.2910, Validation Accuracy= 0.875
2018-01-03 18:37:33,522 : INFO : Step 3, Minibatch Loss= 0.1634, Training Accuracy= 0.928
2018-01-03 18:37:33,522 - root - INFO - Step 3, Minibatch Loss= 0.1634, Training Accuracy= 0.928
2018-01-03 18:37:33,522 - root - INFO - Step 3, Minibatch Loss= 0.1634, Training Accuracy= 0.928
2018-01-03 18:37:33,585 : INFO : Step 3, Validation Loss= 0.2951, Validation Accuracy= 0.862
2018-01-03 18:37:33,585 - root - INFO - Step 3, Validation Loss= 0.2951, Validation Accuracy= 0.862
2018-01-03 18:37:33,585 - root - INFO - Step 3, Validation Loss= 0.2951, Validation Accuracy= 0.862
2018-01-03 18:37:33,585 : INFO : starting fold 4 in 10-fold CV
2018-01-03 18:37:33,585 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:37:33,585 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:37:41,503 : INFO : Step 1, Minibatch Loss= 0.4245, Training Accuracy= 0.819
2018-01-03 18:37:41,503 - root - INFO - Step 1, Minibatch Loss= 0.4245, Training Accuracy= 0.819
2018-01-03 18:37:41,503 - root - INFO - Step 1, Minibatch Loss= 0.4245, Training Accuracy= 0.819
2018-01-03 18:37:41,562 : INFO : Step 1, Validation Loss= 0.4440, Validation Accuracy= 0.828
2018-01-03 18:37:41,562 - root - INFO - Step 1, Validation Loss= 0.4440, Validation Accuracy= 0.828
2018-01-03 18:37:41,562 - root - INFO - Step 1, Validation Loss= 0.4440, Validation Accuracy= 0.828
2018-01-03 18:37:43,661 : INFO : Step 2, Minibatch Loss= 0.2597, Training Accuracy= 0.912
2018-01-03 18:37:43,661 - root - INFO - Step 2, Minibatch Loss= 0.2597, Training Accuracy= 0.912
2018-01-03 18:37:43,661 - root - INFO - Step 2, Minibatch Loss= 0.2597, Training Accuracy= 0.912
2018-01-03 18:37:43,722 : INFO : Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.890
2018-01-03 18:37:43,722 - root - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.890
2018-01-03 18:37:43,722 - root - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.890
2018-01-03 18:37:45,919 : INFO : Step 3, Minibatch Loss= 0.1685, Training Accuracy= 0.936
2018-01-03 18:37:45,919 - root - INFO - Step 3, Minibatch Loss= 0.1685, Training Accuracy= 0.936
2018-01-03 18:37:45,919 - root - INFO - Step 3, Minibatch Loss= 0.1685, Training Accuracy= 0.936
2018-01-03 18:37:45,983 : INFO : Step 3, Validation Loss= 0.2471, Validation Accuracy= 0.908
2018-01-03 18:37:45,983 - root - INFO - Step 3, Validation Loss= 0.2471, Validation Accuracy= 0.908
2018-01-03 18:37:45,983 - root - INFO - Step 3, Validation Loss= 0.2471, Validation Accuracy= 0.908
2018-01-03 18:37:48,156 : INFO : Step 4, Minibatch Loss= 0.1264, Training Accuracy= 0.952
2018-01-03 18:37:48,156 - root - INFO - Step 4, Minibatch Loss= 0.1264, Training Accuracy= 0.952
2018-01-03 18:37:48,156 - root - INFO - Step 4, Minibatch Loss= 0.1264, Training Accuracy= 0.952
2018-01-03 18:37:48,218 : INFO : Step 4, Validation Loss= 0.2131, Validation Accuracy= 0.918
2018-01-03 18:37:48,218 - root - INFO - Step 4, Validation Loss= 0.2131, Validation Accuracy= 0.918
2018-01-03 18:37:48,218 - root - INFO - Step 4, Validation Loss= 0.2131, Validation Accuracy= 0.918
2018-01-03 18:37:50,398 : INFO : Step 5, Minibatch Loss= 0.1127, Training Accuracy= 0.947
2018-01-03 18:37:50,398 - root - INFO - Step 5, Minibatch Loss= 0.1127, Training Accuracy= 0.947
2018-01-03 18:37:50,398 - root - INFO - Step 5, Minibatch Loss= 0.1127, Training Accuracy= 0.947
2018-01-03 18:37:50,461 : INFO : Step 5, Validation Loss= 0.2849, Validation Accuracy= 0.918
2018-01-03 18:37:50,461 - root - INFO - Step 5, Validation Loss= 0.2849, Validation Accuracy= 0.918
2018-01-03 18:37:50,461 - root - INFO - Step 5, Validation Loss= 0.2849, Validation Accuracy= 0.918
2018-01-03 18:37:53,010 : INFO : Step 6, Minibatch Loss= 0.0931, Training Accuracy= 0.958
2018-01-03 18:37:53,010 - root - INFO - Step 6, Minibatch Loss= 0.0931, Training Accuracy= 0.958
2018-01-03 18:37:53,010 - root - INFO - Step 6, Minibatch Loss= 0.0931, Training Accuracy= 0.958
2018-01-03 18:37:53,069 : INFO : Step 6, Validation Loss= 0.2979, Validation Accuracy= 0.899
2018-01-03 18:37:53,069 - root - INFO - Step 6, Validation Loss= 0.2979, Validation Accuracy= 0.899
2018-01-03 18:37:53,069 - root - INFO - Step 6, Validation Loss= 0.2979, Validation Accuracy= 0.899
2018-01-03 18:37:53,070 : INFO : starting fold 5 in 10-fold CV
2018-01-03 18:37:53,070 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:37:53,070 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:38:00,391 : INFO : Step 1, Minibatch Loss= 0.5534, Training Accuracy= 0.707
2018-01-03 18:38:00,391 - root - INFO - Step 1, Minibatch Loss= 0.5534, Training Accuracy= 0.707
2018-01-03 18:38:00,391 - root - INFO - Step 1, Minibatch Loss= 0.5534, Training Accuracy= 0.707
2018-01-03 18:38:00,461 : INFO : Step 1, Validation Loss= 0.5247, Validation Accuracy= 0.768
2018-01-03 18:38:00,461 - root - INFO - Step 1, Validation Loss= 0.5247, Validation Accuracy= 0.768
2018-01-03 18:38:00,461 - root - INFO - Step 1, Validation Loss= 0.5247, Validation Accuracy= 0.768
2018-01-03 18:38:02,774 : INFO : Step 2, Minibatch Loss= 0.2477, Training Accuracy= 0.886
2018-01-03 18:38:02,774 - root - INFO - Step 2, Minibatch Loss= 0.2477, Training Accuracy= 0.886
2018-01-03 18:38:02,774 - root - INFO - Step 2, Minibatch Loss= 0.2477, Training Accuracy= 0.886
2018-01-03 18:38:02,836 : INFO : Step 2, Validation Loss= 0.3124, Validation Accuracy= 0.880
2018-01-03 18:38:02,836 - root - INFO - Step 2, Validation Loss= 0.3124, Validation Accuracy= 0.880
2018-01-03 18:38:02,836 - root - INFO - Step 2, Validation Loss= 0.3124, Validation Accuracy= 0.880
2018-01-03 18:38:04,984 : INFO : Step 3, Minibatch Loss= 0.1803, Training Accuracy= 0.927
2018-01-03 18:38:04,984 - root - INFO - Step 3, Minibatch Loss= 0.1803, Training Accuracy= 0.927
2018-01-03 18:38:04,984 - root - INFO - Step 3, Minibatch Loss= 0.1803, Training Accuracy= 0.927
2018-01-03 18:38:05,049 : INFO : Step 3, Validation Loss= 0.4022, Validation Accuracy= 0.860
2018-01-03 18:38:05,049 - root - INFO - Step 3, Validation Loss= 0.4022, Validation Accuracy= 0.860
2018-01-03 18:38:05,049 - root - INFO - Step 3, Validation Loss= 0.4022, Validation Accuracy= 0.860
2018-01-03 18:38:05,049 : INFO : starting fold 6 in 10-fold CV
2018-01-03 18:38:05,049 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:38:05,049 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:38:12,323 : INFO : Step 1, Minibatch Loss= 0.5486, Training Accuracy= 0.722
2018-01-03 18:38:12,323 - root - INFO - Step 1, Minibatch Loss= 0.5486, Training Accuracy= 0.722
2018-01-03 18:38:12,323 - root - INFO - Step 1, Minibatch Loss= 0.5486, Training Accuracy= 0.722
2018-01-03 18:38:12,395 : INFO : Step 1, Validation Loss= 0.6016, Validation Accuracy= 0.647
2018-01-03 18:38:12,395 - root - INFO - Step 1, Validation Loss= 0.6016, Validation Accuracy= 0.647
2018-01-03 18:38:12,395 - root - INFO - Step 1, Validation Loss= 0.6016, Validation Accuracy= 0.647
2018-01-03 18:38:14,634 : INFO : Step 2, Minibatch Loss= 0.2831, Training Accuracy= 0.875
2018-01-03 18:38:14,634 - root - INFO - Step 2, Minibatch Loss= 0.2831, Training Accuracy= 0.875
2018-01-03 18:38:14,634 - root - INFO - Step 2, Minibatch Loss= 0.2831, Training Accuracy= 0.875
2018-01-03 18:38:14,711 : INFO : Step 2, Validation Loss= 0.3820, Validation Accuracy= 0.787
2018-01-03 18:38:14,711 - root - INFO - Step 2, Validation Loss= 0.3820, Validation Accuracy= 0.787
2018-01-03 18:38:14,711 - root - INFO - Step 2, Validation Loss= 0.3820, Validation Accuracy= 0.787
2018-01-03 18:38:16,893 : INFO : Step 3, Minibatch Loss= 0.1998, Training Accuracy= 0.903
2018-01-03 18:38:16,893 - root - INFO - Step 3, Minibatch Loss= 0.1998, Training Accuracy= 0.903
2018-01-03 18:38:16,893 - root - INFO - Step 3, Minibatch Loss= 0.1998, Training Accuracy= 0.903
2018-01-03 18:38:16,953 : INFO : Step 3, Validation Loss= 0.3715, Validation Accuracy= 0.830
2018-01-03 18:38:16,953 - root - INFO - Step 3, Validation Loss= 0.3715, Validation Accuracy= 0.830
2018-01-03 18:38:16,953 - root - INFO - Step 3, Validation Loss= 0.3715, Validation Accuracy= 0.830
2018-01-03 18:38:19,114 : INFO : Step 4, Minibatch Loss= 0.1485, Training Accuracy= 0.932
2018-01-03 18:38:19,114 - root - INFO - Step 4, Minibatch Loss= 0.1485, Training Accuracy= 0.932
2018-01-03 18:38:19,114 - root - INFO - Step 4, Minibatch Loss= 0.1485, Training Accuracy= 0.932
2018-01-03 18:38:19,173 : INFO : Step 4, Validation Loss= 0.2740, Validation Accuracy= 0.871
2018-01-03 18:38:19,173 - root - INFO - Step 4, Validation Loss= 0.2740, Validation Accuracy= 0.871
2018-01-03 18:38:19,173 - root - INFO - Step 4, Validation Loss= 0.2740, Validation Accuracy= 0.871
2018-01-03 18:38:21,339 : INFO : Step 5, Minibatch Loss= 0.1474, Training Accuracy= 0.940
2018-01-03 18:38:21,339 - root - INFO - Step 5, Minibatch Loss= 0.1474, Training Accuracy= 0.940
2018-01-03 18:38:21,339 - root - INFO - Step 5, Minibatch Loss= 0.1474, Training Accuracy= 0.940
2018-01-03 18:38:21,408 : INFO : Step 5, Validation Loss= 0.4436, Validation Accuracy= 0.884
2018-01-03 18:38:21,408 - root - INFO - Step 5, Validation Loss= 0.4436, Validation Accuracy= 0.884
2018-01-03 18:38:21,408 - root - INFO - Step 5, Validation Loss= 0.4436, Validation Accuracy= 0.884
2018-01-03 18:38:23,478 : INFO : Step 6, Minibatch Loss= 0.1236, Training Accuracy= 0.942
2018-01-03 18:38:23,478 - root - INFO - Step 6, Minibatch Loss= 0.1236, Training Accuracy= 0.942
2018-01-03 18:38:23,478 - root - INFO - Step 6, Minibatch Loss= 0.1236, Training Accuracy= 0.942
2018-01-03 18:38:23,537 : INFO : Step 6, Validation Loss= 0.3532, Validation Accuracy= 0.865
2018-01-03 18:38:23,537 - root - INFO - Step 6, Validation Loss= 0.3532, Validation Accuracy= 0.865
2018-01-03 18:38:23,537 - root - INFO - Step 6, Validation Loss= 0.3532, Validation Accuracy= 0.865
2018-01-03 18:38:23,538 : INFO : starting fold 7 in 10-fold CV
2018-01-03 18:38:23,538 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:38:23,538 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:38:31,610 : INFO : Step 1, Minibatch Loss= 0.5787, Training Accuracy= 0.698
2018-01-03 18:38:31,610 - root - INFO - Step 1, Minibatch Loss= 0.5787, Training Accuracy= 0.698
2018-01-03 18:38:31,610 - root - INFO - Step 1, Minibatch Loss= 0.5787, Training Accuracy= 0.698
2018-01-03 18:38:31,676 : INFO : Step 1, Validation Loss= 0.4932, Validation Accuracy= 0.822
2018-01-03 18:38:31,676 - root - INFO - Step 1, Validation Loss= 0.4932, Validation Accuracy= 0.822
2018-01-03 18:38:31,676 - root - INFO - Step 1, Validation Loss= 0.4932, Validation Accuracy= 0.822
2018-01-03 18:38:33,789 : INFO : Step 2, Minibatch Loss= 0.2729, Training Accuracy= 0.900
2018-01-03 18:38:33,789 - root - INFO - Step 2, Minibatch Loss= 0.2729, Training Accuracy= 0.900
2018-01-03 18:38:33,789 - root - INFO - Step 2, Minibatch Loss= 0.2729, Training Accuracy= 0.900
2018-01-03 18:38:33,851 : INFO : Step 2, Validation Loss= 0.5825, Validation Accuracy= 0.875
2018-01-03 18:38:33,851 - root - INFO - Step 2, Validation Loss= 0.5825, Validation Accuracy= 0.875
2018-01-03 18:38:33,851 - root - INFO - Step 2, Validation Loss= 0.5825, Validation Accuracy= 0.875
2018-01-03 18:38:35,980 : INFO : Step 3, Minibatch Loss= 0.1860, Training Accuracy= 0.918
2018-01-03 18:38:35,980 - root - INFO - Step 3, Minibatch Loss= 0.1860, Training Accuracy= 0.918
2018-01-03 18:38:35,980 - root - INFO - Step 3, Minibatch Loss= 0.1860, Training Accuracy= 0.918
2018-01-03 18:38:36,044 : INFO : Step 3, Validation Loss= 0.3349, Validation Accuracy= 0.895
2018-01-03 18:38:36,044 - root - INFO - Step 3, Validation Loss= 0.3349, Validation Accuracy= 0.895
2018-01-03 18:38:36,044 - root - INFO - Step 3, Validation Loss= 0.3349, Validation Accuracy= 0.895
2018-01-03 18:38:38,208 : INFO : Step 4, Minibatch Loss= 0.1751, Training Accuracy= 0.930
2018-01-03 18:38:38,208 - root - INFO - Step 4, Minibatch Loss= 0.1751, Training Accuracy= 0.930
2018-01-03 18:38:38,208 - root - INFO - Step 4, Minibatch Loss= 0.1751, Training Accuracy= 0.930
2018-01-03 18:38:38,271 : INFO : Step 4, Validation Loss= 0.7339, Validation Accuracy= 0.901
2018-01-03 18:38:38,271 - root - INFO - Step 4, Validation Loss= 0.7339, Validation Accuracy= 0.901
2018-01-03 18:38:38,271 - root - INFO - Step 4, Validation Loss= 0.7339, Validation Accuracy= 0.901
2018-01-03 18:38:40,330 : INFO : Step 5, Minibatch Loss= 0.1429, Training Accuracy= 0.930
2018-01-03 18:38:40,330 - root - INFO - Step 5, Minibatch Loss= 0.1429, Training Accuracy= 0.930
2018-01-03 18:38:40,330 - root - INFO - Step 5, Minibatch Loss= 0.1429, Training Accuracy= 0.930
2018-01-03 18:38:40,391 : INFO : Step 5, Validation Loss= 0.3270, Validation Accuracy= 0.933
2018-01-03 18:38:40,391 - root - INFO - Step 5, Validation Loss= 0.3270, Validation Accuracy= 0.933
2018-01-03 18:38:40,391 - root - INFO - Step 5, Validation Loss= 0.3270, Validation Accuracy= 0.933
2018-01-03 18:38:42,461 : INFO : Step 6, Minibatch Loss= 0.1110, Training Accuracy= 0.950
2018-01-03 18:38:42,461 - root - INFO - Step 6, Minibatch Loss= 0.1110, Training Accuracy= 0.950
2018-01-03 18:38:42,461 - root - INFO - Step 6, Minibatch Loss= 0.1110, Training Accuracy= 0.950
2018-01-03 18:38:42,523 : INFO : Step 6, Validation Loss= 0.3919, Validation Accuracy= 0.914
2018-01-03 18:38:42,523 - root - INFO - Step 6, Validation Loss= 0.3919, Validation Accuracy= 0.914
2018-01-03 18:38:42,523 - root - INFO - Step 6, Validation Loss= 0.3919, Validation Accuracy= 0.914
2018-01-03 18:38:42,524 : INFO : starting fold 8 in 10-fold CV
2018-01-03 18:38:42,524 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:38:42,524 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:38:50,211 : INFO : Step 1, Minibatch Loss= 0.4925, Training Accuracy= 0.800
2018-01-03 18:38:50,211 - root - INFO - Step 1, Minibatch Loss= 0.4925, Training Accuracy= 0.800
2018-01-03 18:38:50,211 - root - INFO - Step 1, Minibatch Loss= 0.4925, Training Accuracy= 0.800
2018-01-03 18:38:50,279 : INFO : Step 1, Validation Loss= 0.5206, Validation Accuracy= 0.796
2018-01-03 18:38:50,279 - root - INFO - Step 1, Validation Loss= 0.5206, Validation Accuracy= 0.796
2018-01-03 18:38:50,279 - root - INFO - Step 1, Validation Loss= 0.5206, Validation Accuracy= 0.796
2018-01-03 18:38:52,423 : INFO : Step 2, Minibatch Loss= 0.2199, Training Accuracy= 0.913
2018-01-03 18:38:52,423 - root - INFO - Step 2, Minibatch Loss= 0.2199, Training Accuracy= 0.913
2018-01-03 18:38:52,423 - root - INFO - Step 2, Minibatch Loss= 0.2199, Training Accuracy= 0.913
2018-01-03 18:38:52,489 : INFO : Step 2, Validation Loss= 0.3002, Validation Accuracy= 0.875
2018-01-03 18:38:52,489 - root - INFO - Step 2, Validation Loss= 0.3002, Validation Accuracy= 0.875
2018-01-03 18:38:52,489 - root - INFO - Step 2, Validation Loss= 0.3002, Validation Accuracy= 0.875
2018-01-03 18:38:54,644 : INFO : Step 3, Minibatch Loss= 0.1617, Training Accuracy= 0.940
2018-01-03 18:38:54,644 - root - INFO - Step 3, Minibatch Loss= 0.1617, Training Accuracy= 0.940
2018-01-03 18:38:54,644 - root - INFO - Step 3, Minibatch Loss= 0.1617, Training Accuracy= 0.940
2018-01-03 18:38:54,710 : INFO : Step 3, Validation Loss= 0.2954, Validation Accuracy= 0.888
2018-01-03 18:38:54,710 - root - INFO - Step 3, Validation Loss= 0.2954, Validation Accuracy= 0.888
2018-01-03 18:38:54,710 - root - INFO - Step 3, Validation Loss= 0.2954, Validation Accuracy= 0.888
2018-01-03 18:38:56,825 : INFO : Step 4, Minibatch Loss= 0.1293, Training Accuracy= 0.945
2018-01-03 18:38:56,825 - root - INFO - Step 4, Minibatch Loss= 0.1293, Training Accuracy= 0.945
2018-01-03 18:38:56,825 - root - INFO - Step 4, Minibatch Loss= 0.1293, Training Accuracy= 0.945
2018-01-03 18:38:56,887 : INFO : Step 4, Validation Loss= 0.3586, Validation Accuracy= 0.890
2018-01-03 18:38:56,887 - root - INFO - Step 4, Validation Loss= 0.3586, Validation Accuracy= 0.890
2018-01-03 18:38:56,887 - root - INFO - Step 4, Validation Loss= 0.3586, Validation Accuracy= 0.890
2018-01-03 18:38:59,051 : INFO : Step 5, Minibatch Loss= 0.1191, Training Accuracy= 0.946
2018-01-03 18:38:59,051 - root - INFO - Step 5, Minibatch Loss= 0.1191, Training Accuracy= 0.946
2018-01-03 18:38:59,051 - root - INFO - Step 5, Minibatch Loss= 0.1191, Training Accuracy= 0.946
2018-01-03 18:38:59,114 : INFO : Step 5, Validation Loss= 0.2796, Validation Accuracy= 0.901
2018-01-03 18:38:59,114 - root - INFO - Step 5, Validation Loss= 0.2796, Validation Accuracy= 0.901
2018-01-03 18:38:59,114 - root - INFO - Step 5, Validation Loss= 0.2796, Validation Accuracy= 0.901
2018-01-03 18:39:01,223 : INFO : Step 6, Minibatch Loss= 0.0900, Training Accuracy= 0.955
2018-01-03 18:39:01,223 - root - INFO - Step 6, Minibatch Loss= 0.0900, Training Accuracy= 0.955
2018-01-03 18:39:01,223 - root - INFO - Step 6, Minibatch Loss= 0.0900, Training Accuracy= 0.955
2018-01-03 18:39:01,292 : INFO : Step 6, Validation Loss= 0.4231, Validation Accuracy= 0.860
2018-01-03 18:39:01,292 - root - INFO - Step 6, Validation Loss= 0.4231, Validation Accuracy= 0.860
2018-01-03 18:39:01,292 - root - INFO - Step 6, Validation Loss= 0.4231, Validation Accuracy= 0.860
2018-01-03 18:39:01,292 : INFO : starting fold 9 in 10-fold CV
2018-01-03 18:39:01,292 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:39:01,292 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:39:09,128 : INFO : Step 1, Minibatch Loss= 0.6756, Training Accuracy= 0.659
2018-01-03 18:39:09,128 - root - INFO - Step 1, Minibatch Loss= 0.6756, Training Accuracy= 0.659
2018-01-03 18:39:09,128 - root - INFO - Step 1, Minibatch Loss= 0.6756, Training Accuracy= 0.659
2018-01-03 18:39:09,186 : INFO : Step 1, Validation Loss= 0.5574, Validation Accuracy= 0.748
2018-01-03 18:39:09,186 - root - INFO - Step 1, Validation Loss= 0.5574, Validation Accuracy= 0.748
2018-01-03 18:39:09,186 - root - INFO - Step 1, Validation Loss= 0.5574, Validation Accuracy= 0.748
2018-01-03 18:39:11,389 : INFO : Step 2, Minibatch Loss= 0.2825, Training Accuracy= 0.878
2018-01-03 18:39:11,389 - root - INFO - Step 2, Minibatch Loss= 0.2825, Training Accuracy= 0.878
2018-01-03 18:39:11,389 - root - INFO - Step 2, Minibatch Loss= 0.2825, Training Accuracy= 0.878
2018-01-03 18:39:11,450 : INFO : Step 2, Validation Loss= 0.3699, Validation Accuracy= 0.869
2018-01-03 18:39:11,450 - root - INFO - Step 2, Validation Loss= 0.3699, Validation Accuracy= 0.869
2018-01-03 18:39:11,450 - root - INFO - Step 2, Validation Loss= 0.3699, Validation Accuracy= 0.869
2018-01-03 18:39:13,591 : INFO : Step 3, Minibatch Loss= 0.2301, Training Accuracy= 0.907
2018-01-03 18:39:13,591 - root - INFO - Step 3, Minibatch Loss= 0.2301, Training Accuracy= 0.907
2018-01-03 18:39:13,591 - root - INFO - Step 3, Minibatch Loss= 0.2301, Training Accuracy= 0.907
2018-01-03 18:39:13,648 : INFO : Step 3, Validation Loss= 0.3336, Validation Accuracy= 0.886
2018-01-03 18:39:13,648 - root - INFO - Step 3, Validation Loss= 0.3336, Validation Accuracy= 0.886
2018-01-03 18:39:13,648 - root - INFO - Step 3, Validation Loss= 0.3336, Validation Accuracy= 0.886
2018-01-03 18:39:15,818 : INFO : Step 4, Minibatch Loss= 0.1968, Training Accuracy= 0.922
2018-01-03 18:39:15,818 - root - INFO - Step 4, Minibatch Loss= 0.1968, Training Accuracy= 0.922
2018-01-03 18:39:15,818 - root - INFO - Step 4, Minibatch Loss= 0.1968, Training Accuracy= 0.922
2018-01-03 18:39:15,879 : INFO : Step 4, Validation Loss= 0.5012, Validation Accuracy= 0.877
2018-01-03 18:39:15,879 - root - INFO - Step 4, Validation Loss= 0.5012, Validation Accuracy= 0.877
2018-01-03 18:39:15,879 - root - INFO - Step 4, Validation Loss= 0.5012, Validation Accuracy= 0.877
2018-01-03 18:39:15,879 : INFO : starting fold 10 in 10-fold CV
2018-01-03 18:39:15,879 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:39:15,879 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:39:23,421 : INFO : Step 1, Minibatch Loss= 0.5283, Training Accuracy= 0.725
2018-01-03 18:39:23,421 - root - INFO - Step 1, Minibatch Loss= 0.5283, Training Accuracy= 0.725
2018-01-03 18:39:23,421 - root - INFO - Step 1, Minibatch Loss= 0.5283, Training Accuracy= 0.725
2018-01-03 18:39:23,487 : INFO : Step 1, Validation Loss= 0.6648, Validation Accuracy= 0.535
2018-01-03 18:39:23,487 - root - INFO - Step 1, Validation Loss= 0.6648, Validation Accuracy= 0.535
2018-01-03 18:39:23,487 - root - INFO - Step 1, Validation Loss= 0.6648, Validation Accuracy= 0.535
2018-01-03 18:39:25,671 : INFO : Step 2, Minibatch Loss= 0.2609, Training Accuracy= 0.884
2018-01-03 18:39:25,671 - root - INFO - Step 2, Minibatch Loss= 0.2609, Training Accuracy= 0.884
2018-01-03 18:39:25,671 - root - INFO - Step 2, Minibatch Loss= 0.2609, Training Accuracy= 0.884
2018-01-03 18:39:25,735 : INFO : Step 2, Validation Loss= 0.4441, Validation Accuracy= 0.753
2018-01-03 18:39:25,735 - root - INFO - Step 2, Validation Loss= 0.4441, Validation Accuracy= 0.753
2018-01-03 18:39:25,735 - root - INFO - Step 2, Validation Loss= 0.4441, Validation Accuracy= 0.753
2018-01-03 18:39:27,794 : INFO : Step 3, Minibatch Loss= 0.1850, Training Accuracy= 0.921
2018-01-03 18:39:27,794 - root - INFO - Step 3, Minibatch Loss= 0.1850, Training Accuracy= 0.921
2018-01-03 18:39:27,794 - root - INFO - Step 3, Minibatch Loss= 0.1850, Training Accuracy= 0.921
2018-01-03 18:39:27,854 : INFO : Step 3, Validation Loss= 0.3956, Validation Accuracy= 0.798
2018-01-03 18:39:27,854 - root - INFO - Step 3, Validation Loss= 0.3956, Validation Accuracy= 0.798
2018-01-03 18:39:27,854 - root - INFO - Step 3, Validation Loss= 0.3956, Validation Accuracy= 0.798
2018-01-03 18:39:30,028 : INFO : Step 4, Minibatch Loss= 0.1478, Training Accuracy= 0.937
2018-01-03 18:39:30,028 - root - INFO - Step 4, Minibatch Loss= 0.1478, Training Accuracy= 0.937
2018-01-03 18:39:30,028 - root - INFO - Step 4, Minibatch Loss= 0.1478, Training Accuracy= 0.937
2018-01-03 18:39:30,094 : INFO : Step 4, Validation Loss= 0.5368, Validation Accuracy= 0.766
2018-01-03 18:39:30,094 - root - INFO - Step 4, Validation Loss= 0.5368, Validation Accuracy= 0.766
2018-01-03 18:39:30,094 - root - INFO - Step 4, Validation Loss= 0.5368, Validation Accuracy= 0.766
2018-01-03 18:39:30,095 : INFO : Average accuracy is 0.869247 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:39:30,095 - root - INFO - Average accuracy is 0.869247 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:39:30,095 - root - INFO - Average accuracy is 0.869247 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:39:30,095 : INFO : This 10-fold CV run-time: 155.82586908340454 seconds
2018-01-03 18:39:30,095 - root - INFO - This 10-fold CV run-time: 155.82586908340454 seconds
2018-01-03 18:39:30,095 - root - INFO - This 10-fold CV run-time: 155.82586908340454 seconds
2018-01-03 18:39:30,244 : INFO : current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:39:30,244 - root - INFO - current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:39:30,244 - root - INFO - current best: accuracy=0.893763, num_hidden=20, dropout=0.1
2018-01-03 18:39:30,244 : INFO : results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.89376342, (25, 0.1): 0.86924732}
2018-01-03 18:39:30,244 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.89376342, (25, 0.1): 0.86924732}
2018-01-03 18:39:30,244 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.89376342, (25, 0.1): 0.86924732}
2018-01-03 18:39:30,245 : INFO : Code run-time: 340.6103620529175 seconds
2018-01-03 18:39:30,245 - root - INFO - Code run-time: 340.6103620529175 seconds
2018-01-03 18:39:30,245 - root - INFO - Code run-time: 340.6103620529175 seconds
2018-01-03 18:53:23,318 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:53:23,318 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:53:23,318 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 18:53:23,319 : INFO : collecting all words and their counts
2018-01-03 18:53:23,319 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:53:23,319 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 18:53:23,319 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:53:23,319 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:53:23,319 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 18:53:23,347 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:53:23,347 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:53:23,347 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 18:53:23,348 : INFO : Loading a fresh vocabulary
2018-01-03 18:53:23,348 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:53:23,348 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 18:53:23,370 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:53:23,370 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:53:23,370 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 18:53:23,370 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:53:23,370 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:53:23,370 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 18:53:23,397 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 18:53:23,397 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 18:53:23,397 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:53:23,397 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 18:53:23,398 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:53:23,398 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:53:23,398 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 18:53:23,415 : INFO : resetting layer weights
2018-01-03 18:53:23,415 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:53:23,415 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 18:53:23,482 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:23,482 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:23,482 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:23,916 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:23,916 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:23,916 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:23,922 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:23,922 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:23,922 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:23,923 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:23,923 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:23,923 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:23,923 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1278019 effective words/s
2018-01-03 18:53:23,923 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1278019 effective words/s
2018-01-03 18:53:23,923 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1278019 effective words/s
2018-01-03 18:53:23,924 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:23,924 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:23,924 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 18:53:24,396 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:24,396 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:24,396 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 18:53:24,402 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:24,402 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:24,402 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 18:53:24,405 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:24,405 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:24,405 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 18:53:24,405 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1170409 effective words/s
2018-01-03 18:53:24,405 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1170409 effective words/s
2018-01-03 18:53:24,405 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1170409 effective words/s
2018-01-03 18:53:44,405 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:53:44,405 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:53:44,405 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:53:44,405 : INFO : starting fold 1 in 10-fold CV
2018-01-03 18:53:44,405 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:53:44,405 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:53:52,456 : INFO : Step 1, Minibatch Loss= 0.4960, Training Accuracy= 0.769
2018-01-03 18:53:52,456 - root - INFO - Step 1, Minibatch Loss= 0.4960, Training Accuracy= 0.769
2018-01-03 18:53:52,456 - root - INFO - Step 1, Minibatch Loss= 0.4960, Training Accuracy= 0.769
2018-01-03 18:53:52,511 : INFO : Step 1, Validation Loss= 0.6356, Validation Accuracy= 0.510
2018-01-03 18:53:52,511 - root - INFO - Step 1, Validation Loss= 0.6356, Validation Accuracy= 0.510
2018-01-03 18:53:52,511 - root - INFO - Step 1, Validation Loss= 0.6356, Validation Accuracy= 0.510
2018-01-03 18:53:54,486 : INFO : Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.873
2018-01-03 18:53:54,486 - root - INFO - Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.873
2018-01-03 18:53:54,486 - root - INFO - Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.873
2018-01-03 18:53:54,544 : INFO : Step 2, Validation Loss= 0.4249, Validation Accuracy= 0.708
2018-01-03 18:53:54,544 - root - INFO - Step 2, Validation Loss= 0.4249, Validation Accuracy= 0.708
2018-01-03 18:53:54,544 - root - INFO - Step 2, Validation Loss= 0.4249, Validation Accuracy= 0.708
2018-01-03 18:53:56,524 : INFO : Step 3, Minibatch Loss= 0.2086, Training Accuracy= 0.893
2018-01-03 18:53:56,524 - root - INFO - Step 3, Minibatch Loss= 0.2086, Training Accuracy= 0.893
2018-01-03 18:53:56,524 - root - INFO - Step 3, Minibatch Loss= 0.2086, Training Accuracy= 0.893
2018-01-03 18:53:56,579 : INFO : Step 3, Validation Loss= 0.3961, Validation Accuracy= 0.733
2018-01-03 18:53:56,579 - root - INFO - Step 3, Validation Loss= 0.3961, Validation Accuracy= 0.733
2018-01-03 18:53:56,579 - root - INFO - Step 3, Validation Loss= 0.3961, Validation Accuracy= 0.733
2018-01-03 18:53:58,542 : INFO : Step 4, Minibatch Loss= 0.1787, Training Accuracy= 0.906
2018-01-03 18:53:58,542 - root - INFO - Step 4, Minibatch Loss= 0.1787, Training Accuracy= 0.906
2018-01-03 18:53:58,542 - root - INFO - Step 4, Minibatch Loss= 0.1787, Training Accuracy= 0.906
2018-01-03 18:53:58,605 : INFO : Step 4, Validation Loss= 0.5684, Validation Accuracy= 0.697
2018-01-03 18:53:58,605 - root - INFO - Step 4, Validation Loss= 0.5684, Validation Accuracy= 0.697
2018-01-03 18:53:58,605 - root - INFO - Step 4, Validation Loss= 0.5684, Validation Accuracy= 0.697
2018-01-03 18:53:58,605 : INFO : starting fold 2 in 10-fold CV
2018-01-03 18:53:58,605 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:53:58,605 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:54:05,802 : INFO : Step 1, Minibatch Loss= 0.5259, Training Accuracy= 0.728
2018-01-03 18:54:05,802 - root - INFO - Step 1, Minibatch Loss= 0.5259, Training Accuracy= 0.728
2018-01-03 18:54:05,802 - root - INFO - Step 1, Minibatch Loss= 0.5259, Training Accuracy= 0.728
2018-01-03 18:54:05,847 : INFO : Step 1, Validation Loss= 0.4493, Validation Accuracy= 0.892
2018-01-03 18:54:05,847 - root - INFO - Step 1, Validation Loss= 0.4493, Validation Accuracy= 0.892
2018-01-03 18:54:05,847 - root - INFO - Step 1, Validation Loss= 0.4493, Validation Accuracy= 0.892
2018-01-03 18:54:07,854 : INFO : Step 2, Minibatch Loss= 0.2899, Training Accuracy= 0.864
2018-01-03 18:54:07,854 - root - INFO - Step 2, Minibatch Loss= 0.2899, Training Accuracy= 0.864
2018-01-03 18:54:07,854 - root - INFO - Step 2, Minibatch Loss= 0.2899, Training Accuracy= 0.864
2018-01-03 18:54:07,905 : INFO : Step 2, Validation Loss= 0.2949, Validation Accuracy= 0.944
2018-01-03 18:54:07,905 - root - INFO - Step 2, Validation Loss= 0.2949, Validation Accuracy= 0.944
2018-01-03 18:54:07,905 - root - INFO - Step 2, Validation Loss= 0.2949, Validation Accuracy= 0.944
2018-01-03 18:54:09,870 : INFO : Step 3, Minibatch Loss= 0.2192, Training Accuracy= 0.889
2018-01-03 18:54:09,870 - root - INFO - Step 3, Minibatch Loss= 0.2192, Training Accuracy= 0.889
2018-01-03 18:54:09,870 - root - INFO - Step 3, Minibatch Loss= 0.2192, Training Accuracy= 0.889
2018-01-03 18:54:09,924 : INFO : Step 3, Validation Loss= 0.2274, Validation Accuracy= 0.966
2018-01-03 18:54:09,924 - root - INFO - Step 3, Validation Loss= 0.2274, Validation Accuracy= 0.966
2018-01-03 18:54:09,924 - root - INFO - Step 3, Validation Loss= 0.2274, Validation Accuracy= 0.966
2018-01-03 18:54:11,894 : INFO : Step 4, Minibatch Loss= 0.2071, Training Accuracy= 0.904
2018-01-03 18:54:11,894 - root - INFO - Step 4, Minibatch Loss= 0.2071, Training Accuracy= 0.904
2018-01-03 18:54:11,894 - root - INFO - Step 4, Minibatch Loss= 0.2071, Training Accuracy= 0.904
2018-01-03 18:54:11,953 : INFO : Step 4, Validation Loss= 0.6853, Validation Accuracy= 0.914
2018-01-03 18:54:11,953 - root - INFO - Step 4, Validation Loss= 0.6853, Validation Accuracy= 0.914
2018-01-03 18:54:11,953 - root - INFO - Step 4, Validation Loss= 0.6853, Validation Accuracy= 0.914
2018-01-03 18:54:11,954 : INFO : starting fold 3 in 10-fold CV
2018-01-03 18:54:11,954 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:54:11,954 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:54:19,176 : INFO : Step 1, Minibatch Loss= 0.7516, Training Accuracy= 0.627
2018-01-03 18:54:19,176 - root - INFO - Step 1, Minibatch Loss= 0.7516, Training Accuracy= 0.627
2018-01-03 18:54:19,176 - root - INFO - Step 1, Minibatch Loss= 0.7516, Training Accuracy= 0.627
2018-01-03 18:54:19,229 : INFO : Step 1, Validation Loss= 0.9386, Validation Accuracy= 0.499
2018-01-03 18:54:19,229 - root - INFO - Step 1, Validation Loss= 0.9386, Validation Accuracy= 0.499
2018-01-03 18:54:19,229 - root - INFO - Step 1, Validation Loss= 0.9386, Validation Accuracy= 0.499
2018-01-03 18:54:21,190 : INFO : Step 2, Minibatch Loss= 0.3789, Training Accuracy= 0.851
2018-01-03 18:54:21,190 - root - INFO - Step 2, Minibatch Loss= 0.3789, Training Accuracy= 0.851
2018-01-03 18:54:21,190 - root - INFO - Step 2, Minibatch Loss= 0.3789, Training Accuracy= 0.851
2018-01-03 18:54:21,245 : INFO : Step 2, Validation Loss= 0.4802, Validation Accuracy= 0.796
2018-01-03 18:54:21,245 - root - INFO - Step 2, Validation Loss= 0.4802, Validation Accuracy= 0.796
2018-01-03 18:54:21,245 - root - INFO - Step 2, Validation Loss= 0.4802, Validation Accuracy= 0.796
2018-01-03 18:54:23,127 : INFO : Step 3, Minibatch Loss= 0.3013, Training Accuracy= 0.882
2018-01-03 18:54:23,127 - root - INFO - Step 3, Minibatch Loss= 0.3013, Training Accuracy= 0.882
2018-01-03 18:54:23,127 - root - INFO - Step 3, Minibatch Loss= 0.3013, Training Accuracy= 0.882
2018-01-03 18:54:23,182 : INFO : Step 3, Validation Loss= 0.4702, Validation Accuracy= 0.800
2018-01-03 18:54:23,182 - root - INFO - Step 3, Validation Loss= 0.4702, Validation Accuracy= 0.800
2018-01-03 18:54:23,182 - root - INFO - Step 3, Validation Loss= 0.4702, Validation Accuracy= 0.800
2018-01-03 18:54:25,123 : INFO : Step 4, Minibatch Loss= 0.2758, Training Accuracy= 0.897
2018-01-03 18:54:25,123 - root - INFO - Step 4, Minibatch Loss= 0.2758, Training Accuracy= 0.897
2018-01-03 18:54:25,123 - root - INFO - Step 4, Minibatch Loss= 0.2758, Training Accuracy= 0.897
2018-01-03 18:54:25,184 : INFO : Step 4, Validation Loss= 0.4291, Validation Accuracy= 0.832
2018-01-03 18:54:25,184 - root - INFO - Step 4, Validation Loss= 0.4291, Validation Accuracy= 0.832
2018-01-03 18:54:25,184 - root - INFO - Step 4, Validation Loss= 0.4291, Validation Accuracy= 0.832
2018-01-03 18:54:27,138 : INFO : Step 5, Minibatch Loss= 0.2324, Training Accuracy= 0.907
2018-01-03 18:54:27,138 - root - INFO - Step 5, Minibatch Loss= 0.2324, Training Accuracy= 0.907
2018-01-03 18:54:27,138 - root - INFO - Step 5, Minibatch Loss= 0.2324, Training Accuracy= 0.907
2018-01-03 18:54:27,200 : INFO : Step 5, Validation Loss= 0.4252, Validation Accuracy= 0.847
2018-01-03 18:54:27,200 - root - INFO - Step 5, Validation Loss= 0.4252, Validation Accuracy= 0.847
2018-01-03 18:54:27,200 - root - INFO - Step 5, Validation Loss= 0.4252, Validation Accuracy= 0.847
2018-01-03 18:54:29,094 : INFO : Step 6, Minibatch Loss= 0.2352, Training Accuracy= 0.905
2018-01-03 18:54:29,094 - root - INFO - Step 6, Minibatch Loss= 0.2352, Training Accuracy= 0.905
2018-01-03 18:54:29,094 - root - INFO - Step 6, Minibatch Loss= 0.2352, Training Accuracy= 0.905
2018-01-03 18:54:29,146 : INFO : Step 6, Validation Loss= 0.4176, Validation Accuracy= 0.822
2018-01-03 18:54:29,146 - root - INFO - Step 6, Validation Loss= 0.4176, Validation Accuracy= 0.822
2018-01-03 18:54:29,146 - root - INFO - Step 6, Validation Loss= 0.4176, Validation Accuracy= 0.822
2018-01-03 18:54:29,146 : INFO : starting fold 4 in 10-fold CV
2018-01-03 18:54:29,146 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:54:29,146 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:54:36,355 : INFO : Step 1, Minibatch Loss= 0.5508, Training Accuracy= 0.706
2018-01-03 18:54:36,355 - root - INFO - Step 1, Minibatch Loss= 0.5508, Training Accuracy= 0.706
2018-01-03 18:54:36,355 - root - INFO - Step 1, Minibatch Loss= 0.5508, Training Accuracy= 0.706
2018-01-03 18:54:36,415 : INFO : Step 1, Validation Loss= 0.5517, Validation Accuracy= 0.714
2018-01-03 18:54:36,415 - root - INFO - Step 1, Validation Loss= 0.5517, Validation Accuracy= 0.714
2018-01-03 18:54:36,415 - root - INFO - Step 1, Validation Loss= 0.5517, Validation Accuracy= 0.714
2018-01-03 18:54:38,289 : INFO : Step 2, Minibatch Loss= 0.2843, Training Accuracy= 0.866
2018-01-03 18:54:38,289 - root - INFO - Step 2, Minibatch Loss= 0.2843, Training Accuracy= 0.866
2018-01-03 18:54:38,289 - root - INFO - Step 2, Minibatch Loss= 0.2843, Training Accuracy= 0.866
2018-01-03 18:54:38,342 : INFO : Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.862
2018-01-03 18:54:38,342 - root - INFO - Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.862
2018-01-03 18:54:38,342 - root - INFO - Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.862
2018-01-03 18:54:40,395 : INFO : Step 3, Minibatch Loss= 0.2459, Training Accuracy= 0.877
2018-01-03 18:54:40,395 - root - INFO - Step 3, Minibatch Loss= 0.2459, Training Accuracy= 0.877
2018-01-03 18:54:40,395 - root - INFO - Step 3, Minibatch Loss= 0.2459, Training Accuracy= 0.877
2018-01-03 18:54:40,446 : INFO : Step 3, Validation Loss= 0.3011, Validation Accuracy= 0.837
2018-01-03 18:54:40,446 - root - INFO - Step 3, Validation Loss= 0.3011, Validation Accuracy= 0.837
2018-01-03 18:54:40,446 - root - INFO - Step 3, Validation Loss= 0.3011, Validation Accuracy= 0.837
2018-01-03 18:54:40,447 : INFO : starting fold 5 in 10-fold CV
2018-01-03 18:54:40,447 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:54:40,447 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:54:47,443 : INFO : Step 1, Minibatch Loss= 0.5100, Training Accuracy= 0.772
2018-01-03 18:54:47,443 - root - INFO - Step 1, Minibatch Loss= 0.5100, Training Accuracy= 0.772
2018-01-03 18:54:47,443 - root - INFO - Step 1, Minibatch Loss= 0.5100, Training Accuracy= 0.772
2018-01-03 18:54:47,504 : INFO : Step 1, Validation Loss= 0.5664, Validation Accuracy= 0.688
2018-01-03 18:54:47,504 - root - INFO - Step 1, Validation Loss= 0.5664, Validation Accuracy= 0.688
2018-01-03 18:54:47,504 - root - INFO - Step 1, Validation Loss= 0.5664, Validation Accuracy= 0.688
2018-01-03 18:54:49,452 : INFO : Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.879
2018-01-03 18:54:49,452 - root - INFO - Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.879
2018-01-03 18:54:49,452 - root - INFO - Step 2, Minibatch Loss= 0.2664, Training Accuracy= 0.879
2018-01-03 18:54:49,511 : INFO : Step 2, Validation Loss= 0.3848, Validation Accuracy= 0.787
2018-01-03 18:54:49,511 - root - INFO - Step 2, Validation Loss= 0.3848, Validation Accuracy= 0.787
2018-01-03 18:54:49,511 - root - INFO - Step 2, Validation Loss= 0.3848, Validation Accuracy= 0.787
2018-01-03 18:54:51,454 : INFO : Step 3, Minibatch Loss= 0.2045, Training Accuracy= 0.904
2018-01-03 18:54:51,454 - root - INFO - Step 3, Minibatch Loss= 0.2045, Training Accuracy= 0.904
2018-01-03 18:54:51,454 - root - INFO - Step 3, Minibatch Loss= 0.2045, Training Accuracy= 0.904
2018-01-03 18:54:51,515 : INFO : Step 3, Validation Loss= 0.3645, Validation Accuracy= 0.802
2018-01-03 18:54:51,515 - root - INFO - Step 3, Validation Loss= 0.3645, Validation Accuracy= 0.802
2018-01-03 18:54:51,515 - root - INFO - Step 3, Validation Loss= 0.3645, Validation Accuracy= 0.802
2018-01-03 18:54:53,345 : INFO : Step 4, Minibatch Loss= 0.1638, Training Accuracy= 0.920
2018-01-03 18:54:53,345 - root - INFO - Step 4, Minibatch Loss= 0.1638, Training Accuracy= 0.920
2018-01-03 18:54:53,345 - root - INFO - Step 4, Minibatch Loss= 0.1638, Training Accuracy= 0.920
2018-01-03 18:54:53,397 : INFO : Step 4, Validation Loss= 0.3821, Validation Accuracy= 0.824
2018-01-03 18:54:53,397 - root - INFO - Step 4, Validation Loss= 0.3821, Validation Accuracy= 0.824
2018-01-03 18:54:53,397 - root - INFO - Step 4, Validation Loss= 0.3821, Validation Accuracy= 0.824
2018-01-03 18:54:55,246 : INFO : Step 5, Minibatch Loss= 0.1503, Training Accuracy= 0.927
2018-01-03 18:54:55,246 - root - INFO - Step 5, Minibatch Loss= 0.1503, Training Accuracy= 0.927
2018-01-03 18:54:55,246 - root - INFO - Step 5, Minibatch Loss= 0.1503, Training Accuracy= 0.927
2018-01-03 18:54:55,298 : INFO : Step 5, Validation Loss= 0.4753, Validation Accuracy= 0.837
2018-01-03 18:54:55,298 - root - INFO - Step 5, Validation Loss= 0.4753, Validation Accuracy= 0.837
2018-01-03 18:54:55,298 - root - INFO - Step 5, Validation Loss= 0.4753, Validation Accuracy= 0.837
2018-01-03 18:54:57,141 : INFO : Step 6, Minibatch Loss= 0.1256, Training Accuracy= 0.934
2018-01-03 18:54:57,141 - root - INFO - Step 6, Minibatch Loss= 0.1256, Training Accuracy= 0.934
2018-01-03 18:54:57,141 - root - INFO - Step 6, Minibatch Loss= 0.1256, Training Accuracy= 0.934
2018-01-03 18:54:57,195 : INFO : Step 6, Validation Loss= 0.4519, Validation Accuracy= 0.826
2018-01-03 18:54:57,195 - root - INFO - Step 6, Validation Loss= 0.4519, Validation Accuracy= 0.826
2018-01-03 18:54:57,195 - root - INFO - Step 6, Validation Loss= 0.4519, Validation Accuracy= 0.826
2018-01-03 18:54:57,195 : INFO : starting fold 6 in 10-fold CV
2018-01-03 18:54:57,195 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:54:57,195 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:55:04,316 : INFO : Step 1, Minibatch Loss= 0.5379, Training Accuracy= 0.751
2018-01-03 18:55:04,316 - root - INFO - Step 1, Minibatch Loss= 0.5379, Training Accuracy= 0.751
2018-01-03 18:55:04,316 - root - INFO - Step 1, Minibatch Loss= 0.5379, Training Accuracy= 0.751
2018-01-03 18:55:04,371 : INFO : Step 1, Validation Loss= 0.5349, Validation Accuracy= 0.725
2018-01-03 18:55:04,371 - root - INFO - Step 1, Validation Loss= 0.5349, Validation Accuracy= 0.725
2018-01-03 18:55:04,371 - root - INFO - Step 1, Validation Loss= 0.5349, Validation Accuracy= 0.725
2018-01-03 18:55:06,320 : INFO : Step 2, Minibatch Loss= 0.2960, Training Accuracy= 0.882
2018-01-03 18:55:06,320 - root - INFO - Step 2, Minibatch Loss= 0.2960, Training Accuracy= 0.882
2018-01-03 18:55:06,320 - root - INFO - Step 2, Minibatch Loss= 0.2960, Training Accuracy= 0.882
2018-01-03 18:55:06,374 : INFO : Step 2, Validation Loss= 0.3810, Validation Accuracy= 0.839
2018-01-03 18:55:06,374 - root - INFO - Step 2, Validation Loss= 0.3810, Validation Accuracy= 0.839
2018-01-03 18:55:06,374 - root - INFO - Step 2, Validation Loss= 0.3810, Validation Accuracy= 0.839
2018-01-03 18:55:08,363 : INFO : Step 3, Minibatch Loss= 0.2115, Training Accuracy= 0.909
2018-01-03 18:55:08,363 - root - INFO - Step 3, Minibatch Loss= 0.2115, Training Accuracy= 0.909
2018-01-03 18:55:08,363 - root - INFO - Step 3, Minibatch Loss= 0.2115, Training Accuracy= 0.909
2018-01-03 18:55:08,417 : INFO : Step 3, Validation Loss= 0.3208, Validation Accuracy= 0.867
2018-01-03 18:55:08,417 - root - INFO - Step 3, Validation Loss= 0.3208, Validation Accuracy= 0.867
2018-01-03 18:55:08,417 - root - INFO - Step 3, Validation Loss= 0.3208, Validation Accuracy= 0.867
2018-01-03 18:55:10,365 : INFO : Step 4, Minibatch Loss= 0.1719, Training Accuracy= 0.923
2018-01-03 18:55:10,365 - root - INFO - Step 4, Minibatch Loss= 0.1719, Training Accuracy= 0.923
2018-01-03 18:55:10,365 - root - INFO - Step 4, Minibatch Loss= 0.1719, Training Accuracy= 0.923
2018-01-03 18:55:10,417 : INFO : Step 4, Validation Loss= 0.3419, Validation Accuracy= 0.817
2018-01-03 18:55:10,417 - root - INFO - Step 4, Validation Loss= 0.3419, Validation Accuracy= 0.817
2018-01-03 18:55:10,417 - root - INFO - Step 4, Validation Loss= 0.3419, Validation Accuracy= 0.817
2018-01-03 18:55:10,418 : INFO : starting fold 7 in 10-fold CV
2018-01-03 18:55:10,418 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:55:10,418 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:55:17,031 : INFO : Step 1, Minibatch Loss= 0.7718, Training Accuracy= 0.675
2018-01-03 18:55:17,031 - root - INFO - Step 1, Minibatch Loss= 0.7718, Training Accuracy= 0.675
2018-01-03 18:55:17,031 - root - INFO - Step 1, Minibatch Loss= 0.7718, Training Accuracy= 0.675
2018-01-03 18:55:17,087 : INFO : Step 1, Validation Loss= 1.1236, Validation Accuracy= 0.475
2018-01-03 18:55:17,087 - root - INFO - Step 1, Validation Loss= 1.1236, Validation Accuracy= 0.475
2018-01-03 18:55:17,087 - root - INFO - Step 1, Validation Loss= 1.1236, Validation Accuracy= 0.475
2018-01-03 18:55:18,959 : INFO : Step 2, Minibatch Loss= 0.4605, Training Accuracy= 0.812
2018-01-03 18:55:18,959 - root - INFO - Step 2, Minibatch Loss= 0.4605, Training Accuracy= 0.812
2018-01-03 18:55:18,959 - root - INFO - Step 2, Minibatch Loss= 0.4605, Training Accuracy= 0.812
2018-01-03 18:55:19,015 : INFO : Step 2, Validation Loss= 0.7600, Validation Accuracy= 0.675
2018-01-03 18:55:19,015 - root - INFO - Step 2, Validation Loss= 0.7600, Validation Accuracy= 0.675
2018-01-03 18:55:19,015 - root - INFO - Step 2, Validation Loss= 0.7600, Validation Accuracy= 0.675
2018-01-03 18:55:20,933 : INFO : Step 3, Minibatch Loss= 0.3431, Training Accuracy= 0.876
2018-01-03 18:55:20,933 - root - INFO - Step 3, Minibatch Loss= 0.3431, Training Accuracy= 0.876
2018-01-03 18:55:20,933 - root - INFO - Step 3, Minibatch Loss= 0.3431, Training Accuracy= 0.876
2018-01-03 18:55:20,992 : INFO : Step 3, Validation Loss= 0.6592, Validation Accuracy= 0.733
2018-01-03 18:55:20,992 - root - INFO - Step 3, Validation Loss= 0.6592, Validation Accuracy= 0.733
2018-01-03 18:55:20,992 - root - INFO - Step 3, Validation Loss= 0.6592, Validation Accuracy= 0.733
2018-01-03 18:55:22,923 : INFO : Step 4, Minibatch Loss= 0.2827, Training Accuracy= 0.899
2018-01-03 18:55:22,923 - root - INFO - Step 4, Minibatch Loss= 0.2827, Training Accuracy= 0.899
2018-01-03 18:55:22,923 - root - INFO - Step 4, Minibatch Loss= 0.2827, Training Accuracy= 0.899
2018-01-03 18:55:22,981 : INFO : Step 4, Validation Loss= 0.6702, Validation Accuracy= 0.759
2018-01-03 18:55:22,981 - root - INFO - Step 4, Validation Loss= 0.6702, Validation Accuracy= 0.759
2018-01-03 18:55:22,981 - root - INFO - Step 4, Validation Loss= 0.6702, Validation Accuracy= 0.759
2018-01-03 18:55:24,936 : INFO : Step 5, Minibatch Loss= 0.2439, Training Accuracy= 0.911
2018-01-03 18:55:24,936 - root - INFO - Step 5, Minibatch Loss= 0.2439, Training Accuracy= 0.911
2018-01-03 18:55:24,936 - root - INFO - Step 5, Minibatch Loss= 0.2439, Training Accuracy= 0.911
2018-01-03 18:55:24,998 : INFO : Step 5, Validation Loss= 0.5845, Validation Accuracy= 0.781
2018-01-03 18:55:24,998 - root - INFO - Step 5, Validation Loss= 0.5845, Validation Accuracy= 0.781
2018-01-03 18:55:24,998 - root - INFO - Step 5, Validation Loss= 0.5845, Validation Accuracy= 0.781
2018-01-03 18:55:26,879 : INFO : Step 6, Minibatch Loss= 0.2104, Training Accuracy= 0.929
2018-01-03 18:55:26,879 - root - INFO - Step 6, Minibatch Loss= 0.2104, Training Accuracy= 0.929
2018-01-03 18:55:26,879 - root - INFO - Step 6, Minibatch Loss= 0.2104, Training Accuracy= 0.929
2018-01-03 18:55:26,929 : INFO : Step 6, Validation Loss= 0.4561, Validation Accuracy= 0.830
2018-01-03 18:55:26,929 - root - INFO - Step 6, Validation Loss= 0.4561, Validation Accuracy= 0.830
2018-01-03 18:55:26,929 - root - INFO - Step 6, Validation Loss= 0.4561, Validation Accuracy= 0.830
2018-01-03 18:55:28,839 : INFO : Step 7, Minibatch Loss= 0.2054, Training Accuracy= 0.930
2018-01-03 18:55:28,839 - root - INFO - Step 7, Minibatch Loss= 0.2054, Training Accuracy= 0.930
2018-01-03 18:55:28,839 - root - INFO - Step 7, Minibatch Loss= 0.2054, Training Accuracy= 0.930
2018-01-03 18:55:28,893 : INFO : Step 7, Validation Loss= 0.6157, Validation Accuracy= 0.791
2018-01-03 18:55:28,893 - root - INFO - Step 7, Validation Loss= 0.6157, Validation Accuracy= 0.791
2018-01-03 18:55:28,893 - root - INFO - Step 7, Validation Loss= 0.6157, Validation Accuracy= 0.791
2018-01-03 18:55:28,893 : INFO : starting fold 8 in 10-fold CV
2018-01-03 18:55:28,893 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:55:28,893 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:55:35,923 : INFO : Step 1, Minibatch Loss= 0.4445, Training Accuracy= 0.775
2018-01-03 18:55:35,923 - root - INFO - Step 1, Minibatch Loss= 0.4445, Training Accuracy= 0.775
2018-01-03 18:55:35,923 - root - INFO - Step 1, Minibatch Loss= 0.4445, Training Accuracy= 0.775
2018-01-03 18:55:35,983 : INFO : Step 1, Validation Loss= 0.4694, Validation Accuracy= 0.804
2018-01-03 18:55:35,983 - root - INFO - Step 1, Validation Loss= 0.4694, Validation Accuracy= 0.804
2018-01-03 18:55:35,983 - root - INFO - Step 1, Validation Loss= 0.4694, Validation Accuracy= 0.804
2018-01-03 18:55:37,936 : INFO : Step 2, Minibatch Loss= 0.2791, Training Accuracy= 0.869
2018-01-03 18:55:37,936 - root - INFO - Step 2, Minibatch Loss= 0.2791, Training Accuracy= 0.869
2018-01-03 18:55:37,936 - root - INFO - Step 2, Minibatch Loss= 0.2791, Training Accuracy= 0.869
2018-01-03 18:55:37,994 : INFO : Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.856
2018-01-03 18:55:37,994 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.856
2018-01-03 18:55:37,994 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.856
2018-01-03 18:55:39,967 : INFO : Step 3, Minibatch Loss= 0.2130, Training Accuracy= 0.901
2018-01-03 18:55:39,967 - root - INFO - Step 3, Minibatch Loss= 0.2130, Training Accuracy= 0.901
2018-01-03 18:55:39,967 - root - INFO - Step 3, Minibatch Loss= 0.2130, Training Accuracy= 0.901
2018-01-03 18:55:40,021 : INFO : Step 3, Validation Loss= 0.3037, Validation Accuracy= 0.875
2018-01-03 18:55:40,021 - root - INFO - Step 3, Validation Loss= 0.3037, Validation Accuracy= 0.875
2018-01-03 18:55:40,021 - root - INFO - Step 3, Validation Loss= 0.3037, Validation Accuracy= 0.875
2018-01-03 18:55:41,963 : INFO : Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.927
2018-01-03 18:55:41,963 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.927
2018-01-03 18:55:41,963 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.927
2018-01-03 18:55:42,018 : INFO : Step 4, Validation Loss= 0.4342, Validation Accuracy= 0.845
2018-01-03 18:55:42,018 - root - INFO - Step 4, Validation Loss= 0.4342, Validation Accuracy= 0.845
2018-01-03 18:55:42,018 - root - INFO - Step 4, Validation Loss= 0.4342, Validation Accuracy= 0.845
2018-01-03 18:55:42,018 : INFO : starting fold 9 in 10-fold CV
2018-01-03 18:55:42,018 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:55:42,018 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:55:49,195 : INFO : Step 1, Minibatch Loss= 0.5273, Training Accuracy= 0.735
2018-01-03 18:55:49,195 - root - INFO - Step 1, Minibatch Loss= 0.5273, Training Accuracy= 0.735
2018-01-03 18:55:49,195 - root - INFO - Step 1, Minibatch Loss= 0.5273, Training Accuracy= 0.735
2018-01-03 18:55:49,245 : INFO : Step 1, Validation Loss= 0.5993, Validation Accuracy= 0.637
2018-01-03 18:55:49,245 - root - INFO - Step 1, Validation Loss= 0.5993, Validation Accuracy= 0.637
2018-01-03 18:55:49,245 - root - INFO - Step 1, Validation Loss= 0.5993, Validation Accuracy= 0.637
2018-01-03 18:55:51,157 : INFO : Step 2, Minibatch Loss= 0.3020, Training Accuracy= 0.880
2018-01-03 18:55:51,157 - root - INFO - Step 2, Minibatch Loss= 0.3020, Training Accuracy= 0.880
2018-01-03 18:55:51,157 - root - INFO - Step 2, Minibatch Loss= 0.3020, Training Accuracy= 0.880
2018-01-03 18:55:51,209 : INFO : Step 2, Validation Loss= 0.5623, Validation Accuracy= 0.774
2018-01-03 18:55:51,209 - root - INFO - Step 2, Validation Loss= 0.5623, Validation Accuracy= 0.774
2018-01-03 18:55:51,209 - root - INFO - Step 2, Validation Loss= 0.5623, Validation Accuracy= 0.774
2018-01-03 18:55:53,140 : INFO : Step 3, Minibatch Loss= 0.2050, Training Accuracy= 0.907
2018-01-03 18:55:53,140 - root - INFO - Step 3, Minibatch Loss= 0.2050, Training Accuracy= 0.907
2018-01-03 18:55:53,140 - root - INFO - Step 3, Minibatch Loss= 0.2050, Training Accuracy= 0.907
2018-01-03 18:55:53,191 : INFO : Step 3, Validation Loss= 0.2864, Validation Accuracy= 0.839
2018-01-03 18:55:53,191 - root - INFO - Step 3, Validation Loss= 0.2864, Validation Accuracy= 0.839
2018-01-03 18:55:53,191 - root - INFO - Step 3, Validation Loss= 0.2864, Validation Accuracy= 0.839
2018-01-03 18:55:55,122 : INFO : Step 4, Minibatch Loss= 0.1640, Training Accuracy= 0.928
2018-01-03 18:55:55,122 - root - INFO - Step 4, Minibatch Loss= 0.1640, Training Accuracy= 0.928
2018-01-03 18:55:55,122 - root - INFO - Step 4, Minibatch Loss= 0.1640, Training Accuracy= 0.928
2018-01-03 18:55:55,169 : INFO : Step 4, Validation Loss= 0.3279, Validation Accuracy= 0.847
2018-01-03 18:55:55,169 - root - INFO - Step 4, Validation Loss= 0.3279, Validation Accuracy= 0.847
2018-01-03 18:55:55,169 - root - INFO - Step 4, Validation Loss= 0.3279, Validation Accuracy= 0.847
2018-01-03 18:55:57,001 : INFO : Step 5, Minibatch Loss= 0.1369, Training Accuracy= 0.930
2018-01-03 18:55:57,001 - root - INFO - Step 5, Minibatch Loss= 0.1369, Training Accuracy= 0.930
2018-01-03 18:55:57,001 - root - INFO - Step 5, Minibatch Loss= 0.1369, Training Accuracy= 0.930
2018-01-03 18:55:57,051 : INFO : Step 5, Validation Loss= 0.4821, Validation Accuracy= 0.839
2018-01-03 18:55:57,051 - root - INFO - Step 5, Validation Loss= 0.4821, Validation Accuracy= 0.839
2018-01-03 18:55:57,051 - root - INFO - Step 5, Validation Loss= 0.4821, Validation Accuracy= 0.839
2018-01-03 18:55:57,051 : INFO : starting fold 10 in 10-fold CV
2018-01-03 18:55:57,051 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:55:57,051 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:56:05,196 : INFO : Step 1, Minibatch Loss= 0.6238, Training Accuracy= 0.659
2018-01-03 18:56:05,196 - root - INFO - Step 1, Minibatch Loss= 0.6238, Training Accuracy= 0.659
2018-01-03 18:56:05,196 - root - INFO - Step 1, Minibatch Loss= 0.6238, Training Accuracy= 0.659
2018-01-03 18:56:05,252 : INFO : Step 1, Validation Loss= 0.6218, Validation Accuracy= 0.684
2018-01-03 18:56:05,252 - root - INFO - Step 1, Validation Loss= 0.6218, Validation Accuracy= 0.684
2018-01-03 18:56:05,252 - root - INFO - Step 1, Validation Loss= 0.6218, Validation Accuracy= 0.684
2018-01-03 18:56:07,744 : INFO : Step 2, Minibatch Loss= 0.2939, Training Accuracy= 0.875
2018-01-03 18:56:07,744 - root - INFO - Step 2, Minibatch Loss= 0.2939, Training Accuracy= 0.875
2018-01-03 18:56:07,744 - root - INFO - Step 2, Minibatch Loss= 0.2939, Training Accuracy= 0.875
2018-01-03 18:56:07,798 : INFO : Step 2, Validation Loss= 0.4452, Validation Accuracy= 0.852
2018-01-03 18:56:07,798 - root - INFO - Step 2, Validation Loss= 0.4452, Validation Accuracy= 0.852
2018-01-03 18:56:07,798 - root - INFO - Step 2, Validation Loss= 0.4452, Validation Accuracy= 0.852
2018-01-03 18:56:09,748 : INFO : Step 3, Minibatch Loss= 0.2476, Training Accuracy= 0.888
2018-01-03 18:56:09,748 - root - INFO - Step 3, Minibatch Loss= 0.2476, Training Accuracy= 0.888
2018-01-03 18:56:09,748 - root - INFO - Step 3, Minibatch Loss= 0.2476, Training Accuracy= 0.888
2018-01-03 18:56:09,799 : INFO : Step 3, Validation Loss= 0.5631, Validation Accuracy= 0.843
2018-01-03 18:56:09,799 - root - INFO - Step 3, Validation Loss= 0.5631, Validation Accuracy= 0.843
2018-01-03 18:56:09,799 - root - INFO - Step 3, Validation Loss= 0.5631, Validation Accuracy= 0.843
2018-01-03 18:56:09,800 : INFO : Average accuracy is 0.851613 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:56:09,800 - root - INFO - Average accuracy is 0.851613 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:56:09,800 - root - INFO - Average accuracy is 0.851613 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 18:56:09,800 : INFO : This 10-fold CV run-time: 145.3948540687561 seconds
2018-01-03 18:56:09,800 - root - INFO - This 10-fold CV run-time: 145.3948540687561 seconds
2018-01-03 18:56:09,800 - root - INFO - This 10-fold CV run-time: 145.3948540687561 seconds
2018-01-03 18:56:09,959 : INFO : current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:56:09,959 - root - INFO - current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:56:09,959 - root - INFO - current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:56:25,985 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:56:25,985 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:56:25,985 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:56:25,985 : INFO : starting fold 1 in 10-fold CV
2018-01-03 18:56:25,985 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:56:25,985 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 18:56:34,387 : INFO : Step 1, Minibatch Loss= 0.9676, Training Accuracy= 0.609
2018-01-03 18:56:34,387 - root - INFO - Step 1, Minibatch Loss= 0.9676, Training Accuracy= 0.609
2018-01-03 18:56:34,387 - root - INFO - Step 1, Minibatch Loss= 0.9676, Training Accuracy= 0.609
2018-01-03 18:56:34,453 : INFO : Step 1, Validation Loss= 1.7684, Validation Accuracy= 0.273
2018-01-03 18:56:34,453 - root - INFO - Step 1, Validation Loss= 1.7684, Validation Accuracy= 0.273
2018-01-03 18:56:34,453 - root - INFO - Step 1, Validation Loss= 1.7684, Validation Accuracy= 0.273
2018-01-03 18:56:36,549 : INFO : Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.852
2018-01-03 18:56:36,549 - root - INFO - Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.852
2018-01-03 18:56:36,549 - root - INFO - Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.852
2018-01-03 18:56:36,609 : INFO : Step 2, Validation Loss= 0.9238, Validation Accuracy= 0.667
2018-01-03 18:56:36,609 - root - INFO - Step 2, Validation Loss= 0.9238, Validation Accuracy= 0.667
2018-01-03 18:56:36,609 - root - INFO - Step 2, Validation Loss= 0.9238, Validation Accuracy= 0.667
2018-01-03 18:56:38,654 : INFO : Step 3, Minibatch Loss= 0.3329, Training Accuracy= 0.884
2018-01-03 18:56:38,654 - root - INFO - Step 3, Minibatch Loss= 0.3329, Training Accuracy= 0.884
2018-01-03 18:56:38,654 - root - INFO - Step 3, Minibatch Loss= 0.3329, Training Accuracy= 0.884
2018-01-03 18:56:38,713 : INFO : Step 3, Validation Loss= 0.9538, Validation Accuracy= 0.680
2018-01-03 18:56:38,713 - root - INFO - Step 3, Validation Loss= 0.9538, Validation Accuracy= 0.680
2018-01-03 18:56:38,713 - root - INFO - Step 3, Validation Loss= 0.9538, Validation Accuracy= 0.680
2018-01-03 18:56:40,733 : INFO : Step 4, Minibatch Loss= 0.3088, Training Accuracy= 0.891
2018-01-03 18:56:40,733 - root - INFO - Step 4, Minibatch Loss= 0.3088, Training Accuracy= 0.891
2018-01-03 18:56:40,733 - root - INFO - Step 4, Minibatch Loss= 0.3088, Training Accuracy= 0.891
2018-01-03 18:56:40,794 : INFO : Step 4, Validation Loss= 1.0586, Validation Accuracy= 0.615
2018-01-03 18:56:40,794 - root - INFO - Step 4, Validation Loss= 1.0586, Validation Accuracy= 0.615
2018-01-03 18:56:40,794 - root - INFO - Step 4, Validation Loss= 1.0586, Validation Accuracy= 0.615
2018-01-03 18:56:40,795 : INFO : starting fold 2 in 10-fold CV
2018-01-03 18:56:40,795 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:56:40,795 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 18:56:47,953 : INFO : Step 1, Minibatch Loss= 0.4608, Training Accuracy= 0.786
2018-01-03 18:56:47,953 - root - INFO - Step 1, Minibatch Loss= 0.4608, Training Accuracy= 0.786
2018-01-03 18:56:47,953 - root - INFO - Step 1, Minibatch Loss= 0.4608, Training Accuracy= 0.786
2018-01-03 18:56:48,017 : INFO : Step 1, Validation Loss= 0.4473, Validation Accuracy= 0.882
2018-01-03 18:56:48,017 - root - INFO - Step 1, Validation Loss= 0.4473, Validation Accuracy= 0.882
2018-01-03 18:56:48,017 - root - INFO - Step 1, Validation Loss= 0.4473, Validation Accuracy= 0.882
2018-01-03 18:56:50,142 : INFO : Step 2, Minibatch Loss= 0.2371, Training Accuracy= 0.902
2018-01-03 18:56:50,142 - root - INFO - Step 2, Minibatch Loss= 0.2371, Training Accuracy= 0.902
2018-01-03 18:56:50,142 - root - INFO - Step 2, Minibatch Loss= 0.2371, Training Accuracy= 0.902
2018-01-03 18:56:50,206 : INFO : Step 2, Validation Loss= 0.4039, Validation Accuracy= 0.903
2018-01-03 18:56:50,206 - root - INFO - Step 2, Validation Loss= 0.4039, Validation Accuracy= 0.903
2018-01-03 18:56:50,206 - root - INFO - Step 2, Validation Loss= 0.4039, Validation Accuracy= 0.903
2018-01-03 18:56:52,302 : INFO : Step 3, Minibatch Loss= 0.1704, Training Accuracy= 0.923
2018-01-03 18:56:52,302 - root - INFO - Step 3, Minibatch Loss= 0.1704, Training Accuracy= 0.923
2018-01-03 18:56:52,302 - root - INFO - Step 3, Minibatch Loss= 0.1704, Training Accuracy= 0.923
2018-01-03 18:56:52,363 : INFO : Step 3, Validation Loss= 0.4093, Validation Accuracy= 0.925
2018-01-03 18:56:52,363 - root - INFO - Step 3, Validation Loss= 0.4093, Validation Accuracy= 0.925
2018-01-03 18:56:52,363 - root - INFO - Step 3, Validation Loss= 0.4093, Validation Accuracy= 0.925
2018-01-03 18:56:54,481 : INFO : Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.932
2018-01-03 18:56:54,481 - root - INFO - Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.932
2018-01-03 18:56:54,481 - root - INFO - Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.932
2018-01-03 18:56:54,546 : INFO : Step 4, Validation Loss= 0.3824, Validation Accuracy= 0.931
2018-01-03 18:56:54,546 - root - INFO - Step 4, Validation Loss= 0.3824, Validation Accuracy= 0.931
2018-01-03 18:56:54,546 - root - INFO - Step 4, Validation Loss= 0.3824, Validation Accuracy= 0.931
2018-01-03 18:56:56,597 : INFO : Step 5, Minibatch Loss= 0.1059, Training Accuracy= 0.952
2018-01-03 18:56:56,597 - root - INFO - Step 5, Minibatch Loss= 0.1059, Training Accuracy= 0.952
2018-01-03 18:56:56,597 - root - INFO - Step 5, Minibatch Loss= 0.1059, Training Accuracy= 0.952
2018-01-03 18:56:56,655 : INFO : Step 5, Validation Loss= 0.3220, Validation Accuracy= 0.951
2018-01-03 18:56:56,655 - root - INFO - Step 5, Validation Loss= 0.3220, Validation Accuracy= 0.951
2018-01-03 18:56:56,655 - root - INFO - Step 5, Validation Loss= 0.3220, Validation Accuracy= 0.951
2018-01-03 18:56:58,844 : INFO : Step 6, Minibatch Loss= 0.0975, Training Accuracy= 0.949
2018-01-03 18:56:58,844 - root - INFO - Step 6, Minibatch Loss= 0.0975, Training Accuracy= 0.949
2018-01-03 18:56:58,844 - root - INFO - Step 6, Minibatch Loss= 0.0975, Training Accuracy= 0.949
2018-01-03 18:56:58,907 : INFO : Step 6, Validation Loss= 0.2926, Validation Accuracy= 0.955
2018-01-03 18:56:58,907 - root - INFO - Step 6, Validation Loss= 0.2926, Validation Accuracy= 0.955
2018-01-03 18:56:58,907 - root - INFO - Step 6, Validation Loss= 0.2926, Validation Accuracy= 0.955
2018-01-03 18:57:01,115 : INFO : Step 7, Minibatch Loss= 0.0844, Training Accuracy= 0.955
2018-01-03 18:57:01,115 - root - INFO - Step 7, Minibatch Loss= 0.0844, Training Accuracy= 0.955
2018-01-03 18:57:01,115 - root - INFO - Step 7, Minibatch Loss= 0.0844, Training Accuracy= 0.955
2018-01-03 18:57:01,190 : INFO : Step 7, Validation Loss= 0.4693, Validation Accuracy= 0.914
2018-01-03 18:57:01,190 - root - INFO - Step 7, Validation Loss= 0.4693, Validation Accuracy= 0.914
2018-01-03 18:57:01,190 - root - INFO - Step 7, Validation Loss= 0.4693, Validation Accuracy= 0.914
2018-01-03 18:57:01,190 : INFO : starting fold 3 in 10-fold CV
2018-01-03 18:57:01,190 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:57:01,190 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 18:57:08,592 : INFO : Step 1, Minibatch Loss= 0.7085, Training Accuracy= 0.646
2018-01-03 18:57:08,592 - root - INFO - Step 1, Minibatch Loss= 0.7085, Training Accuracy= 0.646
2018-01-03 18:57:08,592 - root - INFO - Step 1, Minibatch Loss= 0.7085, Training Accuracy= 0.646
2018-01-03 18:57:08,658 : INFO : Step 1, Validation Loss= 0.8372, Validation Accuracy= 0.542
2018-01-03 18:57:08,658 - root - INFO - Step 1, Validation Loss= 0.8372, Validation Accuracy= 0.542
2018-01-03 18:57:08,658 - root - INFO - Step 1, Validation Loss= 0.8372, Validation Accuracy= 0.542
2018-01-03 18:57:10,782 : INFO : Step 2, Minibatch Loss= 0.3132, Training Accuracy= 0.870
2018-01-03 18:57:10,782 - root - INFO - Step 2, Minibatch Loss= 0.3132, Training Accuracy= 0.870
2018-01-03 18:57:10,782 - root - INFO - Step 2, Minibatch Loss= 0.3132, Training Accuracy= 0.870
2018-01-03 18:57:10,844 : INFO : Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.822
2018-01-03 18:57:10,844 - root - INFO - Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.822
2018-01-03 18:57:10,844 - root - INFO - Step 2, Validation Loss= 0.3789, Validation Accuracy= 0.822
2018-01-03 18:57:12,984 : INFO : Step 3, Minibatch Loss= 0.2409, Training Accuracy= 0.906
2018-01-03 18:57:12,984 - root - INFO - Step 3, Minibatch Loss= 0.2409, Training Accuracy= 0.906
2018-01-03 18:57:12,984 - root - INFO - Step 3, Minibatch Loss= 0.2409, Training Accuracy= 0.906
2018-01-03 18:57:13,051 : INFO : Step 3, Validation Loss= 0.3791, Validation Accuracy= 0.832
2018-01-03 18:57:13,051 - root - INFO - Step 3, Validation Loss= 0.3791, Validation Accuracy= 0.832
2018-01-03 18:57:13,051 - root - INFO - Step 3, Validation Loss= 0.3791, Validation Accuracy= 0.832
2018-01-03 18:57:15,256 : INFO : Step 4, Minibatch Loss= 0.1941, Training Accuracy= 0.926
2018-01-03 18:57:15,256 - root - INFO - Step 4, Minibatch Loss= 0.1941, Training Accuracy= 0.926
2018-01-03 18:57:15,256 - root - INFO - Step 4, Minibatch Loss= 0.1941, Training Accuracy= 0.926
2018-01-03 18:57:15,312 : INFO : Step 4, Validation Loss= 0.4426, Validation Accuracy= 0.824
2018-01-03 18:57:15,312 - root - INFO - Step 4, Validation Loss= 0.4426, Validation Accuracy= 0.824
2018-01-03 18:57:15,312 - root - INFO - Step 4, Validation Loss= 0.4426, Validation Accuracy= 0.824
2018-01-03 18:57:15,312 : INFO : starting fold 4 in 10-fold CV
2018-01-03 18:57:15,312 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:57:15,312 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 18:57:23,513 : INFO : Step 1, Minibatch Loss= 0.5643, Training Accuracy= 0.704
2018-01-03 18:57:23,513 - root - INFO - Step 1, Minibatch Loss= 0.5643, Training Accuracy= 0.704
2018-01-03 18:57:23,513 - root - INFO - Step 1, Minibatch Loss= 0.5643, Training Accuracy= 0.704
2018-01-03 18:57:23,571 : INFO : Step 1, Validation Loss= 0.5667, Validation Accuracy= 0.703
2018-01-03 18:57:23,571 - root - INFO - Step 1, Validation Loss= 0.5667, Validation Accuracy= 0.703
2018-01-03 18:57:23,571 - root - INFO - Step 1, Validation Loss= 0.5667, Validation Accuracy= 0.703
2018-01-03 18:57:25,699 : INFO : Step 2, Minibatch Loss= 0.2431, Training Accuracy= 0.893
2018-01-03 18:57:25,699 - root - INFO - Step 2, Minibatch Loss= 0.2431, Training Accuracy= 0.893
2018-01-03 18:57:25,699 - root - INFO - Step 2, Minibatch Loss= 0.2431, Training Accuracy= 0.893
2018-01-03 18:57:25,760 : INFO : Step 2, Validation Loss= 0.2441, Validation Accuracy= 0.895
2018-01-03 18:57:25,760 - root - INFO - Step 2, Validation Loss= 0.2441, Validation Accuracy= 0.895
2018-01-03 18:57:25,760 - root - INFO - Step 2, Validation Loss= 0.2441, Validation Accuracy= 0.895
2018-01-03 18:57:28,002 : INFO : Step 3, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 18:57:28,002 - root - INFO - Step 3, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 18:57:28,002 - root - INFO - Step 3, Minibatch Loss= 0.1987, Training Accuracy= 0.919
2018-01-03 18:57:28,080 : INFO : Step 3, Validation Loss= 0.4116, Validation Accuracy= 0.888
2018-01-03 18:57:28,080 - root - INFO - Step 3, Validation Loss= 0.4116, Validation Accuracy= 0.888
2018-01-03 18:57:28,080 - root - INFO - Step 3, Validation Loss= 0.4116, Validation Accuracy= 0.888
2018-01-03 18:57:28,081 : INFO : starting fold 5 in 10-fold CV
2018-01-03 18:57:28,081 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:57:28,081 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 18:57:35,821 : INFO : Step 1, Minibatch Loss= 0.4631, Training Accuracy= 0.806
2018-01-03 18:57:35,821 - root - INFO - Step 1, Minibatch Loss= 0.4631, Training Accuracy= 0.806
2018-01-03 18:57:35,821 - root - INFO - Step 1, Minibatch Loss= 0.4631, Training Accuracy= 0.806
2018-01-03 18:57:35,882 : INFO : Step 1, Validation Loss= 0.5262, Validation Accuracy= 0.742
2018-01-03 18:57:35,882 - root - INFO - Step 1, Validation Loss= 0.5262, Validation Accuracy= 0.742
2018-01-03 18:57:35,882 - root - INFO - Step 1, Validation Loss= 0.5262, Validation Accuracy= 0.742
2018-01-03 18:57:38,030 : INFO : Step 2, Minibatch Loss= 0.2302, Training Accuracy= 0.917
2018-01-03 18:57:38,030 - root - INFO - Step 2, Minibatch Loss= 0.2302, Training Accuracy= 0.917
2018-01-03 18:57:38,030 - root - INFO - Step 2, Minibatch Loss= 0.2302, Training Accuracy= 0.917
2018-01-03 18:57:38,093 : INFO : Step 2, Validation Loss= 0.3570, Validation Accuracy= 0.839
2018-01-03 18:57:38,093 - root - INFO - Step 2, Validation Loss= 0.3570, Validation Accuracy= 0.839
2018-01-03 18:57:38,093 - root - INFO - Step 2, Validation Loss= 0.3570, Validation Accuracy= 0.839
2018-01-03 18:57:40,200 : INFO : Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.948
2018-01-03 18:57:40,200 - root - INFO - Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.948
2018-01-03 18:57:40,200 - root - INFO - Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.948
2018-01-03 18:57:40,260 : INFO : Step 3, Validation Loss= 0.4211, Validation Accuracy= 0.854
2018-01-03 18:57:40,260 - root - INFO - Step 3, Validation Loss= 0.4211, Validation Accuracy= 0.854
2018-01-03 18:57:40,260 - root - INFO - Step 3, Validation Loss= 0.4211, Validation Accuracy= 0.854
2018-01-03 18:57:42,292 : INFO : Step 4, Minibatch Loss= 0.1286, Training Accuracy= 0.948
2018-01-03 18:57:42,292 - root - INFO - Step 4, Minibatch Loss= 0.1286, Training Accuracy= 0.948
2018-01-03 18:57:42,292 - root - INFO - Step 4, Minibatch Loss= 0.1286, Training Accuracy= 0.948
2018-01-03 18:57:42,352 : INFO : Step 4, Validation Loss= 0.3201, Validation Accuracy= 0.886
2018-01-03 18:57:42,352 - root - INFO - Step 4, Validation Loss= 0.3201, Validation Accuracy= 0.886
2018-01-03 18:57:42,352 - root - INFO - Step 4, Validation Loss= 0.3201, Validation Accuracy= 0.886
2018-01-03 18:57:44,411 : INFO : Step 5, Minibatch Loss= 0.1013, Training Accuracy= 0.955
2018-01-03 18:57:44,411 - root - INFO - Step 5, Minibatch Loss= 0.1013, Training Accuracy= 0.955
2018-01-03 18:57:44,411 - root - INFO - Step 5, Minibatch Loss= 0.1013, Training Accuracy= 0.955
2018-01-03 18:57:44,475 : INFO : Step 5, Validation Loss= 0.4810, Validation Accuracy= 0.875
2018-01-03 18:57:44,475 - root - INFO - Step 5, Validation Loss= 0.4810, Validation Accuracy= 0.875
2018-01-03 18:57:44,475 - root - INFO - Step 5, Validation Loss= 0.4810, Validation Accuracy= 0.875
2018-01-03 18:57:44,475 : INFO : starting fold 6 in 10-fold CV
2018-01-03 18:57:44,475 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:57:44,475 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 18:57:51,990 : INFO : Step 1, Minibatch Loss= 0.4004, Training Accuracy= 0.846
2018-01-03 18:57:51,990 - root - INFO - Step 1, Minibatch Loss= 0.4004, Training Accuracy= 0.846
2018-01-03 18:57:51,990 - root - INFO - Step 1, Minibatch Loss= 0.4004, Training Accuracy= 0.846
2018-01-03 18:57:52,044 : INFO : Step 1, Validation Loss= 0.4162, Validation Accuracy= 0.843
2018-01-03 18:57:52,044 - root - INFO - Step 1, Validation Loss= 0.4162, Validation Accuracy= 0.843
2018-01-03 18:57:52,044 - root - INFO - Step 1, Validation Loss= 0.4162, Validation Accuracy= 0.843
2018-01-03 18:57:54,148 : INFO : Step 2, Minibatch Loss= 0.2018, Training Accuracy= 0.926
2018-01-03 18:57:54,148 - root - INFO - Step 2, Minibatch Loss= 0.2018, Training Accuracy= 0.926
2018-01-03 18:57:54,148 - root - INFO - Step 2, Minibatch Loss= 0.2018, Training Accuracy= 0.926
2018-01-03 18:57:54,206 : INFO : Step 2, Validation Loss= 0.2826, Validation Accuracy= 0.890
2018-01-03 18:57:54,206 - root - INFO - Step 2, Validation Loss= 0.2826, Validation Accuracy= 0.890
2018-01-03 18:57:54,206 - root - INFO - Step 2, Validation Loss= 0.2826, Validation Accuracy= 0.890
2018-01-03 18:57:56,280 : INFO : Step 3, Minibatch Loss= 0.1427, Training Accuracy= 0.941
2018-01-03 18:57:56,280 - root - INFO - Step 3, Minibatch Loss= 0.1427, Training Accuracy= 0.941
2018-01-03 18:57:56,280 - root - INFO - Step 3, Minibatch Loss= 0.1427, Training Accuracy= 0.941
2018-01-03 18:57:56,353 : INFO : Step 3, Validation Loss= 0.2779, Validation Accuracy= 0.890
2018-01-03 18:57:56,353 - root - INFO - Step 3, Validation Loss= 0.2779, Validation Accuracy= 0.890
2018-01-03 18:57:56,353 - root - INFO - Step 3, Validation Loss= 0.2779, Validation Accuracy= 0.890
2018-01-03 18:57:58,405 : INFO : Step 4, Minibatch Loss= 0.1173, Training Accuracy= 0.952
2018-01-03 18:57:58,405 - root - INFO - Step 4, Minibatch Loss= 0.1173, Training Accuracy= 0.952
2018-01-03 18:57:58,405 - root - INFO - Step 4, Minibatch Loss= 0.1173, Training Accuracy= 0.952
2018-01-03 18:57:58,465 : INFO : Step 4, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 18:57:58,465 - root - INFO - Step 4, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 18:57:58,465 - root - INFO - Step 4, Validation Loss= 0.2611, Validation Accuracy= 0.908
2018-01-03 18:58:00,564 : INFO : Step 5, Minibatch Loss= 0.0937, Training Accuracy= 0.953
2018-01-03 18:58:00,564 - root - INFO - Step 5, Minibatch Loss= 0.0937, Training Accuracy= 0.953
2018-01-03 18:58:00,564 - root - INFO - Step 5, Minibatch Loss= 0.0937, Training Accuracy= 0.953
2018-01-03 18:58:00,622 : INFO : Step 5, Validation Loss= 0.3243, Validation Accuracy= 0.892
2018-01-03 18:58:00,622 - root - INFO - Step 5, Validation Loss= 0.3243, Validation Accuracy= 0.892
2018-01-03 18:58:00,622 - root - INFO - Step 5, Validation Loss= 0.3243, Validation Accuracy= 0.892
2018-01-03 18:58:00,622 : INFO : starting fold 7 in 10-fold CV
2018-01-03 18:58:00,622 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:58:00,622 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 18:58:08,102 : INFO : Step 1, Minibatch Loss= 0.4520, Training Accuracy= 0.794
2018-01-03 18:58:08,102 - root - INFO - Step 1, Minibatch Loss= 0.4520, Training Accuracy= 0.794
2018-01-03 18:58:08,102 - root - INFO - Step 1, Minibatch Loss= 0.4520, Training Accuracy= 0.794
2018-01-03 18:58:08,163 : INFO : Step 1, Validation Loss= 0.5778, Validation Accuracy= 0.639
2018-01-03 18:58:08,163 - root - INFO - Step 1, Validation Loss= 0.5778, Validation Accuracy= 0.639
2018-01-03 18:58:08,163 - root - INFO - Step 1, Validation Loss= 0.5778, Validation Accuracy= 0.639
2018-01-03 18:58:10,362 : INFO : Step 2, Minibatch Loss= 0.2352, Training Accuracy= 0.894
2018-01-03 18:58:10,362 - root - INFO - Step 2, Minibatch Loss= 0.2352, Training Accuracy= 0.894
2018-01-03 18:58:10,362 - root - INFO - Step 2, Minibatch Loss= 0.2352, Training Accuracy= 0.894
2018-01-03 18:58:10,421 : INFO : Step 2, Validation Loss= 0.3630, Validation Accuracy= 0.806
2018-01-03 18:58:10,421 - root - INFO - Step 2, Validation Loss= 0.3630, Validation Accuracy= 0.806
2018-01-03 18:58:10,421 - root - INFO - Step 2, Validation Loss= 0.3630, Validation Accuracy= 0.806
2018-01-03 18:58:12,533 : INFO : Step 3, Minibatch Loss= 0.1738, Training Accuracy= 0.917
2018-01-03 18:58:12,533 - root - INFO - Step 3, Minibatch Loss= 0.1738, Training Accuracy= 0.917
2018-01-03 18:58:12,533 - root - INFO - Step 3, Minibatch Loss= 0.1738, Training Accuracy= 0.917
2018-01-03 18:58:12,595 : INFO : Step 3, Validation Loss= 0.3454, Validation Accuracy= 0.796
2018-01-03 18:58:12,595 - root - INFO - Step 3, Validation Loss= 0.3454, Validation Accuracy= 0.796
2018-01-03 18:58:12,595 - root - INFO - Step 3, Validation Loss= 0.3454, Validation Accuracy= 0.796
2018-01-03 18:58:12,596 : INFO : starting fold 8 in 10-fold CV
2018-01-03 18:58:12,596 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:58:12,596 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 18:58:20,059 : INFO : Step 1, Minibatch Loss= 0.7780, Training Accuracy= 0.630
2018-01-03 18:58:20,059 - root - INFO - Step 1, Minibatch Loss= 0.7780, Training Accuracy= 0.630
2018-01-03 18:58:20,059 - root - INFO - Step 1, Minibatch Loss= 0.7780, Training Accuracy= 0.630
2018-01-03 18:58:20,120 : INFO : Step 1, Validation Loss= 0.9802, Validation Accuracy= 0.525
2018-01-03 18:58:20,120 - root - INFO - Step 1, Validation Loss= 0.9802, Validation Accuracy= 0.525
2018-01-03 18:58:20,120 - root - INFO - Step 1, Validation Loss= 0.9802, Validation Accuracy= 0.525
2018-01-03 18:58:22,203 : INFO : Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.829
2018-01-03 18:58:22,203 - root - INFO - Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.829
2018-01-03 18:58:22,203 - root - INFO - Step 2, Minibatch Loss= 0.4146, Training Accuracy= 0.829
2018-01-03 18:58:22,264 : INFO : Step 2, Validation Loss= 0.5240, Validation Accuracy= 0.757
2018-01-03 18:58:22,264 - root - INFO - Step 2, Validation Loss= 0.5240, Validation Accuracy= 0.757
2018-01-03 18:58:22,264 - root - INFO - Step 2, Validation Loss= 0.5240, Validation Accuracy= 0.757
2018-01-03 18:58:24,413 : INFO : Step 3, Minibatch Loss= 0.2695, Training Accuracy= 0.904
2018-01-03 18:58:24,413 - root - INFO - Step 3, Minibatch Loss= 0.2695, Training Accuracy= 0.904
2018-01-03 18:58:24,413 - root - INFO - Step 3, Minibatch Loss= 0.2695, Training Accuracy= 0.904
2018-01-03 18:58:24,484 : INFO : Step 3, Validation Loss= 0.4848, Validation Accuracy= 0.809
2018-01-03 18:58:24,484 - root - INFO - Step 3, Validation Loss= 0.4848, Validation Accuracy= 0.809
2018-01-03 18:58:24,484 - root - INFO - Step 3, Validation Loss= 0.4848, Validation Accuracy= 0.809
2018-01-03 18:58:27,047 : INFO : Step 4, Minibatch Loss= 0.2348, Training Accuracy= 0.917
2018-01-03 18:58:27,047 - root - INFO - Step 4, Minibatch Loss= 0.2348, Training Accuracy= 0.917
2018-01-03 18:58:27,047 - root - INFO - Step 4, Minibatch Loss= 0.2348, Training Accuracy= 0.917
2018-01-03 18:58:27,118 : INFO : Step 4, Validation Loss= 0.5016, Validation Accuracy= 0.819
2018-01-03 18:58:27,118 - root - INFO - Step 4, Validation Loss= 0.5016, Validation Accuracy= 0.819
2018-01-03 18:58:27,118 - root - INFO - Step 4, Validation Loss= 0.5016, Validation Accuracy= 0.819
2018-01-03 18:58:29,333 : INFO : Step 5, Minibatch Loss= 0.1816, Training Accuracy= 0.932
2018-01-03 18:58:29,333 - root - INFO - Step 5, Minibatch Loss= 0.1816, Training Accuracy= 0.932
2018-01-03 18:58:29,333 - root - INFO - Step 5, Minibatch Loss= 0.1816, Training Accuracy= 0.932
2018-01-03 18:58:29,397 : INFO : Step 5, Validation Loss= 0.4383, Validation Accuracy= 0.845
2018-01-03 18:58:29,397 - root - INFO - Step 5, Validation Loss= 0.4383, Validation Accuracy= 0.845
2018-01-03 18:58:29,397 - root - INFO - Step 5, Validation Loss= 0.4383, Validation Accuracy= 0.845
2018-01-03 18:58:31,635 : INFO : Step 6, Minibatch Loss= 0.1777, Training Accuracy= 0.930
2018-01-03 18:58:31,635 - root - INFO - Step 6, Minibatch Loss= 0.1777, Training Accuracy= 0.930
2018-01-03 18:58:31,635 - root - INFO - Step 6, Minibatch Loss= 0.1777, Training Accuracy= 0.930
2018-01-03 18:58:31,704 : INFO : Step 6, Validation Loss= 0.4339, Validation Accuracy= 0.826
2018-01-03 18:58:31,704 - root - INFO - Step 6, Validation Loss= 0.4339, Validation Accuracy= 0.826
2018-01-03 18:58:31,704 - root - INFO - Step 6, Validation Loss= 0.4339, Validation Accuracy= 0.826
2018-01-03 18:58:31,704 : INFO : starting fold 9 in 10-fold CV
2018-01-03 18:58:31,704 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:58:31,704 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 18:58:39,080 : INFO : Step 1, Minibatch Loss= 0.5072, Training Accuracy= 0.741
2018-01-03 18:58:39,080 - root - INFO - Step 1, Minibatch Loss= 0.5072, Training Accuracy= 0.741
2018-01-03 18:58:39,080 - root - INFO - Step 1, Minibatch Loss= 0.5072, Training Accuracy= 0.741
2018-01-03 18:58:39,147 : INFO : Step 1, Validation Loss= 0.5785, Validation Accuracy= 0.682
2018-01-03 18:58:39,147 - root - INFO - Step 1, Validation Loss= 0.5785, Validation Accuracy= 0.682
2018-01-03 18:58:39,147 - root - INFO - Step 1, Validation Loss= 0.5785, Validation Accuracy= 0.682
2018-01-03 18:58:41,265 : INFO : Step 2, Minibatch Loss= 0.2688, Training Accuracy= 0.896
2018-01-03 18:58:41,265 - root - INFO - Step 2, Minibatch Loss= 0.2688, Training Accuracy= 0.896
2018-01-03 18:58:41,265 - root - INFO - Step 2, Minibatch Loss= 0.2688, Training Accuracy= 0.896
2018-01-03 18:58:41,322 : INFO : Step 2, Validation Loss= 0.4742, Validation Accuracy= 0.854
2018-01-03 18:58:41,322 - root - INFO - Step 2, Validation Loss= 0.4742, Validation Accuracy= 0.854
2018-01-03 18:58:41,322 - root - INFO - Step 2, Validation Loss= 0.4742, Validation Accuracy= 0.854
2018-01-03 18:58:43,379 : INFO : Step 3, Minibatch Loss= 0.1897, Training Accuracy= 0.917
2018-01-03 18:58:43,379 - root - INFO - Step 3, Minibatch Loss= 0.1897, Training Accuracy= 0.917
2018-01-03 18:58:43,379 - root - INFO - Step 3, Minibatch Loss= 0.1897, Training Accuracy= 0.917
2018-01-03 18:58:43,441 : INFO : Step 3, Validation Loss= 0.3480, Validation Accuracy= 0.852
2018-01-03 18:58:43,441 - root - INFO - Step 3, Validation Loss= 0.3480, Validation Accuracy= 0.852
2018-01-03 18:58:43,441 - root - INFO - Step 3, Validation Loss= 0.3480, Validation Accuracy= 0.852
2018-01-03 18:58:43,441 : INFO : starting fold 10 in 10-fold CV
2018-01-03 18:58:43,441 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:58:43,441 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 18:58:50,767 : INFO : Step 1, Minibatch Loss= 0.4575, Training Accuracy= 0.780
2018-01-03 18:58:50,767 - root - INFO - Step 1, Minibatch Loss= 0.4575, Training Accuracy= 0.780
2018-01-03 18:58:50,767 - root - INFO - Step 1, Minibatch Loss= 0.4575, Training Accuracy= 0.780
2018-01-03 18:58:50,832 : INFO : Step 1, Validation Loss= 0.6363, Validation Accuracy= 0.602
2018-01-03 18:58:50,832 - root - INFO - Step 1, Validation Loss= 0.6363, Validation Accuracy= 0.602
2018-01-03 18:58:50,832 - root - INFO - Step 1, Validation Loss= 0.6363, Validation Accuracy= 0.602
2018-01-03 18:58:52,883 : INFO : Step 2, Minibatch Loss= 0.2476, Training Accuracy= 0.885
2018-01-03 18:58:52,883 - root - INFO - Step 2, Minibatch Loss= 0.2476, Training Accuracy= 0.885
2018-01-03 18:58:52,883 - root - INFO - Step 2, Minibatch Loss= 0.2476, Training Accuracy= 0.885
2018-01-03 18:58:52,943 : INFO : Step 2, Validation Loss= 0.4677, Validation Accuracy= 0.755
2018-01-03 18:58:52,943 - root - INFO - Step 2, Validation Loss= 0.4677, Validation Accuracy= 0.755
2018-01-03 18:58:52,943 - root - INFO - Step 2, Validation Loss= 0.4677, Validation Accuracy= 0.755
2018-01-03 18:58:54,955 : INFO : Step 3, Minibatch Loss= 0.1662, Training Accuracy= 0.934
2018-01-03 18:58:54,955 - root - INFO - Step 3, Minibatch Loss= 0.1662, Training Accuracy= 0.934
2018-01-03 18:58:54,955 - root - INFO - Step 3, Minibatch Loss= 0.1662, Training Accuracy= 0.934
2018-01-03 18:58:55,014 : INFO : Step 3, Validation Loss= 0.3615, Validation Accuracy= 0.828
2018-01-03 18:58:55,014 - root - INFO - Step 3, Validation Loss= 0.3615, Validation Accuracy= 0.828
2018-01-03 18:58:55,014 - root - INFO - Step 3, Validation Loss= 0.3615, Validation Accuracy= 0.828
2018-01-03 18:58:57,150 : INFO : Step 4, Minibatch Loss= 0.1438, Training Accuracy= 0.942
2018-01-03 18:58:57,150 - root - INFO - Step 4, Minibatch Loss= 0.1438, Training Accuracy= 0.942
2018-01-03 18:58:57,150 - root - INFO - Step 4, Minibatch Loss= 0.1438, Training Accuracy= 0.942
2018-01-03 18:58:57,208 : INFO : Step 4, Validation Loss= 0.4210, Validation Accuracy= 0.830
2018-01-03 18:58:57,208 - root - INFO - Step 4, Validation Loss= 0.4210, Validation Accuracy= 0.830
2018-01-03 18:58:57,208 - root - INFO - Step 4, Validation Loss= 0.4210, Validation Accuracy= 0.830
2018-01-03 18:58:59,267 : INFO : Step 5, Minibatch Loss= 0.1100, Training Accuracy= 0.950
2018-01-03 18:58:59,267 - root - INFO - Step 5, Minibatch Loss= 0.1100, Training Accuracy= 0.950
2018-01-03 18:58:59,267 - root - INFO - Step 5, Minibatch Loss= 0.1100, Training Accuracy= 0.950
2018-01-03 18:58:59,325 : INFO : Step 5, Validation Loss= 0.6513, Validation Accuracy= 0.774
2018-01-03 18:58:59,325 - root - INFO - Step 5, Validation Loss= 0.6513, Validation Accuracy= 0.774
2018-01-03 18:58:59,325 - root - INFO - Step 5, Validation Loss= 0.6513, Validation Accuracy= 0.774
2018-01-03 18:58:59,325 : INFO : Average accuracy is 0.849032 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:58:59,325 - root - INFO - Average accuracy is 0.849032 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:58:59,325 - root - INFO - Average accuracy is 0.849032 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 18:58:59,325 : INFO : This 10-fold CV run-time: 153.34055995941162 seconds
2018-01-03 18:58:59,325 - root - INFO - This 10-fold CV run-time: 153.34055995941162 seconds
2018-01-03 18:58:59,325 - root - INFO - This 10-fold CV run-time: 153.34055995941162 seconds
2018-01-03 18:58:59,482 : INFO : current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:58:59,482 - root - INFO - current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:58:59,482 - root - INFO - current best: accuracy=0.851613, num_hidden=20, dropout=0.1
2018-01-03 18:58:59,483 : INFO : results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.85161293, (25, 0.1): 0.84903228}
2018-01-03 18:58:59,483 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.85161293, (25, 0.1): 0.84903228}
2018-01-03 18:58:59,483 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.85161293, (25, 0.1): 0.84903228}
2018-01-03 18:58:59,484 : INFO : Code run-time: 336.64949202537537 seconds
2018-01-03 18:58:59,484 - root - INFO - Code run-time: 336.64949202537537 seconds
2018-01-03 18:58:59,484 - root - INFO - Code run-time: 336.64949202537537 seconds
2018-01-03 23:34:52,856 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:34:52,856 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:34:52,856 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:34:52,857 : INFO : collecting all words and their counts
2018-01-03 23:34:52,857 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:34:52,857 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:34:52,857 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:34:52,857 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:34:52,857 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:34:52,884 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:34:52,884 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:34:52,884 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:34:52,884 : INFO : Loading a fresh vocabulary
2018-01-03 23:34:52,884 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:34:52,884 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:34:52,903 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:34:52,903 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:34:52,903 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:34:52,904 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:34:52,904 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:34:52,904 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:34:52,929 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 23:34:52,929 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:34:52,929 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:34:52,930 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:34:52,930 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:34:52,930 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:34:52,930 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:34:52,944 : INFO : resetting layer weights
2018-01-03 23:34:52,944 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:34:52,944 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:34:53,017 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:53,017 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:53,017 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:53,579 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:53,579 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:53,579 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:53,584 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:53,584 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:53,584 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:53,590 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:53,590 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:53,590 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:53,591 : INFO : training on 797984 raw words (558609 effective words) took 0.6s, 983074 effective words/s
2018-01-03 23:34:53,591 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.6s, 983074 effective words/s
2018-01-03 23:34:53,591 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.6s, 983074 effective words/s
2018-01-03 23:34:53,591 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:53,591 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:53,591 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:34:54,062 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:54,062 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:54,062 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:34:54,066 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:54,066 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:54,066 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:34:54,072 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:54,072 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:54,072 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:34:54,072 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1171672 effective words/s
2018-01-03 23:34:54,072 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1171672 effective words/s
2018-01-03 23:34:54,072 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.5s, 1171672 effective words/s
2018-01-03 23:35:13,646 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:35:13,646 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:35:13,646 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:35:13,646 : INFO : starting fold 1 in 10-fold CV
2018-01-03 23:35:13,646 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:35:13,646 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:35:21,946 : INFO : Step 1, Minibatch Loss= 0.5018, Training Accuracy= 0.758
2018-01-03 23:35:21,946 - root - INFO - Step 1, Minibatch Loss= 0.5018, Training Accuracy= 0.758
2018-01-03 23:35:21,946 - root - INFO - Step 1, Minibatch Loss= 0.5018, Training Accuracy= 0.758
2018-01-03 23:35:22,005 : INFO : Step 1, Validation Loss= 0.7113, Validation Accuracy= 0.445
2018-01-03 23:35:22,005 - root - INFO - Step 1, Validation Loss= 0.7113, Validation Accuracy= 0.445
2018-01-03 23:35:22,005 - root - INFO - Step 1, Validation Loss= 0.7113, Validation Accuracy= 0.445
2018-01-03 23:35:24,032 : INFO : Step 2, Minibatch Loss= 0.2724, Training Accuracy= 0.886
2018-01-03 23:35:24,032 - root - INFO - Step 2, Minibatch Loss= 0.2724, Training Accuracy= 0.886
2018-01-03 23:35:24,032 - root - INFO - Step 2, Minibatch Loss= 0.2724, Training Accuracy= 0.886
2018-01-03 23:35:24,085 : INFO : Step 2, Validation Loss= 0.3736, Validation Accuracy= 0.727
2018-01-03 23:35:24,085 - root - INFO - Step 2, Validation Loss= 0.3736, Validation Accuracy= 0.727
2018-01-03 23:35:24,085 - root - INFO - Step 2, Validation Loss= 0.3736, Validation Accuracy= 0.727
2018-01-03 23:35:26,040 : INFO : Step 3, Minibatch Loss= 0.2043, Training Accuracy= 0.903
2018-01-03 23:35:26,040 - root - INFO - Step 3, Minibatch Loss= 0.2043, Training Accuracy= 0.903
2018-01-03 23:35:26,040 - root - INFO - Step 3, Minibatch Loss= 0.2043, Training Accuracy= 0.903
2018-01-03 23:35:26,094 : INFO : Step 3, Validation Loss= 0.3631, Validation Accuracy= 0.751
2018-01-03 23:35:26,094 - root - INFO - Step 3, Validation Loss= 0.3631, Validation Accuracy= 0.751
2018-01-03 23:35:26,094 - root - INFO - Step 3, Validation Loss= 0.3631, Validation Accuracy= 0.751
2018-01-03 23:35:28,120 : INFO : Step 4, Minibatch Loss= 0.1721, Training Accuracy= 0.920
2018-01-03 23:35:28,120 - root - INFO - Step 4, Minibatch Loss= 0.1721, Training Accuracy= 0.920
2018-01-03 23:35:28,120 - root - INFO - Step 4, Minibatch Loss= 0.1721, Training Accuracy= 0.920
2018-01-03 23:35:28,181 : INFO : Step 4, Validation Loss= 0.3092, Validation Accuracy= 0.800
2018-01-03 23:35:28,181 - root - INFO - Step 4, Validation Loss= 0.3092, Validation Accuracy= 0.800
2018-01-03 23:35:28,181 - root - INFO - Step 4, Validation Loss= 0.3092, Validation Accuracy= 0.800
2018-01-03 23:35:30,180 : INFO : Step 5, Minibatch Loss= 0.1383, Training Accuracy= 0.938
2018-01-03 23:35:30,180 - root - INFO - Step 5, Minibatch Loss= 0.1383, Training Accuracy= 0.938
2018-01-03 23:35:30,180 - root - INFO - Step 5, Minibatch Loss= 0.1383, Training Accuracy= 0.938
2018-01-03 23:35:30,239 : INFO : Step 5, Validation Loss= 0.4128, Validation Accuracy= 0.759
2018-01-03 23:35:30,239 - root - INFO - Step 5, Validation Loss= 0.4128, Validation Accuracy= 0.759
2018-01-03 23:35:30,239 - root - INFO - Step 5, Validation Loss= 0.4128, Validation Accuracy= 0.759
2018-01-03 23:35:30,239 : INFO : starting fold 2 in 10-fold CV
2018-01-03 23:35:30,239 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:35:30,239 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:35:37,687 : INFO : Step 1, Minibatch Loss= 0.5073, Training Accuracy= 0.750
2018-01-03 23:35:37,687 - root - INFO - Step 1, Minibatch Loss= 0.5073, Training Accuracy= 0.750
2018-01-03 23:35:37,687 - root - INFO - Step 1, Minibatch Loss= 0.5073, Training Accuracy= 0.750
2018-01-03 23:35:37,749 : INFO : Step 1, Validation Loss= 0.7494, Validation Accuracy= 0.467
2018-01-03 23:35:37,749 - root - INFO - Step 1, Validation Loss= 0.7494, Validation Accuracy= 0.467
2018-01-03 23:35:37,749 - root - INFO - Step 1, Validation Loss= 0.7494, Validation Accuracy= 0.467
2018-01-03 23:35:39,630 : INFO : Step 2, Minibatch Loss= 0.2676, Training Accuracy= 0.874
2018-01-03 23:35:39,630 - root - INFO - Step 2, Minibatch Loss= 0.2676, Training Accuracy= 0.874
2018-01-03 23:35:39,630 - root - INFO - Step 2, Minibatch Loss= 0.2676, Training Accuracy= 0.874
2018-01-03 23:35:39,684 : INFO : Step 2, Validation Loss= 0.4119, Validation Accuracy= 0.733
2018-01-03 23:35:39,684 - root - INFO - Step 2, Validation Loss= 0.4119, Validation Accuracy= 0.733
2018-01-03 23:35:39,684 - root - INFO - Step 2, Validation Loss= 0.4119, Validation Accuracy= 0.733
2018-01-03 23:35:41,538 : INFO : Step 3, Minibatch Loss= 0.2113, Training Accuracy= 0.899
2018-01-03 23:35:41,538 - root - INFO - Step 3, Minibatch Loss= 0.2113, Training Accuracy= 0.899
2018-01-03 23:35:41,538 - root - INFO - Step 3, Minibatch Loss= 0.2113, Training Accuracy= 0.899
2018-01-03 23:35:41,589 : INFO : Step 3, Validation Loss= 0.4193, Validation Accuracy= 0.744
2018-01-03 23:35:41,589 - root - INFO - Step 3, Validation Loss= 0.4193, Validation Accuracy= 0.744
2018-01-03 23:35:41,589 - root - INFO - Step 3, Validation Loss= 0.4193, Validation Accuracy= 0.744
2018-01-03 23:35:43,578 : INFO : Step 4, Minibatch Loss= 0.1824, Training Accuracy= 0.919
2018-01-03 23:35:43,578 - root - INFO - Step 4, Minibatch Loss= 0.1824, Training Accuracy= 0.919
2018-01-03 23:35:43,578 - root - INFO - Step 4, Minibatch Loss= 0.1824, Training Accuracy= 0.919
2018-01-03 23:35:43,633 : INFO : Step 4, Validation Loss= 0.3603, Validation Accuracy= 0.798
2018-01-03 23:35:43,633 - root - INFO - Step 4, Validation Loss= 0.3603, Validation Accuracy= 0.798
2018-01-03 23:35:43,633 - root - INFO - Step 4, Validation Loss= 0.3603, Validation Accuracy= 0.798
2018-01-03 23:35:45,494 : INFO : Step 5, Minibatch Loss= 0.1480, Training Accuracy= 0.928
2018-01-03 23:35:45,494 - root - INFO - Step 5, Minibatch Loss= 0.1480, Training Accuracy= 0.928
2018-01-03 23:35:45,494 - root - INFO - Step 5, Minibatch Loss= 0.1480, Training Accuracy= 0.928
2018-01-03 23:35:45,545 : INFO : Step 5, Validation Loss= 0.2834, Validation Accuracy= 0.822
2018-01-03 23:35:45,545 - root - INFO - Step 5, Validation Loss= 0.2834, Validation Accuracy= 0.822
2018-01-03 23:35:45,545 - root - INFO - Step 5, Validation Loss= 0.2834, Validation Accuracy= 0.822
2018-01-03 23:35:47,376 : INFO : Step 6, Minibatch Loss= 0.1416, Training Accuracy= 0.931
2018-01-03 23:35:47,376 - root - INFO - Step 6, Minibatch Loss= 0.1416, Training Accuracy= 0.931
2018-01-03 23:35:47,376 - root - INFO - Step 6, Minibatch Loss= 0.1416, Training Accuracy= 0.931
2018-01-03 23:35:47,430 : INFO : Step 6, Validation Loss= 0.5290, Validation Accuracy= 0.761
2018-01-03 23:35:47,430 - root - INFO - Step 6, Validation Loss= 0.5290, Validation Accuracy= 0.761
2018-01-03 23:35:47,430 - root - INFO - Step 6, Validation Loss= 0.5290, Validation Accuracy= 0.761
2018-01-03 23:35:47,430 : INFO : starting fold 3 in 10-fold CV
2018-01-03 23:35:47,430 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:35:47,430 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:35:54,454 : INFO : Step 1, Minibatch Loss= 0.5770, Training Accuracy= 0.695
2018-01-03 23:35:54,454 - root - INFO - Step 1, Minibatch Loss= 0.5770, Training Accuracy= 0.695
2018-01-03 23:35:54,454 - root - INFO - Step 1, Minibatch Loss= 0.5770, Training Accuracy= 0.695
2018-01-03 23:35:54,510 : INFO : Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.624
2018-01-03 23:35:54,510 - root - INFO - Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.624
2018-01-03 23:35:54,510 - root - INFO - Step 1, Validation Loss= 0.6238, Validation Accuracy= 0.624
2018-01-03 23:35:56,346 : INFO : Step 2, Minibatch Loss= 0.3317, Training Accuracy= 0.833
2018-01-03 23:35:56,346 - root - INFO - Step 2, Minibatch Loss= 0.3317, Training Accuracy= 0.833
2018-01-03 23:35:56,346 - root - INFO - Step 2, Minibatch Loss= 0.3317, Training Accuracy= 0.833
2018-01-03 23:35:56,397 : INFO : Step 2, Validation Loss= 0.3502, Validation Accuracy= 0.809
2018-01-03 23:35:56,397 - root - INFO - Step 2, Validation Loss= 0.3502, Validation Accuracy= 0.809
2018-01-03 23:35:56,397 - root - INFO - Step 2, Validation Loss= 0.3502, Validation Accuracy= 0.809
2018-01-03 23:35:58,182 : INFO : Step 3, Minibatch Loss= 0.2548, Training Accuracy= 0.874
2018-01-03 23:35:58,182 - root - INFO - Step 3, Minibatch Loss= 0.2548, Training Accuracy= 0.874
2018-01-03 23:35:58,182 - root - INFO - Step 3, Minibatch Loss= 0.2548, Training Accuracy= 0.874
2018-01-03 23:35:58,236 : INFO : Step 3, Validation Loss= 0.2934, Validation Accuracy= 0.843
2018-01-03 23:35:58,236 - root - INFO - Step 3, Validation Loss= 0.2934, Validation Accuracy= 0.843
2018-01-03 23:35:58,236 - root - INFO - Step 3, Validation Loss= 0.2934, Validation Accuracy= 0.843
2018-01-03 23:36:00,098 : INFO : Step 4, Minibatch Loss= 0.2156, Training Accuracy= 0.884
2018-01-03 23:36:00,098 - root - INFO - Step 4, Minibatch Loss= 0.2156, Training Accuracy= 0.884
2018-01-03 23:36:00,098 - root - INFO - Step 4, Minibatch Loss= 0.2156, Training Accuracy= 0.884
2018-01-03 23:36:00,151 : INFO : Step 4, Validation Loss= 0.3358, Validation Accuracy= 0.802
2018-01-03 23:36:00,151 - root - INFO - Step 4, Validation Loss= 0.3358, Validation Accuracy= 0.802
2018-01-03 23:36:00,151 - root - INFO - Step 4, Validation Loss= 0.3358, Validation Accuracy= 0.802
2018-01-03 23:36:00,151 : INFO : starting fold 4 in 10-fold CV
2018-01-03 23:36:00,151 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:36:00,151 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:36:07,406 : INFO : Step 1, Minibatch Loss= 0.6520, Training Accuracy= 0.664
2018-01-03 23:36:07,406 - root - INFO - Step 1, Minibatch Loss= 0.6520, Training Accuracy= 0.664
2018-01-03 23:36:07,406 - root - INFO - Step 1, Minibatch Loss= 0.6520, Training Accuracy= 0.664
2018-01-03 23:36:07,464 : INFO : Step 1, Validation Loss= 0.5944, Validation Accuracy= 0.703
2018-01-03 23:36:07,464 - root - INFO - Step 1, Validation Loss= 0.5944, Validation Accuracy= 0.703
2018-01-03 23:36:07,464 - root - INFO - Step 1, Validation Loss= 0.5944, Validation Accuracy= 0.703
2018-01-03 23:36:09,327 : INFO : Step 2, Minibatch Loss= 0.3938, Training Accuracy= 0.821
2018-01-03 23:36:09,327 - root - INFO - Step 2, Minibatch Loss= 0.3938, Training Accuracy= 0.821
2018-01-03 23:36:09,327 - root - INFO - Step 2, Minibatch Loss= 0.3938, Training Accuracy= 0.821
2018-01-03 23:36:09,378 : INFO : Step 2, Validation Loss= 0.3891, Validation Accuracy= 0.837
2018-01-03 23:36:09,378 - root - INFO - Step 2, Validation Loss= 0.3891, Validation Accuracy= 0.837
2018-01-03 23:36:09,378 - root - INFO - Step 2, Validation Loss= 0.3891, Validation Accuracy= 0.837
2018-01-03 23:36:11,348 : INFO : Step 3, Minibatch Loss= 0.2571, Training Accuracy= 0.893
2018-01-03 23:36:11,348 - root - INFO - Step 3, Minibatch Loss= 0.2571, Training Accuracy= 0.893
2018-01-03 23:36:11,348 - root - INFO - Step 3, Minibatch Loss= 0.2571, Training Accuracy= 0.893
2018-01-03 23:36:11,400 : INFO : Step 3, Validation Loss= 0.3334, Validation Accuracy= 0.865
2018-01-03 23:36:11,400 - root - INFO - Step 3, Validation Loss= 0.3334, Validation Accuracy= 0.865
2018-01-03 23:36:11,400 - root - INFO - Step 3, Validation Loss= 0.3334, Validation Accuracy= 0.865
2018-01-03 23:36:13,276 : INFO : Step 4, Minibatch Loss= 0.2101, Training Accuracy= 0.913
2018-01-03 23:36:13,276 - root - INFO - Step 4, Minibatch Loss= 0.2101, Training Accuracy= 0.913
2018-01-03 23:36:13,276 - root - INFO - Step 4, Minibatch Loss= 0.2101, Training Accuracy= 0.913
2018-01-03 23:36:13,331 : INFO : Step 4, Validation Loss= 0.3416, Validation Accuracy= 0.854
2018-01-03 23:36:13,331 - root - INFO - Step 4, Validation Loss= 0.3416, Validation Accuracy= 0.854
2018-01-03 23:36:13,331 - root - INFO - Step 4, Validation Loss= 0.3416, Validation Accuracy= 0.854
2018-01-03 23:36:13,331 : INFO : starting fold 5 in 10-fold CV
2018-01-03 23:36:13,331 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:36:13,331 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:36:20,551 : INFO : Step 1, Minibatch Loss= 0.5007, Training Accuracy= 0.756
2018-01-03 23:36:20,551 - root - INFO - Step 1, Minibatch Loss= 0.5007, Training Accuracy= 0.756
2018-01-03 23:36:20,551 - root - INFO - Step 1, Minibatch Loss= 0.5007, Training Accuracy= 0.756
2018-01-03 23:36:20,611 : INFO : Step 1, Validation Loss= 0.5760, Validation Accuracy= 0.669
2018-01-03 23:36:20,611 - root - INFO - Step 1, Validation Loss= 0.5760, Validation Accuracy= 0.669
2018-01-03 23:36:20,611 - root - INFO - Step 1, Validation Loss= 0.5760, Validation Accuracy= 0.669
2018-01-03 23:36:22,451 : INFO : Step 2, Minibatch Loss= 0.2587, Training Accuracy= 0.888
2018-01-03 23:36:22,451 - root - INFO - Step 2, Minibatch Loss= 0.2587, Training Accuracy= 0.888
2018-01-03 23:36:22,451 - root - INFO - Step 2, Minibatch Loss= 0.2587, Training Accuracy= 0.888
2018-01-03 23:36:22,505 : INFO : Step 2, Validation Loss= 0.4515, Validation Accuracy= 0.817
2018-01-03 23:36:22,505 - root - INFO - Step 2, Validation Loss= 0.4515, Validation Accuracy= 0.817
2018-01-03 23:36:22,505 - root - INFO - Step 2, Validation Loss= 0.4515, Validation Accuracy= 0.817
2018-01-03 23:36:24,433 : INFO : Step 3, Minibatch Loss= 0.2137, Training Accuracy= 0.902
2018-01-03 23:36:24,433 - root - INFO - Step 3, Minibatch Loss= 0.2137, Training Accuracy= 0.902
2018-01-03 23:36:24,433 - root - INFO - Step 3, Minibatch Loss= 0.2137, Training Accuracy= 0.902
2018-01-03 23:36:24,490 : INFO : Step 3, Validation Loss= 0.3519, Validation Accuracy= 0.826
2018-01-03 23:36:24,490 - root - INFO - Step 3, Validation Loss= 0.3519, Validation Accuracy= 0.826
2018-01-03 23:36:24,490 - root - INFO - Step 3, Validation Loss= 0.3519, Validation Accuracy= 0.826
2018-01-03 23:36:26,335 : INFO : Step 4, Minibatch Loss= 0.1737, Training Accuracy= 0.917
2018-01-03 23:36:26,335 - root - INFO - Step 4, Minibatch Loss= 0.1737, Training Accuracy= 0.917
2018-01-03 23:36:26,335 - root - INFO - Step 4, Minibatch Loss= 0.1737, Training Accuracy= 0.917
2018-01-03 23:36:26,387 : INFO : Step 4, Validation Loss= 0.3689, Validation Accuracy= 0.830
2018-01-03 23:36:26,387 - root - INFO - Step 4, Validation Loss= 0.3689, Validation Accuracy= 0.830
2018-01-03 23:36:26,387 - root - INFO - Step 4, Validation Loss= 0.3689, Validation Accuracy= 0.830
2018-01-03 23:36:28,217 : INFO : Step 5, Minibatch Loss= 0.1608, Training Accuracy= 0.918
2018-01-03 23:36:28,217 - root - INFO - Step 5, Minibatch Loss= 0.1608, Training Accuracy= 0.918
2018-01-03 23:36:28,217 - root - INFO - Step 5, Minibatch Loss= 0.1608, Training Accuracy= 0.918
2018-01-03 23:36:28,270 : INFO : Step 5, Validation Loss= 0.4873, Validation Accuracy= 0.813
2018-01-03 23:36:28,270 - root - INFO - Step 5, Validation Loss= 0.4873, Validation Accuracy= 0.813
2018-01-03 23:36:28,270 - root - INFO - Step 5, Validation Loss= 0.4873, Validation Accuracy= 0.813
2018-01-03 23:36:28,270 : INFO : starting fold 6 in 10-fold CV
2018-01-03 23:36:28,270 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:36:28,270 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:36:35,376 : INFO : Step 1, Minibatch Loss= 0.4945, Training Accuracy= 0.772
2018-01-03 23:36:35,376 - root - INFO - Step 1, Minibatch Loss= 0.4945, Training Accuracy= 0.772
2018-01-03 23:36:35,376 - root - INFO - Step 1, Minibatch Loss= 0.4945, Training Accuracy= 0.772
2018-01-03 23:36:35,429 : INFO : Step 1, Validation Loss= 0.5551, Validation Accuracy= 0.699
2018-01-03 23:36:35,429 - root - INFO - Step 1, Validation Loss= 0.5551, Validation Accuracy= 0.699
2018-01-03 23:36:35,429 - root - INFO - Step 1, Validation Loss= 0.5551, Validation Accuracy= 0.699
2018-01-03 23:36:37,317 : INFO : Step 2, Minibatch Loss= 0.2637, Training Accuracy= 0.882
2018-01-03 23:36:37,317 - root - INFO - Step 2, Minibatch Loss= 0.2637, Training Accuracy= 0.882
2018-01-03 23:36:37,317 - root - INFO - Step 2, Minibatch Loss= 0.2637, Training Accuracy= 0.882
2018-01-03 23:36:37,369 : INFO : Step 2, Validation Loss= 0.4340, Validation Accuracy= 0.794
2018-01-03 23:36:37,369 - root - INFO - Step 2, Validation Loss= 0.4340, Validation Accuracy= 0.794
2018-01-03 23:36:37,369 - root - INFO - Step 2, Validation Loss= 0.4340, Validation Accuracy= 0.794
2018-01-03 23:36:39,296 : INFO : Step 3, Minibatch Loss= 0.1996, Training Accuracy= 0.908
2018-01-03 23:36:39,296 - root - INFO - Step 3, Minibatch Loss= 0.1996, Training Accuracy= 0.908
2018-01-03 23:36:39,296 - root - INFO - Step 3, Minibatch Loss= 0.1996, Training Accuracy= 0.908
2018-01-03 23:36:39,349 : INFO : Step 3, Validation Loss= 0.2963, Validation Accuracy= 0.830
2018-01-03 23:36:39,349 - root - INFO - Step 3, Validation Loss= 0.2963, Validation Accuracy= 0.830
2018-01-03 23:36:39,349 - root - INFO - Step 3, Validation Loss= 0.2963, Validation Accuracy= 0.830
2018-01-03 23:36:41,182 : INFO : Step 4, Minibatch Loss= 0.1801, Training Accuracy= 0.916
2018-01-03 23:36:41,182 - root - INFO - Step 4, Minibatch Loss= 0.1801, Training Accuracy= 0.916
2018-01-03 23:36:41,182 - root - INFO - Step 4, Minibatch Loss= 0.1801, Training Accuracy= 0.916
2018-01-03 23:36:41,233 : INFO : Step 4, Validation Loss= 0.3420, Validation Accuracy= 0.826
2018-01-03 23:36:41,233 - root - INFO - Step 4, Validation Loss= 0.3420, Validation Accuracy= 0.826
2018-01-03 23:36:41,233 - root - INFO - Step 4, Validation Loss= 0.3420, Validation Accuracy= 0.826
2018-01-03 23:36:41,233 : INFO : starting fold 7 in 10-fold CV
2018-01-03 23:36:41,233 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:36:41,233 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:36:48,063 : INFO : Step 1, Minibatch Loss= 0.5857, Training Accuracy= 0.702
2018-01-03 23:36:48,063 - root - INFO - Step 1, Minibatch Loss= 0.5857, Training Accuracy= 0.702
2018-01-03 23:36:48,063 - root - INFO - Step 1, Minibatch Loss= 0.5857, Training Accuracy= 0.702
2018-01-03 23:36:48,124 : INFO : Step 1, Validation Loss= 0.7506, Validation Accuracy= 0.540
2018-01-03 23:36:48,124 - root - INFO - Step 1, Validation Loss= 0.7506, Validation Accuracy= 0.540
2018-01-03 23:36:48,124 - root - INFO - Step 1, Validation Loss= 0.7506, Validation Accuracy= 0.540
2018-01-03 23:36:49,899 : INFO : Step 2, Minibatch Loss= 0.3312, Training Accuracy= 0.860
2018-01-03 23:36:49,899 - root - INFO - Step 2, Minibatch Loss= 0.3312, Training Accuracy= 0.860
2018-01-03 23:36:49,899 - root - INFO - Step 2, Minibatch Loss= 0.3312, Training Accuracy= 0.860
2018-01-03 23:36:49,951 : INFO : Step 2, Validation Loss= 0.5032, Validation Accuracy= 0.735
2018-01-03 23:36:49,951 - root - INFO - Step 2, Validation Loss= 0.5032, Validation Accuracy= 0.735
2018-01-03 23:36:49,951 - root - INFO - Step 2, Validation Loss= 0.5032, Validation Accuracy= 0.735
2018-01-03 23:36:51,789 : INFO : Step 3, Minibatch Loss= 0.2349, Training Accuracy= 0.900
2018-01-03 23:36:51,789 - root - INFO - Step 3, Minibatch Loss= 0.2349, Training Accuracy= 0.900
2018-01-03 23:36:51,789 - root - INFO - Step 3, Minibatch Loss= 0.2349, Training Accuracy= 0.900
2018-01-03 23:36:51,842 : INFO : Step 3, Validation Loss= 0.4899, Validation Accuracy= 0.772
2018-01-03 23:36:51,842 - root - INFO - Step 3, Validation Loss= 0.4899, Validation Accuracy= 0.772
2018-01-03 23:36:51,842 - root - INFO - Step 3, Validation Loss= 0.4899, Validation Accuracy= 0.772
2018-01-03 23:36:53,711 : INFO : Step 4, Minibatch Loss= 0.2034, Training Accuracy= 0.912
2018-01-03 23:36:53,711 - root - INFO - Step 4, Minibatch Loss= 0.2034, Training Accuracy= 0.912
2018-01-03 23:36:53,711 - root - INFO - Step 4, Minibatch Loss= 0.2034, Training Accuracy= 0.912
2018-01-03 23:36:53,766 : INFO : Step 4, Validation Loss= 0.4609, Validation Accuracy= 0.757
2018-01-03 23:36:53,766 - root - INFO - Step 4, Validation Loss= 0.4609, Validation Accuracy= 0.757
2018-01-03 23:36:53,766 - root - INFO - Step 4, Validation Loss= 0.4609, Validation Accuracy= 0.757
2018-01-03 23:36:53,766 : INFO : starting fold 8 in 10-fold CV
2018-01-03 23:36:53,766 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:36:53,766 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:37:01,011 : INFO : Step 1, Minibatch Loss= 0.4924, Training Accuracy= 0.779
2018-01-03 23:37:01,011 - root - INFO - Step 1, Minibatch Loss= 0.4924, Training Accuracy= 0.779
2018-01-03 23:37:01,011 - root - INFO - Step 1, Minibatch Loss= 0.4924, Training Accuracy= 0.779
2018-01-03 23:37:01,067 : INFO : Step 1, Validation Loss= 0.5547, Validation Accuracy= 0.712
2018-01-03 23:37:01,067 - root - INFO - Step 1, Validation Loss= 0.5547, Validation Accuracy= 0.712
2018-01-03 23:37:01,067 - root - INFO - Step 1, Validation Loss= 0.5547, Validation Accuracy= 0.712
2018-01-03 23:37:02,905 : INFO : Step 2, Minibatch Loss= 0.2775, Training Accuracy= 0.872
2018-01-03 23:37:02,905 - root - INFO - Step 2, Minibatch Loss= 0.2775, Training Accuracy= 0.872
2018-01-03 23:37:02,905 - root - INFO - Step 2, Minibatch Loss= 0.2775, Training Accuracy= 0.872
2018-01-03 23:37:02,979 : INFO : Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.806
2018-01-03 23:37:02,979 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.806
2018-01-03 23:37:02,979 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.806
2018-01-03 23:37:04,988 : INFO : Step 3, Minibatch Loss= 0.1967, Training Accuracy= 0.913
2018-01-03 23:37:04,988 - root - INFO - Step 3, Minibatch Loss= 0.1967, Training Accuracy= 0.913
2018-01-03 23:37:04,988 - root - INFO - Step 3, Minibatch Loss= 0.1967, Training Accuracy= 0.913
2018-01-03 23:37:05,039 : INFO : Step 3, Validation Loss= 0.3182, Validation Accuracy= 0.834
2018-01-03 23:37:05,039 - root - INFO - Step 3, Validation Loss= 0.3182, Validation Accuracy= 0.834
2018-01-03 23:37:05,039 - root - INFO - Step 3, Validation Loss= 0.3182, Validation Accuracy= 0.834
2018-01-03 23:37:06,870 : INFO : Step 4, Minibatch Loss= 0.1726, Training Accuracy= 0.913
2018-01-03 23:37:06,870 - root - INFO - Step 4, Minibatch Loss= 0.1726, Training Accuracy= 0.913
2018-01-03 23:37:06,870 - root - INFO - Step 4, Minibatch Loss= 0.1726, Training Accuracy= 0.913
2018-01-03 23:37:06,944 : INFO : Step 4, Validation Loss= 0.3542, Validation Accuracy= 0.826
2018-01-03 23:37:06,944 - root - INFO - Step 4, Validation Loss= 0.3542, Validation Accuracy= 0.826
2018-01-03 23:37:06,944 - root - INFO - Step 4, Validation Loss= 0.3542, Validation Accuracy= 0.826
2018-01-03 23:37:06,945 : INFO : starting fold 9 in 10-fold CV
2018-01-03 23:37:06,945 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:37:06,945 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:37:14,454 : INFO : Step 1, Minibatch Loss= 0.5478, Training Accuracy= 0.741
2018-01-03 23:37:14,454 - root - INFO - Step 1, Minibatch Loss= 0.5478, Training Accuracy= 0.741
2018-01-03 23:37:14,454 - root - INFO - Step 1, Minibatch Loss= 0.5478, Training Accuracy= 0.741
2018-01-03 23:37:14,510 : INFO : Step 1, Validation Loss= 0.5402, Validation Accuracy= 0.806
2018-01-03 23:37:14,510 - root - INFO - Step 1, Validation Loss= 0.5402, Validation Accuracy= 0.806
2018-01-03 23:37:14,510 - root - INFO - Step 1, Validation Loss= 0.5402, Validation Accuracy= 0.806
2018-01-03 23:37:16,439 : INFO : Step 2, Minibatch Loss= 0.2818, Training Accuracy= 0.865
2018-01-03 23:37:16,439 - root - INFO - Step 2, Minibatch Loss= 0.2818, Training Accuracy= 0.865
2018-01-03 23:37:16,439 - root - INFO - Step 2, Minibatch Loss= 0.2818, Training Accuracy= 0.865
2018-01-03 23:37:16,486 : INFO : Step 2, Validation Loss= 0.3072, Validation Accuracy= 0.884
2018-01-03 23:37:16,486 - root - INFO - Step 2, Validation Loss= 0.3072, Validation Accuracy= 0.884
2018-01-03 23:37:16,486 - root - INFO - Step 2, Validation Loss= 0.3072, Validation Accuracy= 0.884
2018-01-03 23:37:18,344 : INFO : Step 3, Minibatch Loss= 0.1952, Training Accuracy= 0.901
2018-01-03 23:37:18,344 - root - INFO - Step 3, Minibatch Loss= 0.1952, Training Accuracy= 0.901
2018-01-03 23:37:18,344 - root - INFO - Step 3, Minibatch Loss= 0.1952, Training Accuracy= 0.901
2018-01-03 23:37:18,394 : INFO : Step 3, Validation Loss= 0.3266, Validation Accuracy= 0.884
2018-01-03 23:37:18,394 - root - INFO - Step 3, Validation Loss= 0.3266, Validation Accuracy= 0.884
2018-01-03 23:37:18,394 - root - INFO - Step 3, Validation Loss= 0.3266, Validation Accuracy= 0.884
2018-01-03 23:37:20,243 : INFO : Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.919
2018-01-03 23:37:20,243 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.919
2018-01-03 23:37:20,243 - root - INFO - Step 4, Minibatch Loss= 0.1580, Training Accuracy= 0.919
2018-01-03 23:37:20,297 : INFO : Step 4, Validation Loss= 0.3413, Validation Accuracy= 0.892
2018-01-03 23:37:20,297 - root - INFO - Step 4, Validation Loss= 0.3413, Validation Accuracy= 0.892
2018-01-03 23:37:20,297 - root - INFO - Step 4, Validation Loss= 0.3413, Validation Accuracy= 0.892
2018-01-03 23:37:22,219 : INFO : Step 5, Minibatch Loss= 0.1559, Training Accuracy= 0.919
2018-01-03 23:37:22,219 - root - INFO - Step 5, Minibatch Loss= 0.1559, Training Accuracy= 0.919
2018-01-03 23:37:22,219 - root - INFO - Step 5, Minibatch Loss= 0.1559, Training Accuracy= 0.919
2018-01-03 23:37:22,272 : INFO : Step 5, Validation Loss= 0.2721, Validation Accuracy= 0.897
2018-01-03 23:37:22,272 - root - INFO - Step 5, Validation Loss= 0.2721, Validation Accuracy= 0.897
2018-01-03 23:37:22,272 - root - INFO - Step 5, Validation Loss= 0.2721, Validation Accuracy= 0.897
2018-01-03 23:37:24,210 : INFO : Step 6, Minibatch Loss= 0.1286, Training Accuracy= 0.931
2018-01-03 23:37:24,210 - root - INFO - Step 6, Minibatch Loss= 0.1286, Training Accuracy= 0.931
2018-01-03 23:37:24,210 - root - INFO - Step 6, Minibatch Loss= 0.1286, Training Accuracy= 0.931
2018-01-03 23:37:24,260 : INFO : Step 6, Validation Loss= 0.3044, Validation Accuracy= 0.895
2018-01-03 23:37:24,260 - root - INFO - Step 6, Validation Loss= 0.3044, Validation Accuracy= 0.895
2018-01-03 23:37:24,260 - root - INFO - Step 6, Validation Loss= 0.3044, Validation Accuracy= 0.895
2018-01-03 23:37:24,260 : INFO : starting fold 10 in 10-fold CV
2018-01-03 23:37:24,260 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:37:24,260 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:37:31,483 : INFO : Step 1, Minibatch Loss= 0.5549, Training Accuracy= 0.722
2018-01-03 23:37:31,483 - root - INFO - Step 1, Minibatch Loss= 0.5549, Training Accuracy= 0.722
2018-01-03 23:37:31,483 - root - INFO - Step 1, Minibatch Loss= 0.5549, Training Accuracy= 0.722
2018-01-03 23:37:31,541 : INFO : Step 1, Validation Loss= 0.5658, Validation Accuracy= 0.772
2018-01-03 23:37:31,541 - root - INFO - Step 1, Validation Loss= 0.5658, Validation Accuracy= 0.772
2018-01-03 23:37:31,541 - root - INFO - Step 1, Validation Loss= 0.5658, Validation Accuracy= 0.772
2018-01-03 23:37:33,359 : INFO : Step 2, Minibatch Loss= 0.3032, Training Accuracy= 0.852
2018-01-03 23:37:33,359 - root - INFO - Step 2, Minibatch Loss= 0.3032, Training Accuracy= 0.852
2018-01-03 23:37:33,359 - root - INFO - Step 2, Minibatch Loss= 0.3032, Training Accuracy= 0.852
2018-01-03 23:37:33,411 : INFO : Step 2, Validation Loss= 0.5610, Validation Accuracy= 0.865
2018-01-03 23:37:33,411 - root - INFO - Step 2, Validation Loss= 0.5610, Validation Accuracy= 0.865
2018-01-03 23:37:33,411 - root - INFO - Step 2, Validation Loss= 0.5610, Validation Accuracy= 0.865
2018-01-03 23:37:35,367 : INFO : Step 3, Minibatch Loss= 0.2173, Training Accuracy= 0.903
2018-01-03 23:37:35,367 - root - INFO - Step 3, Minibatch Loss= 0.2173, Training Accuracy= 0.903
2018-01-03 23:37:35,367 - root - INFO - Step 3, Minibatch Loss= 0.2173, Training Accuracy= 0.903
2018-01-03 23:37:35,420 : INFO : Step 3, Validation Loss= 0.3438, Validation Accuracy= 0.899
2018-01-03 23:37:35,420 - root - INFO - Step 3, Validation Loss= 0.3438, Validation Accuracy= 0.899
2018-01-03 23:37:35,420 - root - INFO - Step 3, Validation Loss= 0.3438, Validation Accuracy= 0.899
2018-01-03 23:37:37,363 : INFO : Step 4, Minibatch Loss= 0.1799, Training Accuracy= 0.914
2018-01-03 23:37:37,363 - root - INFO - Step 4, Minibatch Loss= 0.1799, Training Accuracy= 0.914
2018-01-03 23:37:37,363 - root - INFO - Step 4, Minibatch Loss= 0.1799, Training Accuracy= 0.914
2018-01-03 23:37:37,417 : INFO : Step 4, Validation Loss= 0.3556, Validation Accuracy= 0.899
2018-01-03 23:37:37,417 - root - INFO - Step 4, Validation Loss= 0.3556, Validation Accuracy= 0.899
2018-01-03 23:37:37,417 - root - INFO - Step 4, Validation Loss= 0.3556, Validation Accuracy= 0.899
2018-01-03 23:37:39,378 : INFO : Step 5, Minibatch Loss= 0.1591, Training Accuracy= 0.915
2018-01-03 23:37:39,378 - root - INFO - Step 5, Minibatch Loss= 0.1591, Training Accuracy= 0.915
2018-01-03 23:37:39,378 - root - INFO - Step 5, Minibatch Loss= 0.1591, Training Accuracy= 0.915
2018-01-03 23:37:39,438 : INFO : Step 5, Validation Loss= 0.3462, Validation Accuracy= 0.901
2018-01-03 23:37:39,438 - root - INFO - Step 5, Validation Loss= 0.3462, Validation Accuracy= 0.901
2018-01-03 23:37:39,438 - root - INFO - Step 5, Validation Loss= 0.3462, Validation Accuracy= 0.901
2018-01-03 23:37:41,402 : INFO : Step 6, Minibatch Loss= 0.1377, Training Accuracy= 0.925
2018-01-03 23:37:41,402 - root - INFO - Step 6, Minibatch Loss= 0.1377, Training Accuracy= 0.925
2018-01-03 23:37:41,402 - root - INFO - Step 6, Minibatch Loss= 0.1377, Training Accuracy= 0.925
2018-01-03 23:37:41,456 : INFO : Step 6, Validation Loss= 0.3167, Validation Accuracy= 0.901
2018-01-03 23:37:41,456 - root - INFO - Step 6, Validation Loss= 0.3167, Validation Accuracy= 0.901
2018-01-03 23:37:41,456 - root - INFO - Step 6, Validation Loss= 0.3167, Validation Accuracy= 0.901
2018-01-03 23:37:43,455 : INFO : Step 7, Minibatch Loss= 0.1307, Training Accuracy= 0.928
2018-01-03 23:37:43,455 - root - INFO - Step 7, Minibatch Loss= 0.1307, Training Accuracy= 0.928
2018-01-03 23:37:43,455 - root - INFO - Step 7, Minibatch Loss= 0.1307, Training Accuracy= 0.928
2018-01-03 23:37:43,511 : INFO : Step 7, Validation Loss= 0.6699, Validation Accuracy= 0.875
2018-01-03 23:37:43,511 - root - INFO - Step 7, Validation Loss= 0.6699, Validation Accuracy= 0.875
2018-01-03 23:37:43,511 - root - INFO - Step 7, Validation Loss= 0.6699, Validation Accuracy= 0.875
2018-01-03 23:37:43,512 : INFO : Average accuracy is 0.839355 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:37:43,512 - root - INFO - Average accuracy is 0.839355 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:37:43,512 - root - INFO - Average accuracy is 0.839355 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:37:43,512 : INFO : This 10-fold CV run-time: 149.866149187088 seconds
2018-01-03 23:37:43,512 - root - INFO - This 10-fold CV run-time: 149.866149187088 seconds
2018-01-03 23:37:43,512 - root - INFO - This 10-fold CV run-time: 149.866149187088 seconds
2018-01-03 23:37:43,684 : INFO : current best: accuracy=0.839355, num_hidden=20, dropout=0.1
2018-01-03 23:37:43,684 - root - INFO - current best: accuracy=0.839355, num_hidden=20, dropout=0.1
2018-01-03 23:37:43,684 - root - INFO - current best: accuracy=0.839355, num_hidden=20, dropout=0.1
2018-01-03 23:37:44,157 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:37:44,157 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:37:44,157 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:37:44,157 : INFO : collecting all words and their counts
2018-01-03 23:37:44,157 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:37:44,157 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:37:44,157 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:37:44,157 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:37:44,157 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:37:44,179 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:37:44,179 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:37:44,179 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:37:44,179 : INFO : Loading a fresh vocabulary
2018-01-03 23:37:44,179 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:37:44,179 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:37:44,194 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:37:44,194 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:37:44,194 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:37:44,194 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:37:44,194 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:37:44,194 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:37:44,216 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 23:37:44,216 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:37:44,216 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:37:44,217 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:37:44,217 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:37:44,217 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:37:44,217 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:37:44,231 : INFO : resetting layer weights
2018-01-03 23:37:44,231 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:37:44,231 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:37:44,297 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:44,297 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:44,297 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:44,727 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:44,727 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:44,727 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:44,729 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:44,729 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:44,729 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:44,733 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:44,733 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:44,733 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:44,733 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1293575 effective words/s
2018-01-03 23:37:44,733 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1293575 effective words/s
2018-01-03 23:37:44,733 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1293575 effective words/s
2018-01-03 23:37:44,734 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:44,734 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:44,734 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:37:45,242 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:45,242 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:45,242 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:37:45,245 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:45,245 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:45,245 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:37:45,248 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:45,248 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:45,248 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:37:45,248 : INFO : training on 797984 raw words (558914 effective words) took 0.5s, 1103350 effective words/s
2018-01-03 23:37:45,248 - gensim.models.word2vec - INFO - training on 797984 raw words (558914 effective words) took 0.5s, 1103350 effective words/s
2018-01-03 23:37:45,248 - gensim.models.word2vec - INFO - training on 797984 raw words (558914 effective words) took 0.5s, 1103350 effective words/s
2018-01-03 23:38:03,803 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:38:03,803 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:38:03,803 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:38:03,803 : INFO : starting fold 1 in 10-fold CV
2018-01-03 23:38:03,803 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:38:03,803 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:38:12,140 : INFO : Step 1, Minibatch Loss= 0.5120, Training Accuracy= 0.753
2018-01-03 23:38:12,140 - root - INFO - Step 1, Minibatch Loss= 0.5120, Training Accuracy= 0.753
2018-01-03 23:38:12,140 - root - INFO - Step 1, Minibatch Loss= 0.5120, Training Accuracy= 0.753
2018-01-03 23:38:12,207 : INFO : Step 1, Validation Loss= 0.7162, Validation Accuracy= 0.419
2018-01-03 23:38:12,207 - root - INFO - Step 1, Validation Loss= 0.7162, Validation Accuracy= 0.419
2018-01-03 23:38:12,207 - root - INFO - Step 1, Validation Loss= 0.7162, Validation Accuracy= 0.419
2018-01-03 23:38:14,368 : INFO : Step 2, Minibatch Loss= 0.2547, Training Accuracy= 0.897
2018-01-03 23:38:14,368 - root - INFO - Step 2, Minibatch Loss= 0.2547, Training Accuracy= 0.897
2018-01-03 23:38:14,368 - root - INFO - Step 2, Minibatch Loss= 0.2547, Training Accuracy= 0.897
2018-01-03 23:38:14,436 : INFO : Step 2, Validation Loss= 0.4084, Validation Accuracy= 0.740
2018-01-03 23:38:14,436 - root - INFO - Step 2, Validation Loss= 0.4084, Validation Accuracy= 0.740
2018-01-03 23:38:14,436 - root - INFO - Step 2, Validation Loss= 0.4084, Validation Accuracy= 0.740
2018-01-03 23:38:16,598 : INFO : Step 3, Minibatch Loss= 0.1829, Training Accuracy= 0.920
2018-01-03 23:38:16,598 - root - INFO - Step 3, Minibatch Loss= 0.1829, Training Accuracy= 0.920
2018-01-03 23:38:16,598 - root - INFO - Step 3, Minibatch Loss= 0.1829, Training Accuracy= 0.920
2018-01-03 23:38:16,665 : INFO : Step 3, Validation Loss= 0.4130, Validation Accuracy= 0.729
2018-01-03 23:38:16,665 - root - INFO - Step 3, Validation Loss= 0.4130, Validation Accuracy= 0.729
2018-01-03 23:38:16,665 - root - INFO - Step 3, Validation Loss= 0.4130, Validation Accuracy= 0.729
2018-01-03 23:38:16,665 : INFO : starting fold 2 in 10-fold CV
2018-01-03 23:38:16,665 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:38:16,665 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:38:24,191 : INFO : Step 1, Minibatch Loss= 0.5415, Training Accuracy= 0.732
2018-01-03 23:38:24,191 - root - INFO - Step 1, Minibatch Loss= 0.5415, Training Accuracy= 0.732
2018-01-03 23:38:24,191 - root - INFO - Step 1, Minibatch Loss= 0.5415, Training Accuracy= 0.732
2018-01-03 23:38:24,251 : INFO : Step 1, Validation Loss= 0.5057, Validation Accuracy= 0.828
2018-01-03 23:38:24,251 - root - INFO - Step 1, Validation Loss= 0.5057, Validation Accuracy= 0.828
2018-01-03 23:38:24,251 - root - INFO - Step 1, Validation Loss= 0.5057, Validation Accuracy= 0.828
2018-01-03 23:38:26,322 : INFO : Step 2, Minibatch Loss= 0.2583, Training Accuracy= 0.883
2018-01-03 23:38:26,322 - root - INFO - Step 2, Minibatch Loss= 0.2583, Training Accuracy= 0.883
2018-01-03 23:38:26,322 - root - INFO - Step 2, Minibatch Loss= 0.2583, Training Accuracy= 0.883
2018-01-03 23:38:26,393 : INFO : Step 2, Validation Loss= 0.3147, Validation Accuracy= 0.923
2018-01-03 23:38:26,393 - root - INFO - Step 2, Validation Loss= 0.3147, Validation Accuracy= 0.923
2018-01-03 23:38:26,393 - root - INFO - Step 2, Validation Loss= 0.3147, Validation Accuracy= 0.923
2018-01-03 23:38:28,496 : INFO : Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.919
2018-01-03 23:38:28,496 - root - INFO - Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.919
2018-01-03 23:38:28,496 - root - INFO - Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.919
2018-01-03 23:38:28,559 : INFO : Step 3, Validation Loss= 0.3870, Validation Accuracy= 0.914
2018-01-03 23:38:28,559 - root - INFO - Step 3, Validation Loss= 0.3870, Validation Accuracy= 0.914
2018-01-03 23:38:28,559 - root - INFO - Step 3, Validation Loss= 0.3870, Validation Accuracy= 0.914
2018-01-03 23:38:28,560 : INFO : starting fold 3 in 10-fold CV
2018-01-03 23:38:28,560 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:38:28,560 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:38:35,927 : INFO : Step 1, Minibatch Loss= 0.5482, Training Accuracy= 0.725
2018-01-03 23:38:35,927 - root - INFO - Step 1, Minibatch Loss= 0.5482, Training Accuracy= 0.725
2018-01-03 23:38:35,927 - root - INFO - Step 1, Minibatch Loss= 0.5482, Training Accuracy= 0.725
2018-01-03 23:38:35,995 : INFO : Step 1, Validation Loss= 0.5681, Validation Accuracy= 0.714
2018-01-03 23:38:35,995 - root - INFO - Step 1, Validation Loss= 0.5681, Validation Accuracy= 0.714
2018-01-03 23:38:35,995 - root - INFO - Step 1, Validation Loss= 0.5681, Validation Accuracy= 0.714
2018-01-03 23:38:38,145 : INFO : Step 2, Minibatch Loss= 0.2473, Training Accuracy= 0.888
2018-01-03 23:38:38,145 - root - INFO - Step 2, Minibatch Loss= 0.2473, Training Accuracy= 0.888
2018-01-03 23:38:38,145 - root - INFO - Step 2, Minibatch Loss= 0.2473, Training Accuracy= 0.888
2018-01-03 23:38:38,210 : INFO : Step 2, Validation Loss= 0.3014, Validation Accuracy= 0.832
2018-01-03 23:38:38,210 - root - INFO - Step 2, Validation Loss= 0.3014, Validation Accuracy= 0.832
2018-01-03 23:38:38,210 - root - INFO - Step 2, Validation Loss= 0.3014, Validation Accuracy= 0.832
2018-01-03 23:38:40,344 : INFO : Step 3, Minibatch Loss= 0.1943, Training Accuracy= 0.914
2018-01-03 23:38:40,344 - root - INFO - Step 3, Minibatch Loss= 0.1943, Training Accuracy= 0.914
2018-01-03 23:38:40,344 - root - INFO - Step 3, Minibatch Loss= 0.1943, Training Accuracy= 0.914
2018-01-03 23:38:40,417 : INFO : Step 3, Validation Loss= 0.3073, Validation Accuracy= 0.860
2018-01-03 23:38:40,417 - root - INFO - Step 3, Validation Loss= 0.3073, Validation Accuracy= 0.860
2018-01-03 23:38:40,417 - root - INFO - Step 3, Validation Loss= 0.3073, Validation Accuracy= 0.860
2018-01-03 23:38:42,554 : INFO : Step 4, Minibatch Loss= 0.1522, Training Accuracy= 0.928
2018-01-03 23:38:42,554 - root - INFO - Step 4, Minibatch Loss= 0.1522, Training Accuracy= 0.928
2018-01-03 23:38:42,554 - root - INFO - Step 4, Minibatch Loss= 0.1522, Training Accuracy= 0.928
2018-01-03 23:38:42,621 : INFO : Step 4, Validation Loss= 0.3478, Validation Accuracy= 0.873
2018-01-03 23:38:42,621 - root - INFO - Step 4, Validation Loss= 0.3478, Validation Accuracy= 0.873
2018-01-03 23:38:42,621 - root - INFO - Step 4, Validation Loss= 0.3478, Validation Accuracy= 0.873
2018-01-03 23:38:44,860 : INFO : Step 5, Minibatch Loss= 0.1254, Training Accuracy= 0.948
2018-01-03 23:38:44,860 - root - INFO - Step 5, Minibatch Loss= 0.1254, Training Accuracy= 0.948
2018-01-03 23:38:44,860 - root - INFO - Step 5, Minibatch Loss= 0.1254, Training Accuracy= 0.948
2018-01-03 23:38:44,928 : INFO : Step 5, Validation Loss= 0.4053, Validation Accuracy= 0.880
2018-01-03 23:38:44,928 - root - INFO - Step 5, Validation Loss= 0.4053, Validation Accuracy= 0.880
2018-01-03 23:38:44,928 - root - INFO - Step 5, Validation Loss= 0.4053, Validation Accuracy= 0.880
2018-01-03 23:38:47,091 : INFO : Step 6, Minibatch Loss= 0.1187, Training Accuracy= 0.948
2018-01-03 23:38:47,091 - root - INFO - Step 6, Minibatch Loss= 0.1187, Training Accuracy= 0.948
2018-01-03 23:38:47,091 - root - INFO - Step 6, Minibatch Loss= 0.1187, Training Accuracy= 0.948
2018-01-03 23:38:47,156 : INFO : Step 6, Validation Loss= 0.3675, Validation Accuracy= 0.882
2018-01-03 23:38:47,156 - root - INFO - Step 6, Validation Loss= 0.3675, Validation Accuracy= 0.882
2018-01-03 23:38:47,156 - root - INFO - Step 6, Validation Loss= 0.3675, Validation Accuracy= 0.882
2018-01-03 23:38:49,301 : INFO : Step 7, Minibatch Loss= 0.1012, Training Accuracy= 0.955
2018-01-03 23:38:49,301 - root - INFO - Step 7, Minibatch Loss= 0.1012, Training Accuracy= 0.955
2018-01-03 23:38:49,301 - root - INFO - Step 7, Minibatch Loss= 0.1012, Training Accuracy= 0.955
2018-01-03 23:38:49,374 : INFO : Step 7, Validation Loss= 0.4451, Validation Accuracy= 0.905
2018-01-03 23:38:49,374 - root - INFO - Step 7, Validation Loss= 0.4451, Validation Accuracy= 0.905
2018-01-03 23:38:49,374 - root - INFO - Step 7, Validation Loss= 0.4451, Validation Accuracy= 0.905
2018-01-03 23:38:51,594 : INFO : Step 8, Minibatch Loss= 0.0953, Training Accuracy= 0.958
2018-01-03 23:38:51,594 - root - INFO - Step 8, Minibatch Loss= 0.0953, Training Accuracy= 0.958
2018-01-03 23:38:51,594 - root - INFO - Step 8, Minibatch Loss= 0.0953, Training Accuracy= 0.958
2018-01-03 23:38:51,658 : INFO : Step 8, Validation Loss= 0.5104, Validation Accuracy= 0.867
2018-01-03 23:38:51,658 - root - INFO - Step 8, Validation Loss= 0.5104, Validation Accuracy= 0.867
2018-01-03 23:38:51,658 - root - INFO - Step 8, Validation Loss= 0.5104, Validation Accuracy= 0.867
2018-01-03 23:38:51,658 : INFO : starting fold 4 in 10-fold CV
2018-01-03 23:38:51,658 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:38:51,658 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:38:59,378 : INFO : Step 1, Minibatch Loss= 0.3802, Training Accuracy= 0.849
2018-01-03 23:38:59,378 - root - INFO - Step 1, Minibatch Loss= 0.3802, Training Accuracy= 0.849
2018-01-03 23:38:59,378 - root - INFO - Step 1, Minibatch Loss= 0.3802, Training Accuracy= 0.849
2018-01-03 23:38:59,442 : INFO : Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.834
2018-01-03 23:38:59,442 - root - INFO - Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.834
2018-01-03 23:38:59,442 - root - INFO - Step 1, Validation Loss= 0.4150, Validation Accuracy= 0.834
2018-01-03 23:39:01,490 : INFO : Step 2, Minibatch Loss= 0.2024, Training Accuracy= 0.916
2018-01-03 23:39:01,490 - root - INFO - Step 2, Minibatch Loss= 0.2024, Training Accuracy= 0.916
2018-01-03 23:39:01,490 - root - INFO - Step 2, Minibatch Loss= 0.2024, Training Accuracy= 0.916
2018-01-03 23:39:01,549 : INFO : Step 2, Validation Loss= 0.2790, Validation Accuracy= 0.880
2018-01-03 23:39:01,549 - root - INFO - Step 2, Validation Loss= 0.2790, Validation Accuracy= 0.880
2018-01-03 23:39:01,549 - root - INFO - Step 2, Validation Loss= 0.2790, Validation Accuracy= 0.880
2018-01-03 23:39:03,671 : INFO : Step 3, Minibatch Loss= 0.1489, Training Accuracy= 0.942
2018-01-03 23:39:03,671 - root - INFO - Step 3, Minibatch Loss= 0.1489, Training Accuracy= 0.942
2018-01-03 23:39:03,671 - root - INFO - Step 3, Minibatch Loss= 0.1489, Training Accuracy= 0.942
2018-01-03 23:39:03,758 : INFO : Step 3, Validation Loss= 0.1971, Validation Accuracy= 0.912
2018-01-03 23:39:03,758 - root - INFO - Step 3, Validation Loss= 0.1971, Validation Accuracy= 0.912
2018-01-03 23:39:03,758 - root - INFO - Step 3, Validation Loss= 0.1971, Validation Accuracy= 0.912
2018-01-03 23:39:05,844 : INFO : Step 4, Minibatch Loss= 0.1190, Training Accuracy= 0.952
2018-01-03 23:39:05,844 - root - INFO - Step 4, Minibatch Loss= 0.1190, Training Accuracy= 0.952
2018-01-03 23:39:05,844 - root - INFO - Step 4, Minibatch Loss= 0.1190, Training Accuracy= 0.952
2018-01-03 23:39:05,902 : INFO : Step 4, Validation Loss= 0.2181, Validation Accuracy= 0.910
2018-01-03 23:39:05,902 - root - INFO - Step 4, Validation Loss= 0.2181, Validation Accuracy= 0.910
2018-01-03 23:39:05,902 - root - INFO - Step 4, Validation Loss= 0.2181, Validation Accuracy= 0.910
2018-01-03 23:39:05,903 : INFO : starting fold 5 in 10-fold CV
2018-01-03 23:39:05,903 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:39:05,903 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:39:13,002 : INFO : Step 1, Minibatch Loss= 0.7578, Training Accuracy= 0.623
2018-01-03 23:39:13,002 - root - INFO - Step 1, Minibatch Loss= 0.7578, Training Accuracy= 0.623
2018-01-03 23:39:13,002 - root - INFO - Step 1, Minibatch Loss= 0.7578, Training Accuracy= 0.623
2018-01-03 23:39:13,069 : INFO : Step 1, Validation Loss= 0.6483, Validation Accuracy= 0.705
2018-01-03 23:39:13,069 - root - INFO - Step 1, Validation Loss= 0.6483, Validation Accuracy= 0.705
2018-01-03 23:39:13,069 - root - INFO - Step 1, Validation Loss= 0.6483, Validation Accuracy= 0.705
2018-01-03 23:39:15,239 : INFO : Step 2, Minibatch Loss= 0.3304, Training Accuracy= 0.872
2018-01-03 23:39:15,239 - root - INFO - Step 2, Minibatch Loss= 0.3304, Training Accuracy= 0.872
2018-01-03 23:39:15,239 - root - INFO - Step 2, Minibatch Loss= 0.3304, Training Accuracy= 0.872
2018-01-03 23:39:15,303 : INFO : Step 2, Validation Loss= 0.3119, Validation Accuracy= 0.882
2018-01-03 23:39:15,303 - root - INFO - Step 2, Validation Loss= 0.3119, Validation Accuracy= 0.882
2018-01-03 23:39:15,303 - root - INFO - Step 2, Validation Loss= 0.3119, Validation Accuracy= 0.882
2018-01-03 23:39:17,454 : INFO : Step 3, Minibatch Loss= 0.2626, Training Accuracy= 0.903
2018-01-03 23:39:17,454 - root - INFO - Step 3, Minibatch Loss= 0.2626, Training Accuracy= 0.903
2018-01-03 23:39:17,454 - root - INFO - Step 3, Minibatch Loss= 0.2626, Training Accuracy= 0.903
2018-01-03 23:39:17,516 : INFO : Step 3, Validation Loss= 0.4194, Validation Accuracy= 0.858
2018-01-03 23:39:17,516 - root - INFO - Step 3, Validation Loss= 0.4194, Validation Accuracy= 0.858
2018-01-03 23:39:17,516 - root - INFO - Step 3, Validation Loss= 0.4194, Validation Accuracy= 0.858
2018-01-03 23:39:17,517 : INFO : starting fold 6 in 10-fold CV
2018-01-03 23:39:17,517 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:39:17,517 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:39:24,693 : INFO : Step 1, Minibatch Loss= 0.6275, Training Accuracy= 0.680
2018-01-03 23:39:24,693 - root - INFO - Step 1, Minibatch Loss= 0.6275, Training Accuracy= 0.680
2018-01-03 23:39:24,693 - root - INFO - Step 1, Minibatch Loss= 0.6275, Training Accuracy= 0.680
2018-01-03 23:39:24,757 : INFO : Step 1, Validation Loss= 0.5585, Validation Accuracy= 0.718
2018-01-03 23:39:24,757 - root - INFO - Step 1, Validation Loss= 0.5585, Validation Accuracy= 0.718
2018-01-03 23:39:24,757 - root - INFO - Step 1, Validation Loss= 0.5585, Validation Accuracy= 0.718
2018-01-03 23:39:26,868 : INFO : Step 2, Minibatch Loss= 0.2997, Training Accuracy= 0.856
2018-01-03 23:39:26,868 - root - INFO - Step 2, Minibatch Loss= 0.2997, Training Accuracy= 0.856
2018-01-03 23:39:26,868 - root - INFO - Step 2, Minibatch Loss= 0.2997, Training Accuracy= 0.856
2018-01-03 23:39:26,931 : INFO : Step 2, Validation Loss= 0.3111, Validation Accuracy= 0.865
2018-01-03 23:39:26,931 - root - INFO - Step 2, Validation Loss= 0.3111, Validation Accuracy= 0.865
2018-01-03 23:39:26,931 - root - INFO - Step 2, Validation Loss= 0.3111, Validation Accuracy= 0.865
2018-01-03 23:39:29,089 : INFO : Step 3, Minibatch Loss= 0.2365, Training Accuracy= 0.894
2018-01-03 23:39:29,089 - root - INFO - Step 3, Minibatch Loss= 0.2365, Training Accuracy= 0.894
2018-01-03 23:39:29,089 - root - INFO - Step 3, Minibatch Loss= 0.2365, Training Accuracy= 0.894
2018-01-03 23:39:29,151 : INFO : Step 3, Validation Loss= 0.3286, Validation Accuracy= 0.875
2018-01-03 23:39:29,151 - root - INFO - Step 3, Validation Loss= 0.3286, Validation Accuracy= 0.875
2018-01-03 23:39:29,151 - root - INFO - Step 3, Validation Loss= 0.3286, Validation Accuracy= 0.875
2018-01-03 23:39:31,277 : INFO : Step 4, Minibatch Loss= 0.2049, Training Accuracy= 0.920
2018-01-03 23:39:31,277 - root - INFO - Step 4, Minibatch Loss= 0.2049, Training Accuracy= 0.920
2018-01-03 23:39:31,277 - root - INFO - Step 4, Minibatch Loss= 0.2049, Training Accuracy= 0.920
2018-01-03 23:39:31,339 : INFO : Step 4, Validation Loss= 0.3762, Validation Accuracy= 0.877
2018-01-03 23:39:31,339 - root - INFO - Step 4, Validation Loss= 0.3762, Validation Accuracy= 0.877
2018-01-03 23:39:31,339 - root - INFO - Step 4, Validation Loss= 0.3762, Validation Accuracy= 0.877
2018-01-03 23:39:33,477 : INFO : Step 5, Minibatch Loss= 0.1537, Training Accuracy= 0.933
2018-01-03 23:39:33,477 - root - INFO - Step 5, Minibatch Loss= 0.1537, Training Accuracy= 0.933
2018-01-03 23:39:33,477 - root - INFO - Step 5, Minibatch Loss= 0.1537, Training Accuracy= 0.933
2018-01-03 23:39:33,537 : INFO : Step 5, Validation Loss= 0.3448, Validation Accuracy= 0.882
2018-01-03 23:39:33,537 - root - INFO - Step 5, Validation Loss= 0.3448, Validation Accuracy= 0.882
2018-01-03 23:39:33,537 - root - INFO - Step 5, Validation Loss= 0.3448, Validation Accuracy= 0.882
2018-01-03 23:39:35,663 : INFO : Step 6, Minibatch Loss= 0.1444, Training Accuracy= 0.935
2018-01-03 23:39:35,663 - root - INFO - Step 6, Minibatch Loss= 0.1444, Training Accuracy= 0.935
2018-01-03 23:39:35,663 - root - INFO - Step 6, Minibatch Loss= 0.1444, Training Accuracy= 0.935
2018-01-03 23:39:35,724 : INFO : Step 6, Validation Loss= 0.3428, Validation Accuracy= 0.880
2018-01-03 23:39:35,724 - root - INFO - Step 6, Validation Loss= 0.3428, Validation Accuracy= 0.880
2018-01-03 23:39:35,724 - root - INFO - Step 6, Validation Loss= 0.3428, Validation Accuracy= 0.880
2018-01-03 23:39:35,724 : INFO : starting fold 7 in 10-fold CV
2018-01-03 23:39:35,724 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:39:35,724 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:39:42,818 : INFO : Step 1, Minibatch Loss= 0.5266, Training Accuracy= 0.725
2018-01-03 23:39:42,818 - root - INFO - Step 1, Minibatch Loss= 0.5266, Training Accuracy= 0.725
2018-01-03 23:39:42,818 - root - INFO - Step 1, Minibatch Loss= 0.5266, Training Accuracy= 0.725
2018-01-03 23:39:42,886 : INFO : Step 1, Validation Loss= 0.6525, Validation Accuracy= 0.598
2018-01-03 23:39:42,886 - root - INFO - Step 1, Validation Loss= 0.6525, Validation Accuracy= 0.598
2018-01-03 23:39:42,886 - root - INFO - Step 1, Validation Loss= 0.6525, Validation Accuracy= 0.598
2018-01-03 23:39:45,028 : INFO : Step 2, Minibatch Loss= 0.2612, Training Accuracy= 0.894
2018-01-03 23:39:45,028 - root - INFO - Step 2, Minibatch Loss= 0.2612, Training Accuracy= 0.894
2018-01-03 23:39:45,028 - root - INFO - Step 2, Minibatch Loss= 0.2612, Training Accuracy= 0.894
2018-01-03 23:39:45,093 : INFO : Step 2, Validation Loss= 0.4116, Validation Accuracy= 0.761
2018-01-03 23:39:45,093 - root - INFO - Step 2, Validation Loss= 0.4116, Validation Accuracy= 0.761
2018-01-03 23:39:45,093 - root - INFO - Step 2, Validation Loss= 0.4116, Validation Accuracy= 0.761
2018-01-03 23:39:47,165 : INFO : Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.915
2018-01-03 23:39:47,165 - root - INFO - Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.915
2018-01-03 23:39:47,165 - root - INFO - Step 3, Minibatch Loss= 0.1892, Training Accuracy= 0.915
2018-01-03 23:39:47,228 : INFO : Step 3, Validation Loss= 0.4303, Validation Accuracy= 0.783
2018-01-03 23:39:47,228 - root - INFO - Step 3, Validation Loss= 0.4303, Validation Accuracy= 0.783
2018-01-03 23:39:47,228 - root - INFO - Step 3, Validation Loss= 0.4303, Validation Accuracy= 0.783
2018-01-03 23:39:49,390 : INFO : Step 4, Minibatch Loss= 0.1487, Training Accuracy= 0.933
2018-01-03 23:39:49,390 - root - INFO - Step 4, Minibatch Loss= 0.1487, Training Accuracy= 0.933
2018-01-03 23:39:49,390 - root - INFO - Step 4, Minibatch Loss= 0.1487, Training Accuracy= 0.933
2018-01-03 23:39:49,454 : INFO : Step 4, Validation Loss= 0.3203, Validation Accuracy= 0.834
2018-01-03 23:39:49,454 - root - INFO - Step 4, Validation Loss= 0.3203, Validation Accuracy= 0.834
2018-01-03 23:39:49,454 - root - INFO - Step 4, Validation Loss= 0.3203, Validation Accuracy= 0.834
2018-01-03 23:39:51,595 : INFO : Step 5, Minibatch Loss= 0.1289, Training Accuracy= 0.941
2018-01-03 23:39:51,595 - root - INFO - Step 5, Minibatch Loss= 0.1289, Training Accuracy= 0.941
2018-01-03 23:39:51,595 - root - INFO - Step 5, Minibatch Loss= 0.1289, Training Accuracy= 0.941
2018-01-03 23:39:51,658 : INFO : Step 5, Validation Loss= 0.3201, Validation Accuracy= 0.837
2018-01-03 23:39:51,658 - root - INFO - Step 5, Validation Loss= 0.3201, Validation Accuracy= 0.837
2018-01-03 23:39:51,658 - root - INFO - Step 5, Validation Loss= 0.3201, Validation Accuracy= 0.837
2018-01-03 23:39:53,790 : INFO : Step 6, Minibatch Loss= 0.1153, Training Accuracy= 0.947
2018-01-03 23:39:53,790 - root - INFO - Step 6, Minibatch Loss= 0.1153, Training Accuracy= 0.947
2018-01-03 23:39:53,790 - root - INFO - Step 6, Minibatch Loss= 0.1153, Training Accuracy= 0.947
2018-01-03 23:39:53,851 : INFO : Step 6, Validation Loss= 0.3148, Validation Accuracy= 0.845
2018-01-03 23:39:53,851 - root - INFO - Step 6, Validation Loss= 0.3148, Validation Accuracy= 0.845
2018-01-03 23:39:53,851 - root - INFO - Step 6, Validation Loss= 0.3148, Validation Accuracy= 0.845
2018-01-03 23:39:55,988 : INFO : Step 7, Minibatch Loss= 0.1099, Training Accuracy= 0.947
2018-01-03 23:39:55,988 - root - INFO - Step 7, Minibatch Loss= 0.1099, Training Accuracy= 0.947
2018-01-03 23:39:55,988 - root - INFO - Step 7, Minibatch Loss= 0.1099, Training Accuracy= 0.947
2018-01-03 23:39:56,051 : INFO : Step 7, Validation Loss= 0.3747, Validation Accuracy= 0.822
2018-01-03 23:39:56,051 - root - INFO - Step 7, Validation Loss= 0.3747, Validation Accuracy= 0.822
2018-01-03 23:39:56,051 - root - INFO - Step 7, Validation Loss= 0.3747, Validation Accuracy= 0.822
2018-01-03 23:39:56,051 : INFO : starting fold 8 in 10-fold CV
2018-01-03 23:39:56,051 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:39:56,051 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:40:03,551 : INFO : Step 1, Minibatch Loss= 0.6365, Training Accuracy= 0.678
2018-01-03 23:40:03,551 - root - INFO - Step 1, Minibatch Loss= 0.6365, Training Accuracy= 0.678
2018-01-03 23:40:03,551 - root - INFO - Step 1, Minibatch Loss= 0.6365, Training Accuracy= 0.678
2018-01-03 23:40:03,628 : INFO : Step 1, Validation Loss= 0.8017, Validation Accuracy= 0.591
2018-01-03 23:40:03,628 - root - INFO - Step 1, Validation Loss= 0.8017, Validation Accuracy= 0.591
2018-01-03 23:40:03,628 - root - INFO - Step 1, Validation Loss= 0.8017, Validation Accuracy= 0.591
2018-01-03 23:40:05,949 : INFO : Step 2, Minibatch Loss= 0.3084, Training Accuracy= 0.874
2018-01-03 23:40:05,949 - root - INFO - Step 2, Minibatch Loss= 0.3084, Training Accuracy= 0.874
2018-01-03 23:40:05,949 - root - INFO - Step 2, Minibatch Loss= 0.3084, Training Accuracy= 0.874
2018-01-03 23:40:06,023 : INFO : Step 2, Validation Loss= 0.4771, Validation Accuracy= 0.789
2018-01-03 23:40:06,023 - root - INFO - Step 2, Validation Loss= 0.4771, Validation Accuracy= 0.789
2018-01-03 23:40:06,023 - root - INFO - Step 2, Validation Loss= 0.4771, Validation Accuracy= 0.789
2018-01-03 23:40:08,224 : INFO : Step 3, Minibatch Loss= 0.2300, Training Accuracy= 0.906
2018-01-03 23:40:08,224 - root - INFO - Step 3, Minibatch Loss= 0.2300, Training Accuracy= 0.906
2018-01-03 23:40:08,224 - root - INFO - Step 3, Minibatch Loss= 0.2300, Training Accuracy= 0.906
2018-01-03 23:40:08,286 : INFO : Step 3, Validation Loss= 0.4278, Validation Accuracy= 0.817
2018-01-03 23:40:08,286 - root - INFO - Step 3, Validation Loss= 0.4278, Validation Accuracy= 0.817
2018-01-03 23:40:08,286 - root - INFO - Step 3, Validation Loss= 0.4278, Validation Accuracy= 0.817
2018-01-03 23:40:58,172 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:40:58,172 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:40:58,172 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 23:40:58,172 : INFO : collecting all words and their counts
2018-01-03 23:40:58,172 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:40:58,172 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 23:40:58,173 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:40:58,173 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:40:58,173 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 23:40:58,201 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:40:58,201 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:40:58,201 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 23:40:58,201 : INFO : Loading a fresh vocabulary
2018-01-03 23:40:58,201 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:40:58,201 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 23:40:58,216 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:40:58,216 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:40:58,216 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 23:40:58,216 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:40:58,216 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:40:58,216 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 23:40:58,234 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 23:40:58,234 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:40:58,234 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 23:40:58,235 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 23:40:58,235 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:40:58,235 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 23:40:58,236 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:40:58,236 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:40:58,236 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 23:40:58,237 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:40:58,237 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:40:58,237 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 23:40:58,252 : INFO : resetting layer weights
2018-01-03 23:40:58,252 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:40:58,252 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 23:40:58,324 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:58,324 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:58,324 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:58,777 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:58,777 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:58,777 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:58,782 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:58,782 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:58,782 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:58,783 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:58,783 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:58,783 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:58,783 : INFO : training on 797984 raw words (558678 effective words) took 0.5s, 1229052 effective words/s
2018-01-03 23:40:58,783 - gensim.models.word2vec - INFO - training on 797984 raw words (558678 effective words) took 0.5s, 1229052 effective words/s
2018-01-03 23:40:58,783 - gensim.models.word2vec - INFO - training on 797984 raw words (558678 effective words) took 0.5s, 1229052 effective words/s
2018-01-03 23:40:58,784 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:58,784 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:58,784 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 23:40:59,234 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:59,234 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:59,234 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 23:40:59,239 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:59,239 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:59,239 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 23:40:59,240 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:59,240 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:59,240 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 23:40:59,241 : INFO : training on 797984 raw words (559175 effective words) took 0.5s, 1234883 effective words/s
2018-01-03 23:40:59,241 - gensim.models.word2vec - INFO - training on 797984 raw words (559175 effective words) took 0.5s, 1234883 effective words/s
2018-01-03 23:40:59,241 - gensim.models.word2vec - INFO - training on 797984 raw words (559175 effective words) took 0.5s, 1234883 effective words/s
2018-01-03 23:41:18,631 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:41:18,631 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:41:18,631 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:41:18,632 : INFO : starting fold 1 in 10-fold CV
2018-01-03 23:41:18,632 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:41:18,632 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:41:26,167 : INFO : Step 1, Minibatch Loss= 0.5429, Training Accuracy= 0.747
2018-01-03 23:41:26,167 - root - INFO - Step 1, Minibatch Loss= 0.5429, Training Accuracy= 0.747
2018-01-03 23:41:26,167 - root - INFO - Step 1, Minibatch Loss= 0.5429, Training Accuracy= 0.747
2018-01-03 23:41:26,223 : INFO : Step 1, Validation Loss= 0.6126, Validation Accuracy= 0.766
2018-01-03 23:41:26,223 - root - INFO - Step 1, Validation Loss= 0.6126, Validation Accuracy= 0.766
2018-01-03 23:41:26,223 - root - INFO - Step 1, Validation Loss= 0.6126, Validation Accuracy= 0.766
2018-01-03 23:41:28,096 : INFO : Step 2, Minibatch Loss= 0.2966, Training Accuracy= 0.871
2018-01-03 23:41:28,096 - root - INFO - Step 2, Minibatch Loss= 0.2966, Training Accuracy= 0.871
2018-01-03 23:41:28,096 - root - INFO - Step 2, Minibatch Loss= 0.2966, Training Accuracy= 0.871
2018-01-03 23:41:28,148 : INFO : Step 2, Validation Loss= 0.3311, Validation Accuracy= 0.957
2018-01-03 23:41:28,148 - root - INFO - Step 2, Validation Loss= 0.3311, Validation Accuracy= 0.957
2018-01-03 23:41:28,148 - root - INFO - Step 2, Validation Loss= 0.3311, Validation Accuracy= 0.957
2018-01-03 23:41:30,069 : INFO : Step 3, Minibatch Loss= 0.2331, Training Accuracy= 0.898
2018-01-03 23:41:30,069 - root - INFO - Step 3, Minibatch Loss= 0.2331, Training Accuracy= 0.898
2018-01-03 23:41:30,069 - root - INFO - Step 3, Minibatch Loss= 0.2331, Training Accuracy= 0.898
2018-01-03 23:41:30,123 : INFO : Step 3, Validation Loss= 0.2771, Validation Accuracy= 0.955
2018-01-03 23:41:30,123 - root - INFO - Step 3, Validation Loss= 0.2771, Validation Accuracy= 0.955
2018-01-03 23:41:30,123 - root - INFO - Step 3, Validation Loss= 0.2771, Validation Accuracy= 0.955
2018-01-03 23:41:30,123 : INFO : starting fold 2 in 10-fold CV
2018-01-03 23:41:30,123 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:41:30,123 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:41:37,411 : INFO : Step 1, Minibatch Loss= 0.5609, Training Accuracy= 0.715
2018-01-03 23:41:37,411 - root - INFO - Step 1, Minibatch Loss= 0.5609, Training Accuracy= 0.715
2018-01-03 23:41:37,411 - root - INFO - Step 1, Minibatch Loss= 0.5609, Training Accuracy= 0.715
2018-01-03 23:41:37,462 : INFO : Step 1, Validation Loss= 0.4755, Validation Accuracy= 0.847
2018-01-03 23:41:37,462 - root - INFO - Step 1, Validation Loss= 0.4755, Validation Accuracy= 0.847
2018-01-03 23:41:37,462 - root - INFO - Step 1, Validation Loss= 0.4755, Validation Accuracy= 0.847
2018-01-03 23:41:39,305 : INFO : Step 2, Minibatch Loss= 0.3404, Training Accuracy= 0.842
2018-01-03 23:41:39,305 - root - INFO - Step 2, Minibatch Loss= 0.3404, Training Accuracy= 0.842
2018-01-03 23:41:39,305 - root - INFO - Step 2, Minibatch Loss= 0.3404, Training Accuracy= 0.842
2018-01-03 23:41:39,357 : INFO : Step 2, Validation Loss= 0.3627, Validation Accuracy= 0.938
2018-01-03 23:41:39,357 - root - INFO - Step 2, Validation Loss= 0.3627, Validation Accuracy= 0.938
2018-01-03 23:41:39,357 - root - INFO - Step 2, Validation Loss= 0.3627, Validation Accuracy= 0.938
2018-01-03 23:41:41,181 : INFO : Step 3, Minibatch Loss= 0.2324, Training Accuracy= 0.876
2018-01-03 23:41:41,181 - root - INFO - Step 3, Minibatch Loss= 0.2324, Training Accuracy= 0.876
2018-01-03 23:41:41,181 - root - INFO - Step 3, Minibatch Loss= 0.2324, Training Accuracy= 0.876
2018-01-03 23:41:41,238 : INFO : Step 3, Validation Loss= 0.3049, Validation Accuracy= 0.944
2018-01-03 23:41:41,238 - root - INFO - Step 3, Validation Loss= 0.3049, Validation Accuracy= 0.944
2018-01-03 23:41:41,238 - root - INFO - Step 3, Validation Loss= 0.3049, Validation Accuracy= 0.944
2018-01-03 23:41:43,198 : INFO : Step 4, Minibatch Loss= 0.1896, Training Accuracy= 0.891
2018-01-03 23:41:43,198 - root - INFO - Step 4, Minibatch Loss= 0.1896, Training Accuracy= 0.891
2018-01-03 23:41:43,198 - root - INFO - Step 4, Minibatch Loss= 0.1896, Training Accuracy= 0.891
2018-01-03 23:41:43,257 : INFO : Step 4, Validation Loss= 0.3736, Validation Accuracy= 0.942
2018-01-03 23:41:43,257 - root - INFO - Step 4, Validation Loss= 0.3736, Validation Accuracy= 0.942
2018-01-03 23:41:43,257 - root - INFO - Step 4, Validation Loss= 0.3736, Validation Accuracy= 0.942
2018-01-03 23:41:43,257 : INFO : starting fold 3 in 10-fold CV
2018-01-03 23:41:43,257 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:41:43,257 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:41:50,059 : INFO : Step 1, Minibatch Loss= 0.4651, Training Accuracy= 0.807
2018-01-03 23:41:50,059 - root - INFO - Step 1, Minibatch Loss= 0.4651, Training Accuracy= 0.807
2018-01-03 23:41:50,059 - root - INFO - Step 1, Minibatch Loss= 0.4651, Training Accuracy= 0.807
2018-01-03 23:41:50,119 : INFO : Step 1, Validation Loss= 0.4348, Validation Accuracy= 0.845
2018-01-03 23:41:50,119 - root - INFO - Step 1, Validation Loss= 0.4348, Validation Accuracy= 0.845
2018-01-03 23:41:50,119 - root - INFO - Step 1, Validation Loss= 0.4348, Validation Accuracy= 0.845
2018-01-03 23:41:51,992 : INFO : Step 2, Minibatch Loss= 0.2484, Training Accuracy= 0.870
2018-01-03 23:41:51,992 - root - INFO - Step 2, Minibatch Loss= 0.2484, Training Accuracy= 0.870
2018-01-03 23:41:51,992 - root - INFO - Step 2, Minibatch Loss= 0.2484, Training Accuracy= 0.870
2018-01-03 23:41:52,046 : INFO : Step 2, Validation Loss= 0.3048, Validation Accuracy= 0.895
2018-01-03 23:41:52,046 - root - INFO - Step 2, Validation Loss= 0.3048, Validation Accuracy= 0.895
2018-01-03 23:41:52,046 - root - INFO - Step 2, Validation Loss= 0.3048, Validation Accuracy= 0.895
2018-01-03 23:41:53,981 : INFO : Step 3, Minibatch Loss= 0.1887, Training Accuracy= 0.897
2018-01-03 23:41:53,981 - root - INFO - Step 3, Minibatch Loss= 0.1887, Training Accuracy= 0.897
2018-01-03 23:41:53,981 - root - INFO - Step 3, Minibatch Loss= 0.1887, Training Accuracy= 0.897
2018-01-03 23:41:54,038 : INFO : Step 3, Validation Loss= 0.2676, Validation Accuracy= 0.880
2018-01-03 23:41:54,038 - root - INFO - Step 3, Validation Loss= 0.2676, Validation Accuracy= 0.880
2018-01-03 23:41:54,038 - root - INFO - Step 3, Validation Loss= 0.2676, Validation Accuracy= 0.880
2018-01-03 23:41:54,039 : INFO : starting fold 4 in 10-fold CV
2018-01-03 23:41:54,039 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:41:54,039 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:42:01,888 : INFO : Step 1, Minibatch Loss= 0.5061, Training Accuracy= 0.767
2018-01-03 23:42:01,888 - root - INFO - Step 1, Minibatch Loss= 0.5061, Training Accuracy= 0.767
2018-01-03 23:42:01,888 - root - INFO - Step 1, Minibatch Loss= 0.5061, Training Accuracy= 0.767
2018-01-03 23:42:01,941 : INFO : Step 1, Validation Loss= 0.5228, Validation Accuracy= 0.744
2018-01-03 23:42:01,941 - root - INFO - Step 1, Validation Loss= 0.5228, Validation Accuracy= 0.744
2018-01-03 23:42:01,941 - root - INFO - Step 1, Validation Loss= 0.5228, Validation Accuracy= 0.744
2018-01-03 23:42:03,823 : INFO : Step 2, Minibatch Loss= 0.2796, Training Accuracy= 0.860
2018-01-03 23:42:03,823 - root - INFO - Step 2, Minibatch Loss= 0.2796, Training Accuracy= 0.860
2018-01-03 23:42:03,823 - root - INFO - Step 2, Minibatch Loss= 0.2796, Training Accuracy= 0.860
2018-01-03 23:42:03,873 : INFO : Step 2, Validation Loss= 0.2891, Validation Accuracy= 0.858
2018-01-03 23:42:03,873 - root - INFO - Step 2, Validation Loss= 0.2891, Validation Accuracy= 0.858
2018-01-03 23:42:03,873 - root - INFO - Step 2, Validation Loss= 0.2891, Validation Accuracy= 0.858
2018-01-03 23:42:05,700 : INFO : Step 3, Minibatch Loss= 0.2229, Training Accuracy= 0.899
2018-01-03 23:42:05,700 - root - INFO - Step 3, Minibatch Loss= 0.2229, Training Accuracy= 0.899
2018-01-03 23:42:05,700 - root - INFO - Step 3, Minibatch Loss= 0.2229, Training Accuracy= 0.899
2018-01-03 23:42:05,749 : INFO : Step 3, Validation Loss= 0.3321, Validation Accuracy= 0.880
2018-01-03 23:42:05,749 - root - INFO - Step 3, Validation Loss= 0.3321, Validation Accuracy= 0.880
2018-01-03 23:42:05,749 - root - INFO - Step 3, Validation Loss= 0.3321, Validation Accuracy= 0.880
2018-01-03 23:42:07,691 : INFO : Step 4, Minibatch Loss= 0.1809, Training Accuracy= 0.909
2018-01-03 23:42:07,691 - root - INFO - Step 4, Minibatch Loss= 0.1809, Training Accuracy= 0.909
2018-01-03 23:42:07,691 - root - INFO - Step 4, Minibatch Loss= 0.1809, Training Accuracy= 0.909
2018-01-03 23:42:07,742 : INFO : Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.897
2018-01-03 23:42:07,742 - root - INFO - Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.897
2018-01-03 23:42:07,742 - root - INFO - Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.897
2018-01-03 23:42:09,632 : INFO : Step 5, Minibatch Loss= 0.1594, Training Accuracy= 0.916
2018-01-03 23:42:09,632 - root - INFO - Step 5, Minibatch Loss= 0.1594, Training Accuracy= 0.916
2018-01-03 23:42:09,632 - root - INFO - Step 5, Minibatch Loss= 0.1594, Training Accuracy= 0.916
2018-01-03 23:42:09,693 : INFO : Step 5, Validation Loss= 0.2448, Validation Accuracy= 0.903
2018-01-03 23:42:09,693 - root - INFO - Step 5, Validation Loss= 0.2448, Validation Accuracy= 0.903
2018-01-03 23:42:09,693 - root - INFO - Step 5, Validation Loss= 0.2448, Validation Accuracy= 0.903
2018-01-03 23:42:11,682 : INFO : Step 6, Minibatch Loss= 0.1383, Training Accuracy= 0.922
2018-01-03 23:42:11,682 - root - INFO - Step 6, Minibatch Loss= 0.1383, Training Accuracy= 0.922
2018-01-03 23:42:11,682 - root - INFO - Step 6, Minibatch Loss= 0.1383, Training Accuracy= 0.922
2018-01-03 23:42:11,734 : INFO : Step 6, Validation Loss= 0.2655, Validation Accuracy= 0.862
2018-01-03 23:42:11,734 - root - INFO - Step 6, Validation Loss= 0.2655, Validation Accuracy= 0.862
2018-01-03 23:42:11,734 - root - INFO - Step 6, Validation Loss= 0.2655, Validation Accuracy= 0.862
2018-01-03 23:42:11,734 : INFO : starting fold 5 in 10-fold CV
2018-01-03 23:42:11,734 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:42:11,734 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:42:18,580 : INFO : Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.724
2018-01-03 23:42:18,580 - root - INFO - Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.724
2018-01-03 23:42:18,580 - root - INFO - Step 1, Minibatch Loss= 0.5514, Training Accuracy= 0.724
2018-01-03 23:42:18,636 : INFO : Step 1, Validation Loss= 0.5370, Validation Accuracy= 0.776
2018-01-03 23:42:18,636 - root - INFO - Step 1, Validation Loss= 0.5370, Validation Accuracy= 0.776
2018-01-03 23:42:18,636 - root - INFO - Step 1, Validation Loss= 0.5370, Validation Accuracy= 0.776
2018-01-03 23:42:20,507 : INFO : Step 2, Minibatch Loss= 0.2865, Training Accuracy= 0.873
2018-01-03 23:42:20,507 - root - INFO - Step 2, Minibatch Loss= 0.2865, Training Accuracy= 0.873
2018-01-03 23:42:20,507 - root - INFO - Step 2, Minibatch Loss= 0.2865, Training Accuracy= 0.873
2018-01-03 23:42:20,559 : INFO : Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.877
2018-01-03 23:42:20,559 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.877
2018-01-03 23:42:20,559 - root - INFO - Step 2, Validation Loss= 0.3338, Validation Accuracy= 0.877
2018-01-03 23:42:22,390 : INFO : Step 3, Minibatch Loss= 0.2004, Training Accuracy= 0.907
2018-01-03 23:42:22,390 - root - INFO - Step 3, Minibatch Loss= 0.2004, Training Accuracy= 0.907
2018-01-03 23:42:22,390 - root - INFO - Step 3, Minibatch Loss= 0.2004, Training Accuracy= 0.907
2018-01-03 23:42:22,443 : INFO : Step 3, Validation Loss= 0.3110, Validation Accuracy= 0.880
2018-01-03 23:42:22,443 - root - INFO - Step 3, Validation Loss= 0.3110, Validation Accuracy= 0.880
2018-01-03 23:42:22,443 - root - INFO - Step 3, Validation Loss= 0.3110, Validation Accuracy= 0.880
2018-01-03 23:42:24,273 : INFO : Step 4, Minibatch Loss= 0.1521, Training Accuracy= 0.921
2018-01-03 23:42:24,273 - root - INFO - Step 4, Minibatch Loss= 0.1521, Training Accuracy= 0.921
2018-01-03 23:42:24,273 - root - INFO - Step 4, Minibatch Loss= 0.1521, Training Accuracy= 0.921
2018-01-03 23:42:24,332 : INFO : Step 4, Validation Loss= 0.4231, Validation Accuracy= 0.873
2018-01-03 23:42:24,332 - root - INFO - Step 4, Validation Loss= 0.4231, Validation Accuracy= 0.873
2018-01-03 23:42:24,332 - root - INFO - Step 4, Validation Loss= 0.4231, Validation Accuracy= 0.873
2018-01-03 23:42:24,332 : INFO : starting fold 6 in 10-fold CV
2018-01-03 23:42:24,332 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:42:24,332 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:42:31,577 : INFO : Step 1, Minibatch Loss= 0.5855, Training Accuracy= 0.690
2018-01-03 23:42:31,577 - root - INFO - Step 1, Minibatch Loss= 0.5855, Training Accuracy= 0.690
2018-01-03 23:42:31,577 - root - INFO - Step 1, Minibatch Loss= 0.5855, Training Accuracy= 0.690
2018-01-03 23:42:31,634 : INFO : Step 1, Validation Loss= 0.5381, Validation Accuracy= 0.774
2018-01-03 23:42:31,634 - root - INFO - Step 1, Validation Loss= 0.5381, Validation Accuracy= 0.774
2018-01-03 23:42:31,634 - root - INFO - Step 1, Validation Loss= 0.5381, Validation Accuracy= 0.774
2018-01-03 23:42:33,487 : INFO : Step 2, Minibatch Loss= 0.3267, Training Accuracy= 0.843
2018-01-03 23:42:33,487 - root - INFO - Step 2, Minibatch Loss= 0.3267, Training Accuracy= 0.843
2018-01-03 23:42:33,487 - root - INFO - Step 2, Minibatch Loss= 0.3267, Training Accuracy= 0.843
2018-01-03 23:42:33,539 : INFO : Step 2, Validation Loss= 0.3754, Validation Accuracy= 0.824
2018-01-03 23:42:33,539 - root - INFO - Step 2, Validation Loss= 0.3754, Validation Accuracy= 0.824
2018-01-03 23:42:33,539 - root - INFO - Step 2, Validation Loss= 0.3754, Validation Accuracy= 0.824
2018-01-03 23:42:35,408 : INFO : Step 3, Minibatch Loss= 0.2345, Training Accuracy= 0.892
2018-01-03 23:42:35,408 - root - INFO - Step 3, Minibatch Loss= 0.2345, Training Accuracy= 0.892
2018-01-03 23:42:35,408 - root - INFO - Step 3, Minibatch Loss= 0.2345, Training Accuracy= 0.892
2018-01-03 23:42:35,459 : INFO : Step 3, Validation Loss= 0.3542, Validation Accuracy= 0.888
2018-01-03 23:42:35,459 - root - INFO - Step 3, Validation Loss= 0.3542, Validation Accuracy= 0.888
2018-01-03 23:42:35,459 - root - INFO - Step 3, Validation Loss= 0.3542, Validation Accuracy= 0.888
2018-01-03 23:42:37,296 : INFO : Step 4, Minibatch Loss= 0.1870, Training Accuracy= 0.908
2018-01-03 23:42:37,296 - root - INFO - Step 4, Minibatch Loss= 0.1870, Training Accuracy= 0.908
2018-01-03 23:42:37,296 - root - INFO - Step 4, Minibatch Loss= 0.1870, Training Accuracy= 0.908
2018-01-03 23:42:37,346 : INFO : Step 4, Validation Loss= 0.2832, Validation Accuracy= 0.888
2018-01-03 23:42:37,346 - root - INFO - Step 4, Validation Loss= 0.2832, Validation Accuracy= 0.888
2018-01-03 23:42:37,346 - root - INFO - Step 4, Validation Loss= 0.2832, Validation Accuracy= 0.888
2018-01-03 23:42:39,206 : INFO : Step 5, Minibatch Loss= 0.1731, Training Accuracy= 0.914
2018-01-03 23:42:39,206 - root - INFO - Step 5, Minibatch Loss= 0.1731, Training Accuracy= 0.914
2018-01-03 23:42:39,206 - root - INFO - Step 5, Minibatch Loss= 0.1731, Training Accuracy= 0.914
2018-01-03 23:42:39,259 : INFO : Step 5, Validation Loss= 0.2975, Validation Accuracy= 0.882
2018-01-03 23:42:39,259 - root - INFO - Step 5, Validation Loss= 0.2975, Validation Accuracy= 0.882
2018-01-03 23:42:39,259 - root - INFO - Step 5, Validation Loss= 0.2975, Validation Accuracy= 0.882
2018-01-03 23:42:39,260 : INFO : starting fold 7 in 10-fold CV
2018-01-03 23:42:39,260 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:42:39,260 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:42:45,950 : INFO : Step 1, Minibatch Loss= 0.6029, Training Accuracy= 0.678
2018-01-03 23:42:45,950 - root - INFO - Step 1, Minibatch Loss= 0.6029, Training Accuracy= 0.678
2018-01-03 23:42:45,950 - root - INFO - Step 1, Minibatch Loss= 0.6029, Training Accuracy= 0.678
2018-01-03 23:42:46,011 : INFO : Step 1, Validation Loss= 0.7870, Validation Accuracy= 0.514
2018-01-03 23:42:46,011 - root - INFO - Step 1, Validation Loss= 0.7870, Validation Accuracy= 0.514
2018-01-03 23:42:46,011 - root - INFO - Step 1, Validation Loss= 0.7870, Validation Accuracy= 0.514
2018-01-03 23:42:47,874 : INFO : Step 2, Minibatch Loss= 0.3284, Training Accuracy= 0.848
2018-01-03 23:42:47,874 - root - INFO - Step 2, Minibatch Loss= 0.3284, Training Accuracy= 0.848
2018-01-03 23:42:47,874 - root - INFO - Step 2, Minibatch Loss= 0.3284, Training Accuracy= 0.848
2018-01-03 23:42:47,927 : INFO : Step 2, Validation Loss= 0.5464, Validation Accuracy= 0.716
2018-01-03 23:42:47,927 - root - INFO - Step 2, Validation Loss= 0.5464, Validation Accuracy= 0.716
2018-01-03 23:42:47,927 - root - INFO - Step 2, Validation Loss= 0.5464, Validation Accuracy= 0.716
2018-01-03 23:42:49,750 : INFO : Step 3, Minibatch Loss= 0.2675, Training Accuracy= 0.887
2018-01-03 23:42:49,750 - root - INFO - Step 3, Minibatch Loss= 0.2675, Training Accuracy= 0.887
2018-01-03 23:42:49,750 - root - INFO - Step 3, Minibatch Loss= 0.2675, Training Accuracy= 0.887
2018-01-03 23:42:49,802 : INFO : Step 3, Validation Loss= 0.5063, Validation Accuracy= 0.729
2018-01-03 23:42:49,802 - root - INFO - Step 3, Validation Loss= 0.5063, Validation Accuracy= 0.729
2018-01-03 23:42:49,802 - root - INFO - Step 3, Validation Loss= 0.5063, Validation Accuracy= 0.729
2018-01-03 23:42:51,753 : INFO : Step 4, Minibatch Loss= 0.2176, Training Accuracy= 0.900
2018-01-03 23:42:51,753 - root - INFO - Step 4, Minibatch Loss= 0.2176, Training Accuracy= 0.900
2018-01-03 23:42:51,753 - root - INFO - Step 4, Minibatch Loss= 0.2176, Training Accuracy= 0.900
2018-01-03 23:42:51,806 : INFO : Step 4, Validation Loss= 0.4070, Validation Accuracy= 0.785
2018-01-03 23:42:51,806 - root - INFO - Step 4, Validation Loss= 0.4070, Validation Accuracy= 0.785
2018-01-03 23:42:51,806 - root - INFO - Step 4, Validation Loss= 0.4070, Validation Accuracy= 0.785
2018-01-03 23:42:53,749 : INFO : Step 5, Minibatch Loss= 0.1894, Training Accuracy= 0.915
2018-01-03 23:42:53,749 - root - INFO - Step 5, Minibatch Loss= 0.1894, Training Accuracy= 0.915
2018-01-03 23:42:53,749 - root - INFO - Step 5, Minibatch Loss= 0.1894, Training Accuracy= 0.915
2018-01-03 23:42:53,810 : INFO : Step 5, Validation Loss= 0.4612, Validation Accuracy= 0.804
2018-01-03 23:42:53,810 - root - INFO - Step 5, Validation Loss= 0.4612, Validation Accuracy= 0.804
2018-01-03 23:42:53,810 - root - INFO - Step 5, Validation Loss= 0.4612, Validation Accuracy= 0.804
2018-01-03 23:42:55,791 : INFO : Step 6, Minibatch Loss= 0.1801, Training Accuracy= 0.912
2018-01-03 23:42:55,791 - root - INFO - Step 6, Minibatch Loss= 0.1801, Training Accuracy= 0.912
2018-01-03 23:42:55,791 - root - INFO - Step 6, Minibatch Loss= 0.1801, Training Accuracy= 0.912
2018-01-03 23:42:55,844 : INFO : Step 6, Validation Loss= 0.3698, Validation Accuracy= 0.806
2018-01-03 23:42:55,844 - root - INFO - Step 6, Validation Loss= 0.3698, Validation Accuracy= 0.806
2018-01-03 23:42:55,844 - root - INFO - Step 6, Validation Loss= 0.3698, Validation Accuracy= 0.806
2018-01-03 23:42:57,784 : INFO : Step 7, Minibatch Loss= 0.1622, Training Accuracy= 0.915
2018-01-03 23:42:57,784 - root - INFO - Step 7, Minibatch Loss= 0.1622, Training Accuracy= 0.915
2018-01-03 23:42:57,784 - root - INFO - Step 7, Minibatch Loss= 0.1622, Training Accuracy= 0.915
2018-01-03 23:42:57,837 : INFO : Step 7, Validation Loss= 0.3779, Validation Accuracy= 0.822
2018-01-03 23:42:57,837 - root - INFO - Step 7, Validation Loss= 0.3779, Validation Accuracy= 0.822
2018-01-03 23:42:57,837 - root - INFO - Step 7, Validation Loss= 0.3779, Validation Accuracy= 0.822
2018-01-03 23:42:59,781 : INFO : Step 8, Minibatch Loss= 0.1534, Training Accuracy= 0.923
2018-01-03 23:42:59,781 - root - INFO - Step 8, Minibatch Loss= 0.1534, Training Accuracy= 0.923
2018-01-03 23:42:59,781 - root - INFO - Step 8, Minibatch Loss= 0.1534, Training Accuracy= 0.923
2018-01-03 23:42:59,855 : INFO : Step 8, Validation Loss= 0.4112, Validation Accuracy= 0.819
2018-01-03 23:42:59,855 - root - INFO - Step 8, Validation Loss= 0.4112, Validation Accuracy= 0.819
2018-01-03 23:42:59,855 - root - INFO - Step 8, Validation Loss= 0.4112, Validation Accuracy= 0.819
2018-01-03 23:42:59,856 : INFO : starting fold 8 in 10-fold CV
2018-01-03 23:42:59,856 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:42:59,856 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:43:07,441 : INFO : Step 1, Minibatch Loss= 0.5048, Training Accuracy= 0.797
2018-01-03 23:43:07,441 - root - INFO - Step 1, Minibatch Loss= 0.5048, Training Accuracy= 0.797
2018-01-03 23:43:07,441 - root - INFO - Step 1, Minibatch Loss= 0.5048, Training Accuracy= 0.797
2018-01-03 23:43:07,501 : INFO : Step 1, Validation Loss= 0.5433, Validation Accuracy= 0.733
2018-01-03 23:43:07,501 - root - INFO - Step 1, Validation Loss= 0.5433, Validation Accuracy= 0.733
2018-01-03 23:43:07,501 - root - INFO - Step 1, Validation Loss= 0.5433, Validation Accuracy= 0.733
2018-01-03 23:43:09,323 : INFO : Step 2, Minibatch Loss= 0.2508, Training Accuracy= 0.896
2018-01-03 23:43:09,323 - root - INFO - Step 2, Minibatch Loss= 0.2508, Training Accuracy= 0.896
2018-01-03 23:43:09,323 - root - INFO - Step 2, Minibatch Loss= 0.2508, Training Accuracy= 0.896
2018-01-03 23:43:09,375 : INFO : Step 2, Validation Loss= 0.3074, Validation Accuracy= 0.824
2018-01-03 23:43:09,375 - root - INFO - Step 2, Validation Loss= 0.3074, Validation Accuracy= 0.824
2018-01-03 23:43:09,375 - root - INFO - Step 2, Validation Loss= 0.3074, Validation Accuracy= 0.824
2018-01-03 23:43:11,196 : INFO : Step 3, Minibatch Loss= 0.1875, Training Accuracy= 0.919
2018-01-03 23:43:11,196 - root - INFO - Step 3, Minibatch Loss= 0.1875, Training Accuracy= 0.919
2018-01-03 23:43:11,196 - root - INFO - Step 3, Minibatch Loss= 0.1875, Training Accuracy= 0.919
2018-01-03 23:43:11,250 : INFO : Step 3, Validation Loss= 0.3149, Validation Accuracy= 0.839
2018-01-03 23:43:11,250 - root - INFO - Step 3, Validation Loss= 0.3149, Validation Accuracy= 0.839
2018-01-03 23:43:11,250 - root - INFO - Step 3, Validation Loss= 0.3149, Validation Accuracy= 0.839
2018-01-03 23:43:13,073 : INFO : Step 4, Minibatch Loss= 0.1686, Training Accuracy= 0.919
2018-01-03 23:43:13,073 - root - INFO - Step 4, Minibatch Loss= 0.1686, Training Accuracy= 0.919
2018-01-03 23:43:13,073 - root - INFO - Step 4, Minibatch Loss= 0.1686, Training Accuracy= 0.919
2018-01-03 23:43:13,130 : INFO : Step 4, Validation Loss= 0.3491, Validation Accuracy= 0.837
2018-01-03 23:43:13,130 - root - INFO - Step 4, Validation Loss= 0.3491, Validation Accuracy= 0.837
2018-01-03 23:43:13,130 - root - INFO - Step 4, Validation Loss= 0.3491, Validation Accuracy= 0.837
2018-01-03 23:43:13,130 : INFO : starting fold 9 in 10-fold CV
2018-01-03 23:43:13,130 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:43:13,130 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:43:19,804 : INFO : Step 1, Minibatch Loss= 0.6345, Training Accuracy= 0.643
2018-01-03 23:43:19,804 - root - INFO - Step 1, Minibatch Loss= 0.6345, Training Accuracy= 0.643
2018-01-03 23:43:19,804 - root - INFO - Step 1, Minibatch Loss= 0.6345, Training Accuracy= 0.643
2018-01-03 23:43:19,860 : INFO : Step 1, Validation Loss= 0.5642, Validation Accuracy= 0.723
2018-01-03 23:43:19,860 - root - INFO - Step 1, Validation Loss= 0.5642, Validation Accuracy= 0.723
2018-01-03 23:43:19,860 - root - INFO - Step 1, Validation Loss= 0.5642, Validation Accuracy= 0.723
2018-01-03 23:43:21,694 : INFO : Step 2, Minibatch Loss= 0.3271, Training Accuracy= 0.838
2018-01-03 23:43:21,694 - root - INFO - Step 2, Minibatch Loss= 0.3271, Training Accuracy= 0.838
2018-01-03 23:43:21,694 - root - INFO - Step 2, Minibatch Loss= 0.3271, Training Accuracy= 0.838
2018-01-03 23:43:21,742 : INFO : Step 2, Validation Loss= 0.3903, Validation Accuracy= 0.849
2018-01-03 23:43:21,742 - root - INFO - Step 2, Validation Loss= 0.3903, Validation Accuracy= 0.849
2018-01-03 23:43:21,742 - root - INFO - Step 2, Validation Loss= 0.3903, Validation Accuracy= 0.849
2018-01-03 23:43:23,580 : INFO : Step 3, Minibatch Loss= 0.2513, Training Accuracy= 0.890
2018-01-03 23:43:23,580 - root - INFO - Step 3, Minibatch Loss= 0.2513, Training Accuracy= 0.890
2018-01-03 23:43:23,580 - root - INFO - Step 3, Minibatch Loss= 0.2513, Training Accuracy= 0.890
2018-01-03 23:43:23,629 : INFO : Step 3, Validation Loss= 0.3888, Validation Accuracy= 0.869
2018-01-03 23:43:23,629 - root - INFO - Step 3, Validation Loss= 0.3888, Validation Accuracy= 0.869
2018-01-03 23:43:23,629 - root - INFO - Step 3, Validation Loss= 0.3888, Validation Accuracy= 0.869
2018-01-03 23:43:25,530 : INFO : Step 4, Minibatch Loss= 0.2046, Training Accuracy= 0.906
2018-01-03 23:43:25,530 - root - INFO - Step 4, Minibatch Loss= 0.2046, Training Accuracy= 0.906
2018-01-03 23:43:25,530 - root - INFO - Step 4, Minibatch Loss= 0.2046, Training Accuracy= 0.906
2018-01-03 23:43:25,579 : INFO : Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.905
2018-01-03 23:43:25,579 - root - INFO - Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.905
2018-01-03 23:43:25,579 - root - INFO - Step 4, Validation Loss= 0.3207, Validation Accuracy= 0.905
2018-01-03 23:43:27,427 : INFO : Step 5, Minibatch Loss= 0.2077, Training Accuracy= 0.907
2018-01-03 23:43:27,427 - root - INFO - Step 5, Minibatch Loss= 0.2077, Training Accuracy= 0.907
2018-01-03 23:43:27,427 - root - INFO - Step 5, Minibatch Loss= 0.2077, Training Accuracy= 0.907
2018-01-03 23:43:27,486 : INFO : Step 5, Validation Loss= 0.3996, Validation Accuracy= 0.869
2018-01-03 23:43:27,486 - root - INFO - Step 5, Validation Loss= 0.3996, Validation Accuracy= 0.869
2018-01-03 23:43:27,486 - root - INFO - Step 5, Validation Loss= 0.3996, Validation Accuracy= 0.869
2018-01-03 23:43:27,486 : INFO : starting fold 10 in 10-fold CV
2018-01-03 23:43:27,486 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:43:27,486 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:43:36,553 : INFO : Step 1, Minibatch Loss= 0.5989, Training Accuracy= 0.670
2018-01-03 23:43:36,553 - root - INFO - Step 1, Minibatch Loss= 0.5989, Training Accuracy= 0.670
2018-01-03 23:43:36,553 - root - INFO - Step 1, Minibatch Loss= 0.5989, Training Accuracy= 0.670
2018-01-03 23:43:36,625 : INFO : Step 1, Validation Loss= 0.6743, Validation Accuracy= 0.497
2018-01-03 23:43:36,625 - root - INFO - Step 1, Validation Loss= 0.6743, Validation Accuracy= 0.497
2018-01-03 23:43:36,625 - root - INFO - Step 1, Validation Loss= 0.6743, Validation Accuracy= 0.497
2018-01-03 23:43:38,529 : INFO : Step 2, Minibatch Loss= 0.3556, Training Accuracy= 0.851
2018-01-03 23:43:38,529 - root - INFO - Step 2, Minibatch Loss= 0.3556, Training Accuracy= 0.851
2018-01-03 23:43:38,529 - root - INFO - Step 2, Minibatch Loss= 0.3556, Training Accuracy= 0.851
2018-01-03 23:43:38,583 : INFO : Step 2, Validation Loss= 0.3621, Validation Accuracy= 0.804
2018-01-03 23:43:38,583 - root - INFO - Step 2, Validation Loss= 0.3621, Validation Accuracy= 0.804
2018-01-03 23:43:38,583 - root - INFO - Step 2, Validation Loss= 0.3621, Validation Accuracy= 0.804
2018-01-03 23:43:40,447 : INFO : Step 3, Minibatch Loss= 0.2126, Training Accuracy= 0.903
2018-01-03 23:43:40,447 - root - INFO - Step 3, Minibatch Loss= 0.2126, Training Accuracy= 0.903
2018-01-03 23:43:40,447 - root - INFO - Step 3, Minibatch Loss= 0.2126, Training Accuracy= 0.903
2018-01-03 23:43:40,500 : INFO : Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.811
2018-01-03 23:43:40,500 - root - INFO - Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.811
2018-01-03 23:43:40,500 - root - INFO - Step 3, Validation Loss= 0.3623, Validation Accuracy= 0.811
2018-01-03 23:43:42,421 : INFO : Step 4, Minibatch Loss= 0.1763, Training Accuracy= 0.912
2018-01-03 23:43:42,421 - root - INFO - Step 4, Minibatch Loss= 0.1763, Training Accuracy= 0.912
2018-01-03 23:43:42,421 - root - INFO - Step 4, Minibatch Loss= 0.1763, Training Accuracy= 0.912
2018-01-03 23:43:42,474 : INFO : Step 4, Validation Loss= 0.3537, Validation Accuracy= 0.837
2018-01-03 23:43:42,474 - root - INFO - Step 4, Validation Loss= 0.3537, Validation Accuracy= 0.837
2018-01-03 23:43:42,474 - root - INFO - Step 4, Validation Loss= 0.3537, Validation Accuracy= 0.837
2018-01-03 23:43:44,371 : INFO : Step 5, Minibatch Loss= 0.1598, Training Accuracy= 0.920
2018-01-03 23:43:44,371 - root - INFO - Step 5, Minibatch Loss= 0.1598, Training Accuracy= 0.920
2018-01-03 23:43:44,371 - root - INFO - Step 5, Minibatch Loss= 0.1598, Training Accuracy= 0.920
2018-01-03 23:43:44,431 : INFO : Step 5, Validation Loss= 0.3231, Validation Accuracy= 0.828
2018-01-03 23:43:44,431 - root - INFO - Step 5, Validation Loss= 0.3231, Validation Accuracy= 0.828
2018-01-03 23:43:44,431 - root - INFO - Step 5, Validation Loss= 0.3231, Validation Accuracy= 0.828
2018-01-03 23:43:44,432 : INFO : Average accuracy is 0.886882 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:43:44,432 - root - INFO - Average accuracy is 0.886882 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:43:44,432 - root - INFO - Average accuracy is 0.886882 for training_steps=10, batch_size=93, embed_size=50, num_hidden=20, dropout=0.1
2018-01-03 23:43:44,432 : INFO : This 10-fold CV run-time: 145.8008508682251 seconds
2018-01-03 23:43:44,432 - root - INFO - This 10-fold CV run-time: 145.8008508682251 seconds
2018-01-03 23:43:44,432 - root - INFO - This 10-fold CV run-time: 145.8008508682251 seconds
2018-01-03 23:43:44,584 : INFO : current best: accuracy=0.886882, num_hidden=20, dropout=0.1
2018-01-03 23:43:44,584 - root - INFO - current best: accuracy=0.886882, num_hidden=20, dropout=0.1
2018-01-03 23:43:44,584 - root - INFO - current best: accuracy=0.886882, num_hidden=20, dropout=0.1
2018-01-03 23:44:00,049 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:44:00,049 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:44:00,049 - root - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:44:00,050 : INFO : starting fold 1 in 10-fold CV
2018-01-03 23:44:00,050 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:44:00,050 - root - INFO - starting fold 1 in 10-fold CV
2018-01-03 23:44:08,624 : INFO : Step 1, Minibatch Loss= 0.5335, Training Accuracy= 0.746
2018-01-03 23:44:08,624 - root - INFO - Step 1, Minibatch Loss= 0.5335, Training Accuracy= 0.746
2018-01-03 23:44:08,624 - root - INFO - Step 1, Minibatch Loss= 0.5335, Training Accuracy= 0.746
2018-01-03 23:44:08,694 : INFO : Step 1, Validation Loss= 0.6190, Validation Accuracy= 0.729
2018-01-03 23:44:08,694 - root - INFO - Step 1, Validation Loss= 0.6190, Validation Accuracy= 0.729
2018-01-03 23:44:08,694 - root - INFO - Step 1, Validation Loss= 0.6190, Validation Accuracy= 0.729
2018-01-03 23:44:10,727 : INFO : Step 2, Minibatch Loss= 0.2628, Training Accuracy= 0.883
2018-01-03 23:44:10,727 - root - INFO - Step 2, Minibatch Loss= 0.2628, Training Accuracy= 0.883
2018-01-03 23:44:10,727 - root - INFO - Step 2, Minibatch Loss= 0.2628, Training Accuracy= 0.883
2018-01-03 23:44:10,785 : INFO : Step 2, Validation Loss= 0.3063, Validation Accuracy= 0.942
2018-01-03 23:44:10,785 - root - INFO - Step 2, Validation Loss= 0.3063, Validation Accuracy= 0.942
2018-01-03 23:44:10,785 - root - INFO - Step 2, Validation Loss= 0.3063, Validation Accuracy= 0.942
2018-01-03 23:44:12,932 : INFO : Step 3, Minibatch Loss= 0.1719, Training Accuracy= 0.932
2018-01-03 23:44:12,932 - root - INFO - Step 3, Minibatch Loss= 0.1719, Training Accuracy= 0.932
2018-01-03 23:44:12,932 - root - INFO - Step 3, Minibatch Loss= 0.1719, Training Accuracy= 0.932
2018-01-03 23:44:12,996 : INFO : Step 3, Validation Loss= 0.3861, Validation Accuracy= 0.920
2018-01-03 23:44:12,996 - root - INFO - Step 3, Validation Loss= 0.3861, Validation Accuracy= 0.920
2018-01-03 23:44:12,996 - root - INFO - Step 3, Validation Loss= 0.3861, Validation Accuracy= 0.920
2018-01-03 23:44:12,996 : INFO : starting fold 2 in 10-fold CV
2018-01-03 23:44:12,996 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:44:12,996 - root - INFO - starting fold 2 in 10-fold CV
2018-01-03 23:44:20,277 : INFO : Step 1, Minibatch Loss= 0.4173, Training Accuracy= 0.830
2018-01-03 23:44:20,277 - root - INFO - Step 1, Minibatch Loss= 0.4173, Training Accuracy= 0.830
2018-01-03 23:44:20,277 - root - INFO - Step 1, Minibatch Loss= 0.4173, Training Accuracy= 0.830
2018-01-03 23:44:20,342 : INFO : Step 1, Validation Loss= 0.4786, Validation Accuracy= 0.727
2018-01-03 23:44:20,342 - root - INFO - Step 1, Validation Loss= 0.4786, Validation Accuracy= 0.727
2018-01-03 23:44:20,342 - root - INFO - Step 1, Validation Loss= 0.4786, Validation Accuracy= 0.727
2018-01-03 23:44:22,740 : INFO : Step 2, Minibatch Loss= 0.2096, Training Accuracy= 0.918
2018-01-03 23:44:22,740 - root - INFO - Step 2, Minibatch Loss= 0.2096, Training Accuracy= 0.918
2018-01-03 23:44:22,740 - root - INFO - Step 2, Minibatch Loss= 0.2096, Training Accuracy= 0.918
2018-01-03 23:44:22,801 : INFO : Step 2, Validation Loss= 0.2252, Validation Accuracy= 0.854
2018-01-03 23:44:22,801 - root - INFO - Step 2, Validation Loss= 0.2252, Validation Accuracy= 0.854
2018-01-03 23:44:22,801 - root - INFO - Step 2, Validation Loss= 0.2252, Validation Accuracy= 0.854
2018-01-03 23:44:25,093 : INFO : Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.932
2018-01-03 23:44:25,093 - root - INFO - Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.932
2018-01-03 23:44:25,093 - root - INFO - Step 3, Minibatch Loss= 0.1641, Training Accuracy= 0.932
2018-01-03 23:44:25,154 : INFO : Step 3, Validation Loss= 0.3800, Validation Accuracy= 0.809
2018-01-03 23:44:25,154 - root - INFO - Step 3, Validation Loss= 0.3800, Validation Accuracy= 0.809
2018-01-03 23:44:25,154 - root - INFO - Step 3, Validation Loss= 0.3800, Validation Accuracy= 0.809
2018-01-03 23:44:25,154 : INFO : starting fold 3 in 10-fold CV
2018-01-03 23:44:25,154 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:44:25,154 - root - INFO - starting fold 3 in 10-fold CV
2018-01-03 23:44:33,150 : INFO : Step 1, Minibatch Loss= 0.4876, Training Accuracy= 0.774
2018-01-03 23:44:33,150 - root - INFO - Step 1, Minibatch Loss= 0.4876, Training Accuracy= 0.774
2018-01-03 23:44:33,150 - root - INFO - Step 1, Minibatch Loss= 0.4876, Training Accuracy= 0.774
2018-01-03 23:44:33,215 : INFO : Step 1, Validation Loss= 0.5144, Validation Accuracy= 0.725
2018-01-03 23:44:33,215 - root - INFO - Step 1, Validation Loss= 0.5144, Validation Accuracy= 0.725
2018-01-03 23:44:33,215 - root - INFO - Step 1, Validation Loss= 0.5144, Validation Accuracy= 0.725
2018-01-03 23:44:35,447 : INFO : Step 2, Minibatch Loss= 0.2320, Training Accuracy= 0.900
2018-01-03 23:44:35,447 - root - INFO - Step 2, Minibatch Loss= 0.2320, Training Accuracy= 0.900
2018-01-03 23:44:35,447 - root - INFO - Step 2, Minibatch Loss= 0.2320, Training Accuracy= 0.900
2018-01-03 23:44:35,502 : INFO : Step 2, Validation Loss= 0.3151, Validation Accuracy= 0.841
2018-01-03 23:44:35,502 - root - INFO - Step 2, Validation Loss= 0.3151, Validation Accuracy= 0.841
2018-01-03 23:44:35,502 - root - INFO - Step 2, Validation Loss= 0.3151, Validation Accuracy= 0.841
2018-01-03 23:44:37,717 : INFO : Step 3, Minibatch Loss= 0.1947, Training Accuracy= 0.926
2018-01-03 23:44:37,717 - root - INFO - Step 3, Minibatch Loss= 0.1947, Training Accuracy= 0.926
2018-01-03 23:44:37,717 - root - INFO - Step 3, Minibatch Loss= 0.1947, Training Accuracy= 0.926
2018-01-03 23:44:37,780 : INFO : Step 3, Validation Loss= 0.2933, Validation Accuracy= 0.884
2018-01-03 23:44:37,780 - root - INFO - Step 3, Validation Loss= 0.2933, Validation Accuracy= 0.884
2018-01-03 23:44:37,780 - root - INFO - Step 3, Validation Loss= 0.2933, Validation Accuracy= 0.884
2018-01-03 23:44:39,962 : INFO : Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.941
2018-01-03 23:44:39,962 - root - INFO - Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.941
2018-01-03 23:44:39,962 - root - INFO - Step 4, Minibatch Loss= 0.1385, Training Accuracy= 0.941
2018-01-03 23:44:40,025 : INFO : Step 4, Validation Loss= 0.3081, Validation Accuracy= 0.854
2018-01-03 23:44:40,025 - root - INFO - Step 4, Validation Loss= 0.3081, Validation Accuracy= 0.854
2018-01-03 23:44:40,025 - root - INFO - Step 4, Validation Loss= 0.3081, Validation Accuracy= 0.854
2018-01-03 23:44:40,026 : INFO : starting fold 4 in 10-fold CV
2018-01-03 23:44:40,026 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:44:40,026 - root - INFO - starting fold 4 in 10-fold CV
2018-01-03 23:44:47,469 : INFO : Step 1, Minibatch Loss= 0.4842, Training Accuracy= 0.792
2018-01-03 23:44:47,469 - root - INFO - Step 1, Minibatch Loss= 0.4842, Training Accuracy= 0.792
2018-01-03 23:44:47,469 - root - INFO - Step 1, Minibatch Loss= 0.4842, Training Accuracy= 0.792
2018-01-03 23:44:47,532 : INFO : Step 1, Validation Loss= 0.4928, Validation Accuracy= 0.778
2018-01-03 23:44:47,532 - root - INFO - Step 1, Validation Loss= 0.4928, Validation Accuracy= 0.778
2018-01-03 23:44:47,532 - root - INFO - Step 1, Validation Loss= 0.4928, Validation Accuracy= 0.778
2018-01-03 23:44:49,666 : INFO : Step 2, Minibatch Loss= 0.2265, Training Accuracy= 0.896
2018-01-03 23:44:49,666 - root - INFO - Step 2, Minibatch Loss= 0.2265, Training Accuracy= 0.896
2018-01-03 23:44:49,666 - root - INFO - Step 2, Minibatch Loss= 0.2265, Training Accuracy= 0.896
2018-01-03 23:44:49,725 : INFO : Step 2, Validation Loss= 0.2687, Validation Accuracy= 0.882
2018-01-03 23:44:49,725 - root - INFO - Step 2, Validation Loss= 0.2687, Validation Accuracy= 0.882
2018-01-03 23:44:49,725 - root - INFO - Step 2, Validation Loss= 0.2687, Validation Accuracy= 0.882
2018-01-03 23:44:51,763 : INFO : Step 3, Minibatch Loss= 0.1774, Training Accuracy= 0.926
2018-01-03 23:44:51,763 - root - INFO - Step 3, Minibatch Loss= 0.1774, Training Accuracy= 0.926
2018-01-03 23:44:51,763 - root - INFO - Step 3, Minibatch Loss= 0.1774, Training Accuracy= 0.926
2018-01-03 23:44:51,820 : INFO : Step 3, Validation Loss= 0.2314, Validation Accuracy= 0.892
2018-01-03 23:44:51,820 - root - INFO - Step 3, Validation Loss= 0.2314, Validation Accuracy= 0.892
2018-01-03 23:44:51,820 - root - INFO - Step 3, Validation Loss= 0.2314, Validation Accuracy= 0.892
2018-01-03 23:44:53,892 : INFO : Step 4, Minibatch Loss= 0.1244, Training Accuracy= 0.943
2018-01-03 23:44:53,892 - root - INFO - Step 4, Minibatch Loss= 0.1244, Training Accuracy= 0.943
2018-01-03 23:44:53,892 - root - INFO - Step 4, Minibatch Loss= 0.1244, Training Accuracy= 0.943
2018-01-03 23:44:53,953 : INFO : Step 4, Validation Loss= 0.2699, Validation Accuracy= 0.897
2018-01-03 23:44:53,953 - root - INFO - Step 4, Validation Loss= 0.2699, Validation Accuracy= 0.897
2018-01-03 23:44:53,953 - root - INFO - Step 4, Validation Loss= 0.2699, Validation Accuracy= 0.897
2018-01-03 23:44:56,073 : INFO : Step 5, Minibatch Loss= 0.1160, Training Accuracy= 0.945
2018-01-03 23:44:56,073 - root - INFO - Step 5, Minibatch Loss= 0.1160, Training Accuracy= 0.945
2018-01-03 23:44:56,073 - root - INFO - Step 5, Minibatch Loss= 0.1160, Training Accuracy= 0.945
2018-01-03 23:44:56,151 : INFO : Step 5, Validation Loss= 0.2047, Validation Accuracy= 0.931
2018-01-03 23:44:56,151 - root - INFO - Step 5, Validation Loss= 0.2047, Validation Accuracy= 0.931
2018-01-03 23:44:56,151 - root - INFO - Step 5, Validation Loss= 0.2047, Validation Accuracy= 0.931
2018-01-03 23:44:58,279 : INFO : Step 6, Minibatch Loss= 0.1029, Training Accuracy= 0.951
2018-01-03 23:44:58,279 - root - INFO - Step 6, Minibatch Loss= 0.1029, Training Accuracy= 0.951
2018-01-03 23:44:58,279 - root - INFO - Step 6, Minibatch Loss= 0.1029, Training Accuracy= 0.951
2018-01-03 23:44:58,333 : INFO : Step 6, Validation Loss= 0.1907, Validation Accuracy= 0.910
2018-01-03 23:44:58,333 - root - INFO - Step 6, Validation Loss= 0.1907, Validation Accuracy= 0.910
2018-01-03 23:44:58,333 - root - INFO - Step 6, Validation Loss= 0.1907, Validation Accuracy= 0.910
2018-01-03 23:44:58,333 : INFO : starting fold 5 in 10-fold CV
2018-01-03 23:44:58,333 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:44:58,333 - root - INFO - starting fold 5 in 10-fold CV
2018-01-03 23:45:05,879 : INFO : Step 1, Minibatch Loss= 0.4401, Training Accuracy= 0.833
2018-01-03 23:45:05,879 - root - INFO - Step 1, Minibatch Loss= 0.4401, Training Accuracy= 0.833
2018-01-03 23:45:05,879 - root - INFO - Step 1, Minibatch Loss= 0.4401, Training Accuracy= 0.833
2018-01-03 23:45:05,948 : INFO : Step 1, Validation Loss= 0.4884, Validation Accuracy= 0.822
2018-01-03 23:45:05,948 - root - INFO - Step 1, Validation Loss= 0.4884, Validation Accuracy= 0.822
2018-01-03 23:45:05,948 - root - INFO - Step 1, Validation Loss= 0.4884, Validation Accuracy= 0.822
2018-01-03 23:45:08,062 : INFO : Step 2, Minibatch Loss= 0.2124, Training Accuracy= 0.922
2018-01-03 23:45:08,062 - root - INFO - Step 2, Minibatch Loss= 0.2124, Training Accuracy= 0.922
2018-01-03 23:45:08,062 - root - INFO - Step 2, Minibatch Loss= 0.2124, Training Accuracy= 0.922
2018-01-03 23:45:08,121 : INFO : Step 2, Validation Loss= 0.2836, Validation Accuracy= 0.882
2018-01-03 23:45:08,121 - root - INFO - Step 2, Validation Loss= 0.2836, Validation Accuracy= 0.882
2018-01-03 23:45:08,121 - root - INFO - Step 2, Validation Loss= 0.2836, Validation Accuracy= 0.882
2018-01-03 23:45:10,146 : INFO : Step 3, Minibatch Loss= 0.1403, Training Accuracy= 0.934
2018-01-03 23:45:10,146 - root - INFO - Step 3, Minibatch Loss= 0.1403, Training Accuracy= 0.934
2018-01-03 23:45:10,146 - root - INFO - Step 3, Minibatch Loss= 0.1403, Training Accuracy= 0.934
2018-01-03 23:45:10,208 : INFO : Step 3, Validation Loss= 0.4230, Validation Accuracy= 0.892
2018-01-03 23:45:10,208 - root - INFO - Step 3, Validation Loss= 0.4230, Validation Accuracy= 0.892
2018-01-03 23:45:10,208 - root - INFO - Step 3, Validation Loss= 0.4230, Validation Accuracy= 0.892
2018-01-03 23:45:12,384 : INFO : Step 4, Minibatch Loss= 0.1161, Training Accuracy= 0.948
2018-01-03 23:45:12,384 - root - INFO - Step 4, Minibatch Loss= 0.1161, Training Accuracy= 0.948
2018-01-03 23:45:12,384 - root - INFO - Step 4, Minibatch Loss= 0.1161, Training Accuracy= 0.948
2018-01-03 23:45:12,451 : INFO : Step 4, Validation Loss= 0.3395, Validation Accuracy= 0.860
2018-01-03 23:45:12,451 - root - INFO - Step 4, Validation Loss= 0.3395, Validation Accuracy= 0.860
2018-01-03 23:45:12,451 - root - INFO - Step 4, Validation Loss= 0.3395, Validation Accuracy= 0.860
2018-01-03 23:45:12,451 : INFO : starting fold 6 in 10-fold CV
2018-01-03 23:45:12,451 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:45:12,451 - root - INFO - starting fold 6 in 10-fold CV
2018-01-03 23:45:19,413 : INFO : Step 1, Minibatch Loss= 0.5017, Training Accuracy= 0.792
2018-01-03 23:45:19,413 - root - INFO - Step 1, Minibatch Loss= 0.5017, Training Accuracy= 0.792
2018-01-03 23:45:19,413 - root - INFO - Step 1, Minibatch Loss= 0.5017, Training Accuracy= 0.792
2018-01-03 23:45:19,477 : INFO : Step 1, Validation Loss= 0.5348, Validation Accuracy= 0.740
2018-01-03 23:45:19,477 - root - INFO - Step 1, Validation Loss= 0.5348, Validation Accuracy= 0.740
2018-01-03 23:45:19,477 - root - INFO - Step 1, Validation Loss= 0.5348, Validation Accuracy= 0.740
2018-01-03 23:45:21,638 : INFO : Step 2, Minibatch Loss= 0.2257, Training Accuracy= 0.904
2018-01-03 23:45:21,638 - root - INFO - Step 2, Minibatch Loss= 0.2257, Training Accuracy= 0.904
2018-01-03 23:45:21,638 - root - INFO - Step 2, Minibatch Loss= 0.2257, Training Accuracy= 0.904
2018-01-03 23:45:21,698 : INFO : Step 2, Validation Loss= 0.2928, Validation Accuracy= 0.845
2018-01-03 23:45:21,698 - root - INFO - Step 2, Validation Loss= 0.2928, Validation Accuracy= 0.845
2018-01-03 23:45:21,698 - root - INFO - Step 2, Validation Loss= 0.2928, Validation Accuracy= 0.845
2018-01-03 23:45:23,881 : INFO : Step 3, Minibatch Loss= 0.1570, Training Accuracy= 0.938
2018-01-03 23:45:23,881 - root - INFO - Step 3, Minibatch Loss= 0.1570, Training Accuracy= 0.938
2018-01-03 23:45:23,881 - root - INFO - Step 3, Minibatch Loss= 0.1570, Training Accuracy= 0.938
2018-01-03 23:45:23,940 : INFO : Step 3, Validation Loss= 0.2583, Validation Accuracy= 0.875
2018-01-03 23:45:23,940 - root - INFO - Step 3, Validation Loss= 0.2583, Validation Accuracy= 0.875
2018-01-03 23:45:23,940 - root - INFO - Step 3, Validation Loss= 0.2583, Validation Accuracy= 0.875
2018-01-03 23:45:26,274 : INFO : Step 4, Minibatch Loss= 0.1112, Training Accuracy= 0.948
2018-01-03 23:45:26,274 - root - INFO - Step 4, Minibatch Loss= 0.1112, Training Accuracy= 0.948
2018-01-03 23:45:26,274 - root - INFO - Step 4, Minibatch Loss= 0.1112, Training Accuracy= 0.948
2018-01-03 23:45:26,336 : INFO : Step 4, Validation Loss= 0.2927, Validation Accuracy= 0.880
2018-01-03 23:45:26,336 - root - INFO - Step 4, Validation Loss= 0.2927, Validation Accuracy= 0.880
2018-01-03 23:45:26,336 - root - INFO - Step 4, Validation Loss= 0.2927, Validation Accuracy= 0.880
2018-01-03 23:45:28,518 : INFO : Step 5, Minibatch Loss= 0.0995, Training Accuracy= 0.955
2018-01-03 23:45:28,518 - root - INFO - Step 5, Minibatch Loss= 0.0995, Training Accuracy= 0.955
2018-01-03 23:45:28,518 - root - INFO - Step 5, Minibatch Loss= 0.0995, Training Accuracy= 0.955
2018-01-03 23:45:28,773 : INFO : Step 5, Validation Loss= 0.3183, Validation Accuracy= 0.923
2018-01-03 23:45:28,773 - root - INFO - Step 5, Validation Loss= 0.3183, Validation Accuracy= 0.923
2018-01-03 23:45:28,773 - root - INFO - Step 5, Validation Loss= 0.3183, Validation Accuracy= 0.923
2018-01-03 23:45:31,303 : INFO : Step 6, Minibatch Loss= 0.0887, Training Accuracy= 0.957
2018-01-03 23:45:31,303 - root - INFO - Step 6, Minibatch Loss= 0.0887, Training Accuracy= 0.957
2018-01-03 23:45:31,303 - root - INFO - Step 6, Minibatch Loss= 0.0887, Training Accuracy= 0.957
2018-01-03 23:45:31,371 : INFO : Step 6, Validation Loss= 0.2747, Validation Accuracy= 0.884
2018-01-03 23:45:31,371 - root - INFO - Step 6, Validation Loss= 0.2747, Validation Accuracy= 0.884
2018-01-03 23:45:31,371 - root - INFO - Step 6, Validation Loss= 0.2747, Validation Accuracy= 0.884
2018-01-03 23:45:31,371 : INFO : starting fold 7 in 10-fold CV
2018-01-03 23:45:31,371 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:45:31,371 - root - INFO - starting fold 7 in 10-fold CV
2018-01-03 23:45:39,988 : INFO : Step 1, Minibatch Loss= 0.6356, Training Accuracy= 0.649
2018-01-03 23:45:39,988 - root - INFO - Step 1, Minibatch Loss= 0.6356, Training Accuracy= 0.649
2018-01-03 23:45:39,988 - root - INFO - Step 1, Minibatch Loss= 0.6356, Training Accuracy= 0.649
2018-01-03 23:45:40,062 : INFO : Step 1, Validation Loss= 0.5524, Validation Accuracy= 0.735
2018-01-03 23:45:40,062 - root - INFO - Step 1, Validation Loss= 0.5524, Validation Accuracy= 0.735
2018-01-03 23:45:40,062 - root - INFO - Step 1, Validation Loss= 0.5524, Validation Accuracy= 0.735
2018-01-03 23:45:42,113 : INFO : Step 2, Minibatch Loss= 0.2744, Training Accuracy= 0.883
2018-01-03 23:45:42,113 - root - INFO - Step 2, Minibatch Loss= 0.2744, Training Accuracy= 0.883
2018-01-03 23:45:42,113 - root - INFO - Step 2, Minibatch Loss= 0.2744, Training Accuracy= 0.883
2018-01-03 23:45:42,174 : INFO : Step 2, Validation Loss= 0.4021, Validation Accuracy= 0.914
2018-01-03 23:45:42,174 - root - INFO - Step 2, Validation Loss= 0.4021, Validation Accuracy= 0.914
2018-01-03 23:45:42,174 - root - INFO - Step 2, Validation Loss= 0.4021, Validation Accuracy= 0.914
2018-01-03 23:45:44,278 : INFO : Step 3, Minibatch Loss= 0.1981, Training Accuracy= 0.921
2018-01-03 23:45:44,278 - root - INFO - Step 3, Minibatch Loss= 0.1981, Training Accuracy= 0.921
2018-01-03 23:45:44,278 - root - INFO - Step 3, Minibatch Loss= 0.1981, Training Accuracy= 0.921
2018-01-03 23:45:44,340 : INFO : Step 3, Validation Loss= 0.4512, Validation Accuracy= 0.888
2018-01-03 23:45:44,340 - root - INFO - Step 3, Validation Loss= 0.4512, Validation Accuracy= 0.888
2018-01-03 23:45:44,340 - root - INFO - Step 3, Validation Loss= 0.4512, Validation Accuracy= 0.888
2018-01-03 23:45:44,340 : INFO : starting fold 8 in 10-fold CV
2018-01-03 23:45:44,340 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:45:44,340 - root - INFO - starting fold 8 in 10-fold CV
2018-01-03 23:45:51,114 : INFO : Step 1, Minibatch Loss= 0.5848, Training Accuracy= 0.692
2018-01-03 23:45:51,114 - root - INFO - Step 1, Minibatch Loss= 0.5848, Training Accuracy= 0.692
2018-01-03 23:45:51,114 - root - INFO - Step 1, Minibatch Loss= 0.5848, Training Accuracy= 0.692
2018-01-03 23:45:51,180 : INFO : Step 1, Validation Loss= 0.5860, Validation Accuracy= 0.705
2018-01-03 23:45:51,180 - root - INFO - Step 1, Validation Loss= 0.5860, Validation Accuracy= 0.705
2018-01-03 23:45:51,180 - root - INFO - Step 1, Validation Loss= 0.5860, Validation Accuracy= 0.705
2018-01-03 23:45:53,250 : INFO : Step 2, Minibatch Loss= 0.2650, Training Accuracy= 0.879
2018-01-03 23:45:53,250 - root - INFO - Step 2, Minibatch Loss= 0.2650, Training Accuracy= 0.879
2018-01-03 23:45:53,250 - root - INFO - Step 2, Minibatch Loss= 0.2650, Training Accuracy= 0.879
2018-01-03 23:45:53,314 : INFO : Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.882
2018-01-03 23:45:53,314 - root - INFO - Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.882
2018-01-03 23:45:53,314 - root - INFO - Step 2, Validation Loss= 0.2839, Validation Accuracy= 0.882
2018-01-03 23:45:55,352 : INFO : Step 3, Minibatch Loss= 0.1763, Training Accuracy= 0.920
2018-01-03 23:45:55,352 - root - INFO - Step 3, Minibatch Loss= 0.1763, Training Accuracy= 0.920
2018-01-03 23:45:55,352 - root - INFO - Step 3, Minibatch Loss= 0.1763, Training Accuracy= 0.920
2018-01-03 23:45:55,414 : INFO : Step 3, Validation Loss= 0.3176, Validation Accuracy= 0.886
2018-01-03 23:45:55,414 - root - INFO - Step 3, Validation Loss= 0.3176, Validation Accuracy= 0.886
2018-01-03 23:45:55,414 - root - INFO - Step 3, Validation Loss= 0.3176, Validation Accuracy= 0.886
2018-01-03 23:45:57,425 : INFO : Step 4, Minibatch Loss= 0.1584, Training Accuracy= 0.928
2018-01-03 23:45:57,425 - root - INFO - Step 4, Minibatch Loss= 0.1584, Training Accuracy= 0.928
2018-01-03 23:45:57,425 - root - INFO - Step 4, Minibatch Loss= 0.1584, Training Accuracy= 0.928
2018-01-03 23:45:57,490 : INFO : Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 23:45:57,490 - root - INFO - Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 23:45:57,490 - root - INFO - Step 4, Validation Loss= 0.2350, Validation Accuracy= 0.912
2018-01-03 23:45:59,536 : INFO : Step 5, Minibatch Loss= 0.1251, Training Accuracy= 0.951
2018-01-03 23:45:59,536 - root - INFO - Step 5, Minibatch Loss= 0.1251, Training Accuracy= 0.951
2018-01-03 23:45:59,536 - root - INFO - Step 5, Minibatch Loss= 0.1251, Training Accuracy= 0.951
2018-01-03 23:45:59,598 : INFO : Step 5, Validation Loss= 0.4786, Validation Accuracy= 0.886
2018-01-03 23:45:59,598 - root - INFO - Step 5, Validation Loss= 0.4786, Validation Accuracy= 0.886
2018-01-03 23:45:59,598 - root - INFO - Step 5, Validation Loss= 0.4786, Validation Accuracy= 0.886
2018-01-03 23:45:59,598 : INFO : starting fold 9 in 10-fold CV
2018-01-03 23:45:59,598 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:45:59,598 - root - INFO - starting fold 9 in 10-fold CV
2018-01-03 23:46:07,180 : INFO : Step 1, Minibatch Loss= 0.7473, Training Accuracy= 0.641
2018-01-03 23:46:07,180 - root - INFO - Step 1, Minibatch Loss= 0.7473, Training Accuracy= 0.641
2018-01-03 23:46:07,180 - root - INFO - Step 1, Minibatch Loss= 0.7473, Training Accuracy= 0.641
2018-01-03 23:46:07,238 : INFO : Step 1, Validation Loss= 0.8866, Validation Accuracy= 0.551
2018-01-03 23:46:07,238 - root - INFO - Step 1, Validation Loss= 0.8866, Validation Accuracy= 0.551
2018-01-03 23:46:07,238 - root - INFO - Step 1, Validation Loss= 0.8866, Validation Accuracy= 0.551
2018-01-03 23:46:09,416 : INFO : Step 2, Minibatch Loss= 0.3933, Training Accuracy= 0.836
2018-01-03 23:46:09,416 - root - INFO - Step 2, Minibatch Loss= 0.3933, Training Accuracy= 0.836
2018-01-03 23:46:09,416 - root - INFO - Step 2, Minibatch Loss= 0.3933, Training Accuracy= 0.836
2018-01-03 23:46:09,473 : INFO : Step 2, Validation Loss= 0.6779, Validation Accuracy= 0.733
2018-01-03 23:46:09,473 - root - INFO - Step 2, Validation Loss= 0.6779, Validation Accuracy= 0.733
2018-01-03 23:46:09,473 - root - INFO - Step 2, Validation Loss= 0.6779, Validation Accuracy= 0.733
2018-01-03 23:46:11,536 : INFO : Step 3, Minibatch Loss= 0.2882, Training Accuracy= 0.891
2018-01-03 23:46:11,536 - root - INFO - Step 3, Minibatch Loss= 0.2882, Training Accuracy= 0.891
2018-01-03 23:46:11,536 - root - INFO - Step 3, Minibatch Loss= 0.2882, Training Accuracy= 0.891
2018-01-03 23:46:11,595 : INFO : Step 3, Validation Loss= 0.5417, Validation Accuracy= 0.796
2018-01-03 23:46:11,595 - root - INFO - Step 3, Validation Loss= 0.5417, Validation Accuracy= 0.796
2018-01-03 23:46:11,595 - root - INFO - Step 3, Validation Loss= 0.5417, Validation Accuracy= 0.796
2018-01-03 23:46:13,707 : INFO : Step 4, Minibatch Loss= 0.2126, Training Accuracy= 0.921
2018-01-03 23:46:13,707 - root - INFO - Step 4, Minibatch Loss= 0.2126, Training Accuracy= 0.921
2018-01-03 23:46:13,707 - root - INFO - Step 4, Minibatch Loss= 0.2126, Training Accuracy= 0.921
2018-01-03 23:46:13,773 : INFO : Step 4, Validation Loss= 0.5597, Validation Accuracy= 0.819
2018-01-03 23:46:13,773 - root - INFO - Step 4, Validation Loss= 0.5597, Validation Accuracy= 0.819
2018-01-03 23:46:13,773 - root - INFO - Step 4, Validation Loss= 0.5597, Validation Accuracy= 0.819
2018-01-03 23:46:15,930 : INFO : Step 5, Minibatch Loss= 0.1842, Training Accuracy= 0.929
2018-01-03 23:46:15,930 - root - INFO - Step 5, Minibatch Loss= 0.1842, Training Accuracy= 0.929
2018-01-03 23:46:15,930 - root - INFO - Step 5, Minibatch Loss= 0.1842, Training Accuracy= 0.929
2018-01-03 23:46:15,987 : INFO : Step 5, Validation Loss= 0.4597, Validation Accuracy= 0.845
2018-01-03 23:46:15,987 - root - INFO - Step 5, Validation Loss= 0.4597, Validation Accuracy= 0.845
2018-01-03 23:46:15,987 - root - INFO - Step 5, Validation Loss= 0.4597, Validation Accuracy= 0.845
2018-01-03 23:46:18,122 : INFO : Step 6, Minibatch Loss= 0.1441, Training Accuracy= 0.947
2018-01-03 23:46:18,122 - root - INFO - Step 6, Minibatch Loss= 0.1441, Training Accuracy= 0.947
2018-01-03 23:46:18,122 - root - INFO - Step 6, Minibatch Loss= 0.1441, Training Accuracy= 0.947
2018-01-03 23:46:18,179 : INFO : Step 6, Validation Loss= 0.3476, Validation Accuracy= 0.899
2018-01-03 23:46:18,179 - root - INFO - Step 6, Validation Loss= 0.3476, Validation Accuracy= 0.899
2018-01-03 23:46:18,179 - root - INFO - Step 6, Validation Loss= 0.3476, Validation Accuracy= 0.899
2018-01-03 23:46:20,360 : INFO : Step 7, Minibatch Loss= 0.1471, Training Accuracy= 0.943
2018-01-03 23:46:20,360 - root - INFO - Step 7, Minibatch Loss= 0.1471, Training Accuracy= 0.943
2018-01-03 23:46:20,360 - root - INFO - Step 7, Minibatch Loss= 0.1471, Training Accuracy= 0.943
2018-01-03 23:46:20,421 : INFO : Step 7, Validation Loss= 0.4979, Validation Accuracy= 0.882
2018-01-03 23:46:20,421 - root - INFO - Step 7, Validation Loss= 0.4979, Validation Accuracy= 0.882
2018-01-03 23:46:20,421 - root - INFO - Step 7, Validation Loss= 0.4979, Validation Accuracy= 0.882
2018-01-03 23:46:20,421 : INFO : starting fold 10 in 10-fold CV
2018-01-03 23:46:20,421 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:46:20,421 - root - INFO - starting fold 10 in 10-fold CV
2018-01-03 23:46:27,706 : INFO : Step 1, Minibatch Loss= 0.4337, Training Accuracy= 0.817
2018-01-03 23:46:27,706 - root - INFO - Step 1, Minibatch Loss= 0.4337, Training Accuracy= 0.817
2018-01-03 23:46:27,706 - root - INFO - Step 1, Minibatch Loss= 0.4337, Training Accuracy= 0.817
2018-01-03 23:46:27,772 : INFO : Step 1, Validation Loss= 0.4953, Validation Accuracy= 0.708
2018-01-03 23:46:27,772 - root - INFO - Step 1, Validation Loss= 0.4953, Validation Accuracy= 0.708
2018-01-03 23:46:27,772 - root - INFO - Step 1, Validation Loss= 0.4953, Validation Accuracy= 0.708
2018-01-03 23:46:29,957 : INFO : Step 2, Minibatch Loss= 0.2182, Training Accuracy= 0.919
2018-01-03 23:46:29,957 - root - INFO - Step 2, Minibatch Loss= 0.2182, Training Accuracy= 0.919
2018-01-03 23:46:29,957 - root - INFO - Step 2, Minibatch Loss= 0.2182, Training Accuracy= 0.919
2018-01-03 23:46:30,021 : INFO : Step 2, Validation Loss= 0.3044, Validation Accuracy= 0.847
2018-01-03 23:46:30,021 - root - INFO - Step 2, Validation Loss= 0.3044, Validation Accuracy= 0.847
2018-01-03 23:46:30,021 - root - INFO - Step 2, Validation Loss= 0.3044, Validation Accuracy= 0.847
2018-01-03 23:46:32,107 : INFO : Step 3, Minibatch Loss= 0.1466, Training Accuracy= 0.938
2018-01-03 23:46:32,107 - root - INFO - Step 3, Minibatch Loss= 0.1466, Training Accuracy= 0.938
2018-01-03 23:46:32,107 - root - INFO - Step 3, Minibatch Loss= 0.1466, Training Accuracy= 0.938
2018-01-03 23:46:32,168 : INFO : Step 3, Validation Loss= 0.4026, Validation Accuracy= 0.849
2018-01-03 23:46:32,168 - root - INFO - Step 3, Validation Loss= 0.4026, Validation Accuracy= 0.849
2018-01-03 23:46:32,168 - root - INFO - Step 3, Validation Loss= 0.4026, Validation Accuracy= 0.849
2018-01-03 23:46:34,308 : INFO : Step 4, Minibatch Loss= 0.1357, Training Accuracy= 0.937
2018-01-03 23:46:34,308 - root - INFO - Step 4, Minibatch Loss= 0.1357, Training Accuracy= 0.937
2018-01-03 23:46:34,308 - root - INFO - Step 4, Minibatch Loss= 0.1357, Training Accuracy= 0.937
2018-01-03 23:46:34,377 : INFO : Step 4, Validation Loss= 0.4086, Validation Accuracy= 0.852
2018-01-03 23:46:34,377 - root - INFO - Step 4, Validation Loss= 0.4086, Validation Accuracy= 0.852
2018-01-03 23:46:34,377 - root - INFO - Step 4, Validation Loss= 0.4086, Validation Accuracy= 0.852
2018-01-03 23:46:36,520 : INFO : Step 5, Minibatch Loss= 0.1041, Training Accuracy= 0.958
2018-01-03 23:46:36,520 - root - INFO - Step 5, Minibatch Loss= 0.1041, Training Accuracy= 0.958
2018-01-03 23:46:36,520 - root - INFO - Step 5, Minibatch Loss= 0.1041, Training Accuracy= 0.958
2018-01-03 23:46:36,580 : INFO : Step 5, Validation Loss= 0.4814, Validation Accuracy= 0.828
2018-01-03 23:46:36,580 - root - INFO - Step 5, Validation Loss= 0.4814, Validation Accuracy= 0.828
2018-01-03 23:46:36,580 - root - INFO - Step 5, Validation Loss= 0.4814, Validation Accuracy= 0.828
2018-01-03 23:46:36,580 : INFO : Average accuracy is 0.900215 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,580 - root - INFO - Average accuracy is 0.900215 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,580 - root - INFO - Average accuracy is 0.900215 for training_steps=10, batch_size=93, embed_size=50, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,580 : INFO : This 10-fold CV run-time: 156.53127598762512 seconds
2018-01-03 23:46:36,580 - root - INFO - This 10-fold CV run-time: 156.53127598762512 seconds
2018-01-03 23:46:36,580 - root - INFO - This 10-fold CV run-time: 156.53127598762512 seconds
2018-01-03 23:46:36,738 : INFO : current best: accuracy=0.900215, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,738 - root - INFO - current best: accuracy=0.900215, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,738 - root - INFO - current best: accuracy=0.900215, num_hidden=25, dropout=0.1
2018-01-03 23:46:36,738 : INFO : results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.88688171, (25, 0.1): 0.90021503}
2018-01-03 23:46:36,738 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.88688171, (25, 0.1): 0.90021503}
2018-01-03 23:46:36,738 - root - INFO - results for all hyperparam combinations dict[num_hidden,dropout]=accuracy: {(20, 0.1): 0.88688171, (25, 0.1): 0.90021503}
2018-01-03 23:46:36,739 : INFO : Code run-time: 339.0518457889557 seconds
2018-01-03 23:46:36,739 - root - INFO - Code run-time: 339.0518457889557 seconds
2018-01-03 23:46:36,739 - root - INFO - Code run-time: 339.0518457889557 seconds
