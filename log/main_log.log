2017-12-29 18:07:20,513 - tensorflow - INFO - this is a test message
2017-12-29 19:04:09,479 - tensorflow - INFO - this is a test message
2017-12-29 19:04:09,479 - tensorflow - INFO - this is a test message
2017-12-29 19:06:50,513 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:06:50,514 : INFO : collecting all words and their counts
2017-12-29 19:06:50,514 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:06:50,537 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:06:50,538 : INFO : Loading a fresh vocabulary
2017-12-29 19:06:50,644 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:06:50,645 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:06:50,666 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:06:50,667 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:06:50,667 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:06:50,667 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:06:50,679 : INFO : resetting layer weights
2017-12-29 19:06:50,764 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:06:51,238 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:06:51,238 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:06:51,245 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:06:51,245 : INFO : training on 797984 raw words (558278 effective words) took 0.5s, 1170701 effective words/s
2017-12-29 19:06:51,245 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:06:51,814 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:06:51,819 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:06:51,821 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:06:51,822 : INFO : training on 797984 raw words (558682 effective words) took 0.6s, 976258 effective words/s
2017-12-29 19:10:21,651 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:10:21,652 : INFO : collecting all words and their counts
2017-12-29 19:10:21,652 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:10:21,709 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:10:21,709 : INFO : Loading a fresh vocabulary
2017-12-29 19:10:21,848 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:10:21,848 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:10:21,877 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:10:21,880 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:10:21,880 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:10:21,881 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:10:21,920 : INFO : resetting layer weights
2017-12-29 19:10:22,025 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:10:22,461 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:10:22,466 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:10:22,469 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:10:22,470 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1271827 effective words/s
2017-12-29 19:10:22,470 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:10:22,921 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:10:22,926 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:10:22,927 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:10:22,927 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1235080 effective words/s
2017-12-29 19:13:37,278 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2017-12-29 19:13:37,279 : INFO : collecting all words and their counts
2017-12-29 19:13:37,279 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2017-12-29 19:13:37,311 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2017-12-29 19:13:37,312 : INFO : Loading a fresh vocabulary
2017-12-29 19:13:37,415 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2017-12-29 19:13:37,415 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2017-12-29 19:13:37,436 : INFO : deleting the raw counts dictionary of 6994 items
2017-12-29 19:13:37,437 : INFO : sample=0.001 downsamples 59 most-common words
2017-12-29 19:13:37,437 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2017-12-29 19:13:37,437 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2017-12-29 19:13:37,451 : INFO : resetting layer weights
2017-12-29 19:13:37,545 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:13:38,160 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:13:38,166 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:13:38,169 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:13:38,170 : INFO : training on 797984 raw words (558313 effective words) took 0.6s, 901067 effective words/s
2017-12-29 19:13:38,170 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2017-12-29 19:13:38,670 : INFO : worker thread finished; awaiting finish of 2 more threads
2017-12-29 19:13:38,674 : INFO : worker thread finished; awaiting finish of 1 more threads
2017-12-29 19:13:38,676 : INFO : worker thread finished; awaiting finish of 0 more threads
2017-12-29 19:13:38,676 : INFO : training on 797984 raw words (558760 effective words) took 0.5s, 1126686 effective words/s
2018-01-02 09:24:51,347 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 09:24:51,353 : INFO : collecting all words and their counts
2018-01-02 09:24:51,354 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 09:24:51,378 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 09:24:51,378 : INFO : Loading a fresh vocabulary
2018-01-02 09:24:51,466 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 09:24:51,466 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 09:24:51,492 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 09:24:51,495 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 09:24:51,495 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 09:24:51,496 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 09:24:51,514 : INFO : resetting layer weights
2018-01-02 09:24:51,586 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:24:52,023 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:24:52,025 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:24:52,030 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:24:52,030 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1270283 effective words/s
2018-01-02 09:24:52,031 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:24:52,447 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:24:52,451 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:24:52,454 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:24:52,454 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1333767 effective words/s
2018-01-02 09:46:30,619 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 09:46:30,620 : INFO : collecting all words and their counts
2018-01-02 09:46:30,620 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 09:46:30,649 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 09:46:30,649 : INFO : Loading a fresh vocabulary
2018-01-02 09:46:30,666 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 09:46:30,666 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 09:46:30,688 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 09:46:30,688 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 09:46:30,688 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 09:46:30,688 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 09:46:30,706 : INFO : resetting layer weights
2018-01-02 09:46:30,786 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 09:46:31,212 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 09:46:31,219 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 09:46:31,220 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 09:46:31,220 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1382626 effective words/s
2018-01-02 10:01:03,125 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:01:03,126 : INFO : collecting all words and their counts
2018-01-02 10:01:03,126 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:01:03,150 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:01:03,150 : INFO : Loading a fresh vocabulary
2018-01-02 10:01:03,170 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:01:03,170 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:01:03,195 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:01:03,195 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:01:03,195 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:01:03,195 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:01:03,210 : INFO : resetting layer weights
2018-01-02 10:01:03,295 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:01:03,850 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:01:03,854 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:01:03,860 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:01:03,860 : INFO : training on 827888 raw words (591883 effective words) took 0.6s, 1055121 effective words/s
2018-01-02 10:02:34,197 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:02:34,198 : INFO : collecting all words and their counts
2018-01-02 10:02:34,198 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:02:34,221 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:02:34,222 : INFO : Loading a fresh vocabulary
2018-01-02 10:02:34,236 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:02:34,236 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:02:34,260 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:02:34,260 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:02:34,260 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:02:34,260 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:02:34,273 : INFO : resetting layer weights
2018-01-02 10:02:34,357 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:02:34,805 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:02:34,809 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:02:34,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:02:34,812 : INFO : training on 827888 raw words (592151 effective words) took 0.5s, 1312741 effective words/s
2018-01-02 10:02:51,234 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:02:51,234 : INFO : collecting all words and their counts
2018-01-02 10:02:51,234 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:02:51,258 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:02:51,258 : INFO : Loading a fresh vocabulary
2018-01-02 10:02:51,272 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:02:51,273 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:02:51,295 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:02:51,295 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:02:51,295 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:02:51,296 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:02:51,309 : INFO : resetting layer weights
2018-01-02 10:02:51,390 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:02:51,805 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:02:51,808 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:02:51,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:02:51,812 : INFO : training on 827888 raw words (591820 effective words) took 0.4s, 1416934 effective words/s
2018-01-02 10:03:19,652 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:03:19,652 : INFO : collecting all words and their counts
2018-01-02 10:03:19,652 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:03:19,678 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:03:19,678 : INFO : Loading a fresh vocabulary
2018-01-02 10:03:19,695 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:03:19,695 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:03:19,715 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:03:19,716 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:03:19,716 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:03:19,716 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:03:19,733 : INFO : resetting layer weights
2018-01-02 10:03:19,815 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:03:20,234 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:03:20,235 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:03:20,240 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:03:20,240 : INFO : training on 827888 raw words (592368 effective words) took 0.4s, 1408810 effective words/s
2018-01-02 10:06:10,206 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:06:10,207 : INFO : collecting all words and their counts
2018-01-02 10:06:10,208 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:06:10,231 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:06:10,231 : INFO : Loading a fresh vocabulary
2018-01-02 10:06:10,247 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:06:10,247 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:06:10,269 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:06:10,269 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:06:10,269 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:06:10,269 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:06:10,283 : INFO : resetting layer weights
2018-01-02 10:06:10,366 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:06:10,806 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:06:10,809 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:06:10,811 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:06:10,811 : INFO : training on 827888 raw words (591936 effective words) took 0.4s, 1342125 effective words/s
2018-01-02 10:06:35,126 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 10:06:35,126 : INFO : collecting all words and their counts
2018-01-02 10:06:35,126 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 10:06:35,149 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 10:06:35,150 : INFO : Loading a fresh vocabulary
2018-01-02 10:06:35,163 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 10:06:35,163 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 10:06:35,184 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 10:06:35,185 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 10:06:35,185 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 10:06:35,185 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 10:06:35,202 : INFO : resetting layer weights
2018-01-02 10:06:35,281 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 10:06:35,706 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 10:06:35,708 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 10:06:35,710 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 10:06:35,710 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1391799 effective words/s
2018-01-02 14:34:50,174 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:34:50,176 : INFO : collecting all words and their counts
2018-01-02 14:34:50,177 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:34:50,198 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 14:34:50,198 : INFO : Loading a fresh vocabulary
2018-01-02 14:34:50,212 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 14:34:50,212 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 14:34:50,231 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 14:34:50,232 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 14:34:50,232 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 14:34:50,232 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 14:34:50,245 : INFO : resetting layer weights
2018-01-02 14:34:50,322 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:34:50,888 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:34:50,895 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:34:50,898 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:34:50,898 : INFO : training on 827888 raw words (592108 effective words) took 0.6s, 1035817 effective words/s
2018-01-02 14:45:41,237 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:45:41,241 : INFO : collecting all words and their counts
2018-01-02 14:45:41,241 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:45:41,267 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:45:41,267 : INFO : Loading a fresh vocabulary
2018-01-02 14:45:41,286 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:45:41,287 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:45:41,305 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:45:41,305 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:45:41,305 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:45:41,307 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 14:45:41,321 : INFO : resetting layer weights
2018-01-02 14:45:41,399 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:45:41,905 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:45:41,907 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:45:41,912 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:45:41,912 : INFO : training on 797984 raw words (558613 effective words) took 0.5s, 1099640 effective words/s
2018-01-02 14:45:41,912 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:45:42,415 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:45:42,417 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:45:42,421 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:45:42,421 : INFO : training on 797984 raw words (558450 effective words) took 0.5s, 1107059 effective words/s
2018-01-02 14:53:28,707 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:53:28,708 : INFO : collecting all words and their counts
2018-01-02 14:53:28,708 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:53:28,738 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:53:28,738 : INFO : Loading a fresh vocabulary
2018-01-02 14:53:28,753 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:53:28,753 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:53:28,772 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:53:28,772 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:53:28,772 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:53:28,772 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 14:53:28,784 : INFO : resetting layer weights
2018-01-02 14:53:28,865 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:53:29,320 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:53:29,325 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:53:29,327 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:53:29,327 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1220903 effective words/s
2018-01-02 14:53:29,327 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:53:29,757 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:53:29,759 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:53:29,764 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:53:29,764 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1287463 effective words/s
2018-01-02 14:54:10,429 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 14:54:10,430 : INFO : collecting all words and their counts
2018-01-02 14:54:10,430 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 14:54:10,453 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 14:54:10,453 : INFO : Loading a fresh vocabulary
2018-01-02 14:54:10,468 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 14:54:10,468 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 14:54:10,485 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 14:54:10,485 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 14:54:10,485 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 14:54:10,485 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 14:54:10,496 : INFO : resetting layer weights
2018-01-02 14:54:10,569 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:54:10,984 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:54:10,986 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:54:10,989 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:54:10,989 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1343077 effective words/s
2018-01-02 14:54:10,989 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 14:54:11,402 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 14:54:11,404 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 14:54:11,406 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 14:54:11,406 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1350976 effective words/s
2018-01-02 15:00:47,778 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 15:00:47,778 : INFO : collecting all words and their counts
2018-01-02 15:00:47,778 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 15:00:47,801 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 15:00:47,801 : INFO : Loading a fresh vocabulary
2018-01-02 15:00:47,817 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 15:00:47,817 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 15:00:47,839 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 15:00:47,839 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 15:00:47,839 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 15:00:47,839 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 15:00:47,855 : INFO : resetting layer weights
2018-01-02 15:00:47,938 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 15:00:48,416 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 15:00:48,419 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 15:00:48,421 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 15:00:48,421 : INFO : training on 827888 raw words (592107 effective words) took 0.5s, 1241856 effective words/s
2018-01-02 16:50:34,146 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:50:34,147 : INFO : collecting all words and their counts
2018-01-02 16:50:34,147 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:50:34,171 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 16:50:34,171 : INFO : Loading a fresh vocabulary
2018-01-02 16:50:34,188 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 16:50:34,188 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 16:50:34,206 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 16:50:34,206 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 16:50:34,206 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 16:50:34,206 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 16:50:34,219 : INFO : resetting layer weights
2018-01-02 16:50:34,296 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:50:34,722 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:50:34,728 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:50:34,732 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:50:34,732 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1297903 effective words/s
2018-01-02 16:50:34,732 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:50:35,163 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:50:35,169 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:50:35,170 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:50:35,170 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1285754 effective words/s
2018-01-02 16:56:55,599 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:56:55,599 : INFO : collecting all words and their counts
2018-01-02 16:56:55,600 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:56:55,622 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 16:56:55,622 : INFO : Loading a fresh vocabulary
2018-01-02 16:56:55,634 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 16:56:55,635 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 16:56:55,652 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 16:56:55,652 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 16:56:55,652 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 16:56:55,652 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 16:56:55,666 : INFO : resetting layer weights
2018-01-02 16:56:55,748 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:56:56,185 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:56:56,185 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:56:56,190 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:56:56,190 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1277113 effective words/s
2018-01-02 16:56:56,190 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:56:56,612 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:56:56,615 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:56:56,618 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:56:56,619 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1314804 effective words/s
2018-01-02 16:59:00,231 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 16:59:00,231 : INFO : collecting all words and their counts
2018-01-02 16:59:00,232 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 16:59:00,257 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 16:59:00,257 : INFO : Loading a fresh vocabulary
2018-01-02 16:59:00,271 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 16:59:00,271 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 16:59:00,296 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 16:59:00,296 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 16:59:00,296 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 16:59:00,296 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 16:59:00,311 : INFO : resetting layer weights
2018-01-02 16:59:00,393 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 16:59:00,847 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 16:59:00,850 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 16:59:00,854 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 16:59:00,854 : INFO : training on 827888 raw words (592290 effective words) took 0.5s, 1296381 effective words/s
2018-01-02 17:11:02,710 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:02,713 : INFO : collecting all words and their counts
2018-01-02 17:11:02,713 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:02,737 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:02,738 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:02,758 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:02,758 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:02,781 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:02,781 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:02,781 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:02,781 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:02,796 : INFO : resetting layer weights
2018-01-02 17:11:02,882 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:03,424 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:03,427 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:03,431 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:03,431 : INFO : training on 827888 raw words (592301 effective words) took 0.5s, 1097077 effective words/s
2018-01-02 17:11:27,892 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:27,893 : INFO : collecting all words and their counts
2018-01-02 17:11:27,893 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:27,916 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:27,916 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:27,935 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:27,936 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:27,958 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:27,959 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:27,959 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:27,959 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:27,972 : INFO : resetting layer weights
2018-01-02 17:11:28,052 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:28,533 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:28,539 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:28,543 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:28,543 : INFO : training on 827888 raw words (591661 effective words) took 0.5s, 1217171 effective words/s
2018-01-02 17:11:55,212 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:11:55,214 : INFO : collecting all words and their counts
2018-01-02 17:11:55,214 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:11:55,241 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:11:55,241 : INFO : Loading a fresh vocabulary
2018-01-02 17:11:55,264 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:11:55,264 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:11:55,286 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:11:55,287 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:11:55,287 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:11:55,287 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:11:55,305 : INFO : resetting layer weights
2018-01-02 17:11:55,386 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:11:55,847 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:11:55,849 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:11:55,854 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:11:55,854 : INFO : training on 827888 raw words (591820 effective words) took 0.5s, 1276808 effective words/s
2018-01-02 17:15:38,831 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:15:38,833 : INFO : collecting all words and their counts
2018-01-02 17:15:38,833 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:15:38,857 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 17:15:38,858 : INFO : Loading a fresh vocabulary
2018-01-02 17:15:38,877 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 17:15:38,877 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 17:15:38,898 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 17:15:38,898 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 17:15:38,898 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 17:15:38,899 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 17:15:38,915 : INFO : resetting layer weights
2018-01-02 17:15:38,994 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:15:39,605 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:15:39,608 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:15:39,616 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:15:39,616 : INFO : training on 827888 raw words (591653 effective words) took 0.6s, 957054 effective words/s
2018-01-02 17:20:33,540 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:20:33,544 : INFO : collecting all words and their counts
2018-01-02 17:20:33,544 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:20:33,569 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:20:33,569 : INFO : Loading a fresh vocabulary
2018-01-02 17:20:33,586 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:20:33,586 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:20:33,605 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:20:33,605 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:20:33,605 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:20:33,605 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:20:33,627 : INFO : resetting layer weights
2018-01-02 17:20:33,701 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:20:34,237 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:20:34,245 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:20:34,246 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:20:34,246 : INFO : training on 797984 raw words (558244 effective words) took 0.5s, 1032812 effective words/s
2018-01-02 17:20:34,246 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:20:34,841 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:20:34,846 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:20:34,849 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:20:34,850 : INFO : training on 797984 raw words (559026 effective words) took 0.6s, 933533 effective words/s
2018-01-02 17:21:42,251 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:21:42,251 : INFO : collecting all words and their counts
2018-01-02 17:21:42,251 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:21:42,279 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:21:42,279 : INFO : Loading a fresh vocabulary
2018-01-02 17:21:42,292 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:21:42,292 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:21:42,314 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:21:42,316 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:21:42,316 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:21:42,317 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:21:42,332 : INFO : resetting layer weights
2018-01-02 17:21:42,404 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:21:42,882 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:21:42,884 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:21:42,889 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:21:42,889 : INFO : training on 797984 raw words (558991 effective words) took 0.5s, 1164219 effective words/s
2018-01-02 17:21:42,889 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:21:43,338 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:21:43,342 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:21:43,344 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:21:43,344 : INFO : training on 797984 raw words (558657 effective words) took 0.5s, 1238396 effective words/s
2018-01-02 17:22:34,247 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:22:34,247 : INFO : collecting all words and their counts
2018-01-02 17:22:34,247 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:22:34,272 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:22:34,272 : INFO : Loading a fresh vocabulary
2018-01-02 17:22:34,289 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:22:34,290 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:22:34,310 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:22:34,310 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:22:34,310 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:22:34,310 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:22:34,324 : INFO : resetting layer weights
2018-01-02 17:22:34,395 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:22:34,865 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:22:34,868 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:22:34,871 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:22:34,871 : INFO : training on 797984 raw words (559130 effective words) took 0.5s, 1183127 effective words/s
2018-01-02 17:22:34,872 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:22:35,289 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:22:35,294 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:22:35,295 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:22:35,295 : INFO : training on 797984 raw words (558519 effective words) took 0.4s, 1332702 effective words/s
2018-01-02 17:26:53,448 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:26:53,448 : INFO : collecting all words and their counts
2018-01-02 17:26:53,448 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:26:53,470 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:26:53,470 : INFO : Loading a fresh vocabulary
2018-01-02 17:26:53,484 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:26:53,484 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:26:53,507 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:26:53,507 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:26:53,507 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:26:53,507 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:26:53,522 : INFO : resetting layer weights
2018-01-02 17:26:53,594 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:26:54,067 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:26:54,071 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:26:54,075 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:26:54,075 : INFO : training on 797984 raw words (558924 effective words) took 0.5s, 1173226 effective words/s
2018-01-02 17:26:54,075 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:26:54,594 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:26:54,596 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:26:54,599 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:26:54,599 : INFO : training on 797984 raw words (558926 effective words) took 0.5s, 1074545 effective words/s
2018-01-02 17:27:23,432 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:27:23,432 : INFO : collecting all words and their counts
2018-01-02 17:27:23,433 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:27:23,459 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:27:23,460 : INFO : Loading a fresh vocabulary
2018-01-02 17:27:23,475 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:27:23,475 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:27:23,503 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:27:23,504 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:27:23,504 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:27:23,504 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:27:23,519 : INFO : resetting layer weights
2018-01-02 17:27:23,587 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:27:24,023 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:27:24,027 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:27:24,030 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:27:24,030 : INFO : training on 797984 raw words (558463 effective words) took 0.4s, 1273150 effective words/s
2018-01-02 17:27:24,030 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:27:24,489 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:27:24,489 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:27:24,498 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:27:24,498 : INFO : training on 797984 raw words (558220 effective words) took 0.5s, 1203186 effective words/s
2018-01-02 17:28:32,158 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:28:32,159 : INFO : collecting all words and their counts
2018-01-02 17:28:32,159 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:28:32,181 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:28:32,181 : INFO : Loading a fresh vocabulary
2018-01-02 17:28:32,195 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:28:32,195 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:28:32,213 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:28:32,213 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:28:32,214 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:28:32,214 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:28:32,227 : INFO : resetting layer weights
2018-01-02 17:28:32,312 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:28:32,927 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:28:32,928 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:28:32,933 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:28:32,933 : INFO : training on 797984 raw words (558496 effective words) took 0.6s, 906040 effective words/s
2018-01-02 17:28:32,933 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:28:33,384 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:28:33,387 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:28:33,392 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:28:33,392 : INFO : training on 797984 raw words (558545 effective words) took 0.5s, 1231387 effective words/s
2018-01-02 17:33:28,376 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 17:33:28,377 : INFO : collecting all words and their counts
2018-01-02 17:33:28,377 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 17:33:28,401 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 17:33:28,401 : INFO : Loading a fresh vocabulary
2018-01-02 17:33:28,415 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 17:33:28,415 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 17:33:28,435 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 17:33:28,435 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 17:33:28,435 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 17:33:28,435 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 17:33:28,447 : INFO : resetting layer weights
2018-01-02 17:33:28,519 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:33:28,937 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:33:28,938 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:33:28,941 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:33:28,941 : INFO : training on 797984 raw words (558464 effective words) took 0.4s, 1339043 effective words/s
2018-01-02 17:33:28,941 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 17:33:29,363 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 17:33:29,367 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 17:33:29,370 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 17:33:29,370 : INFO : training on 797984 raw words (558276 effective words) took 0.4s, 1314765 effective words/s
2018-01-02 18:39:36,642 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:39:36,643 : INFO : collecting all words and their counts
2018-01-02 18:39:36,643 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:39:36,671 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:39:36,671 : INFO : Loading a fresh vocabulary
2018-01-02 18:39:36,695 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:39:36,695 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:39:36,714 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:39:36,714 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:39:36,714 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:39:36,714 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:39:36,728 : INFO : resetting layer weights
2018-01-02 18:39:36,798 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:37,237 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:37,242 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:37,244 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:37,244 : INFO : training on 797984 raw words (558538 effective words) took 0.4s, 1266320 effective words/s
2018-01-02 18:39:37,244 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:37,795 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:37,811 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:37,812 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:37,812 : INFO : training on 797984 raw words (558961 effective words) took 0.6s, 991490 effective words/s
2018-01-02 18:39:55,524 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:39:55,529 : INFO : collecting all words and their counts
2018-01-02 18:39:55,530 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:39:55,556 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:39:55,556 : INFO : Loading a fresh vocabulary
2018-01-02 18:39:55,579 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:39:55,579 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:39:55,596 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:39:55,596 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:39:55,597 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:39:55,597 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:39:55,610 : INFO : resetting layer weights
2018-01-02 18:39:55,688 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:56,112 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:56,118 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:56,120 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:56,120 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1308562 effective words/s
2018-01-02 18:39:56,120 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:39:56,556 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:39:56,561 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:39:56,562 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:39:56,563 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1273881 effective words/s
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:40:15,209 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:43:38,862 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:43:38,877 : INFO : collecting all words and their counts
2018-01-02 18:43:38,877 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:43:38,901 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:43:38,902 : INFO : Loading a fresh vocabulary
2018-01-02 18:43:38,917 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:43:38,917 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:43:38,938 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:43:38,938 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:43:38,938 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:43:38,939 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:43:38,955 : INFO : resetting layer weights
2018-01-02 18:43:39,042 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:43:39,501 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:43:39,506 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:43:39,507 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:43:39,507 : INFO : training on 827888 raw words (591936 effective words) took 0.5s, 1284742 effective words/s
2018-01-02 18:48:49,385 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:48:49,386 : INFO : collecting all words and their counts
2018-01-02 18:48:49,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:48:49,411 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:48:49,411 : INFO : Loading a fresh vocabulary
2018-01-02 18:48:49,429 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:48:49,430 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:48:49,453 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:48:49,453 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:48:49,453 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:48:49,453 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:48:49,470 : INFO : resetting layer weights
2018-01-02 18:48:49,549 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:48:49,971 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:48:49,976 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:48:49,978 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:48:49,978 : INFO : training on 827888 raw words (592080 effective words) took 0.4s, 1394608 effective words/s
2018-01-02 18:49:20,260 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:49:20,261 : INFO : collecting all words and their counts
2018-01-02 18:49:20,261 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:49:20,286 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 18:49:20,286 : INFO : Loading a fresh vocabulary
2018-01-02 18:49:20,304 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 18:49:20,305 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 18:49:20,322 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 18:49:20,322 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 18:49:20,322 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 18:49:20,322 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 18:49:20,334 : INFO : resetting layer weights
2018-01-02 18:49:20,421 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:49:20,845 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:49:20,846 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:49:20,849 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:49:20,849 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1320162 effective words/s
2018-01-02 18:49:20,850 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:49:21,274 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:49:21,276 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:49:21,281 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:49:21,281 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1305008 effective words/s
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:49:41,067 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 18:52:00,836 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 18:52:00,839 : INFO : collecting all words and their counts
2018-01-02 18:52:00,839 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 18:52:00,864 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 18:52:00,864 : INFO : Loading a fresh vocabulary
2018-01-02 18:52:00,880 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 18:52:00,880 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 18:52:00,901 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 18:52:00,902 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 18:52:00,902 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 18:52:00,902 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 18:52:00,919 : INFO : resetting layer weights
2018-01-02 18:52:01,000 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 18:52:01,425 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 18:52:01,429 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 18:52:01,432 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 18:52:01,433 : INFO : training on 827888 raw words (592108 effective words) took 0.4s, 1383641 effective words/s
2018-01-02 19:00:36,363 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:00:36,364 : INFO : collecting all words and their counts
2018-01-02 19:00:36,364 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:00:36,385 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:00:36,385 : INFO : Loading a fresh vocabulary
2018-01-02 19:00:36,399 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:00:36,399 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:00:36,416 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:00:36,416 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:00:36,416 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:00:36,417 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:00:36,430 : INFO : resetting layer weights
2018-01-02 19:00:36,503 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:36,934 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:36,942 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:36,945 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:36,945 : INFO : training on 797984 raw words (558607 effective words) took 0.4s, 1277989 effective words/s
2018-01-02 19:00:36,945 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:37,447 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:37,451 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:37,452 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:37,452 : INFO : training on 797984 raw words (558818 effective words) took 0.5s, 1113653 effective words/s
2018-01-02 19:00:56,971 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:00:56,977 : INFO : collecting all words and their counts
2018-01-02 19:00:56,977 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:00:57,009 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:00:57,010 : INFO : Loading a fresh vocabulary
2018-01-02 19:00:57,023 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:00:57,023 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:00:57,045 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:00:57,045 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:00:57,045 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:00:57,045 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:00:57,057 : INFO : resetting layer weights
2018-01-02 19:00:57,145 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:57,573 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:57,581 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:57,582 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:57,582 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1289586 effective words/s
2018-01-02 19:00:57,583 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:00:57,999 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:00:58,005 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:00:58,007 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:00:58,007 : INFO : training on 797984 raw words (558457 effective words) took 0.4s, 1327425 effective words/s
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:01:14,908 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:01,785 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:05:01,786 : INFO : collecting all words and their counts
2018-01-02 19:05:01,786 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:05:01,808 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:05:01,808 : INFO : Loading a fresh vocabulary
2018-01-02 19:05:01,822 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:05:01,822 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:05:01,841 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:05:01,842 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:05:01,842 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:05:01,842 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:05:01,857 : INFO : resetting layer weights
2018-01-02 19:05:01,936 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:05:02,348 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:05:02,351 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:05:02,355 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:05:02,356 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1346070 effective words/s
2018-01-02 19:05:02,356 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:05:02,781 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:05:02,785 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:05:02,787 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:05:02,787 : INFO : training on 797984 raw words (558138 effective words) took 0.4s, 1307127 effective words/s
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:05:19,163 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:07:44,909 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:07:44,909 : INFO : collecting all words and their counts
2018-01-02 19:07:44,909 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:07:44,931 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:07:44,931 : INFO : Loading a fresh vocabulary
2018-01-02 19:07:44,943 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:07:44,943 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:07:44,960 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:07:44,960 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:07:44,960 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:07:44,960 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:07:44,971 : INFO : resetting layer weights
2018-01-02 19:07:45,039 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:07:45,483 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:07:45,488 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:07:45,489 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:07:45,489 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1254369 effective words/s
2018-01-02 19:07:45,489 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:07:45,909 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:07:45,915 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:07:45,916 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:07:45,916 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1322208 effective words/s
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:08:03,946 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:12:58,387 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:12:58,387 : INFO : collecting all words and their counts
2018-01-02 19:12:58,387 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:12:58,410 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:12:58,410 : INFO : Loading a fresh vocabulary
2018-01-02 19:12:58,423 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:12:58,423 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:12:58,439 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:12:58,439 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:12:58,439 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:12:58,439 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:12:58,452 : INFO : resetting layer weights
2018-01-02 19:12:58,519 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:12:58,949 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:12:58,955 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:12:58,956 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:12:58,956 : INFO : training on 797984 raw words (558482 effective words) took 0.4s, 1289651 effective words/s
2018-01-02 19:12:58,956 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:12:59,387 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:12:59,392 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:12:59,394 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:12:59,394 : INFO : training on 797984 raw words (558258 effective words) took 0.4s, 1285742 effective words/s
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:13:16,495 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:22:48,251 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:22:48,252 : INFO : collecting all words and their counts
2018-01-02 19:22:48,252 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:22:48,278 : INFO : collected 8046 word types from a corpus of 103486 raw words and 4743 sentences
2018-01-02 19:22:48,278 : INFO : Loading a fresh vocabulary
2018-01-02 19:22:48,298 : INFO : min_count=1 retains 8046 unique words (100% of original 8046, drops 0)
2018-01-02 19:22:48,299 : INFO : min_count=1 leaves 103486 word corpus (100% of original 103486, drops 0)
2018-01-02 19:22:48,319 : INFO : deleting the raw counts dictionary of 8046 items
2018-01-02 19:22:48,319 : INFO : sample=0.001 downsamples 56 most-common words
2018-01-02 19:22:48,319 : INFO : downsampling leaves estimated 74028 word corpus (71.5% of prior 103486)
2018-01-02 19:22:48,319 : INFO : estimated required memory for 8046 words and 25 dimensions: 5632200 bytes
2018-01-02 19:22:48,333 : INFO : resetting layer weights
2018-01-02 19:22:48,408 : INFO : training model with 3 workers on 8046 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:48,832 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:48,836 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:48,836 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:48,836 : INFO : training on 827888 raw words (592107 effective words) took 0.4s, 1399837 effective words/s
2018-01-02 19:22:55,849 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:22:55,850 : INFO : collecting all words and their counts
2018-01-02 19:22:55,850 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:22:55,878 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:22:55,878 : INFO : Loading a fresh vocabulary
2018-01-02 19:22:55,892 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:22:55,893 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:22:55,913 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:22:55,914 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:22:55,914 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:22:55,914 : INFO : estimated required memory for 6994 words and 25 dimensions: 4895800 bytes
2018-01-02 19:22:55,926 : INFO : resetting layer weights
2018-01-02 19:22:56,002 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:56,418 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:56,422 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:56,425 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:56,425 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1334330 effective words/s
2018-01-02 19:22:56,425 : INFO : training model with 3 workers on 6994 vocabulary and 25 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:22:56,837 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:22:56,844 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:22:56,846 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:22:56,846 : INFO : training on 797984 raw words (558916 effective words) took 0.4s, 1340855 effective words/s
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 - tensorflow - INFO - starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:15,604 : INFO : starting training for the follwing parameters: training_steps=20, batch_size=93, embed_size=25, num_hidden=20
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 - tensorflow - INFO - Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,368 : INFO : Step 1, Minibatch Loss= 0.3507, Training Accuracy= 0.904
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 - tensorflow - INFO - Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:23,427 : INFO : Step 1, Validation Loss= 0.4821, Validation Accuracy= 0.723
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,211 : INFO : Step 2, Minibatch Loss= 0.1244, Training Accuracy= 0.961
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 - tensorflow - INFO - Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:25,266 : INFO : Step 2, Validation Loss= 0.2643, Validation Accuracy= 0.903
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,036 : INFO : Step 3, Minibatch Loss= 0.0783, Training Accuracy= 0.976
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 - tensorflow - INFO - Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:27,096 : INFO : Step 3, Validation Loss= 0.2129, Validation Accuracy= 0.927
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,827 : INFO : Step 4, Minibatch Loss= 0.0482, Training Accuracy= 0.991
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 - tensorflow - INFO - Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:28,895 : INFO : Step 4, Validation Loss= 0.2136, Validation Accuracy= 0.931
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,644 : INFO : Step 5, Minibatch Loss= 0.0287, Training Accuracy= 0.994
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 - tensorflow - INFO - Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:30,705 : INFO : Step 5, Validation Loss= 0.3572, Validation Accuracy= 0.892
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,383 : INFO : Step 6, Minibatch Loss= 0.0162, Training Accuracy= 0.997
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 - tensorflow - INFO - Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:32,436 : INFO : Step 6, Validation Loss= 0.3653, Validation Accuracy= 0.897
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,153 : INFO : Step 7, Minibatch Loss= 0.0151, Training Accuracy= 0.996
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 - tensorflow - INFO - Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:34,220 : INFO : Step 7, Validation Loss= 0.5132, Validation Accuracy= 0.882
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:35,946 : INFO : Step 8, Minibatch Loss= 0.0099, Training Accuracy= 0.999
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 - tensorflow - INFO - Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:36,009 : INFO : Step 8, Validation Loss= 0.3817, Validation Accuracy= 0.897
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,778 : INFO : Step 9, Minibatch Loss= 0.0076, Training Accuracy= 0.999
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 - tensorflow - INFO - Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:37,843 : INFO : Step 9, Validation Loss= 0.5768, Validation Accuracy= 0.865
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,731 : INFO : Step 10, Minibatch Loss= 0.0065, Training Accuracy= 0.999
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 - tensorflow - INFO - Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:39,795 : INFO : Step 10, Validation Loss= 0.4532, Validation Accuracy= 0.899
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 - tensorflow - INFO - Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,703 : INFO : Step 11, Minibatch Loss= 0.0045, Training Accuracy= 1.000
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 - tensorflow - INFO - Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:41,763 : INFO : Step 11, Validation Loss= 0.4438, Validation Accuracy= 0.910
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 - tensorflow - INFO - Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,602 : INFO : Step 12, Minibatch Loss= 0.0112, Training Accuracy= 0.997
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 - tensorflow - INFO - Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:43,657 : INFO : Step 12, Validation Loss= 0.7433, Validation Accuracy= 0.849
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 - tensorflow - INFO - Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,377 : INFO : Step 13, Minibatch Loss= 0.0064, Training Accuracy= 1.000
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 - tensorflow - INFO - Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:45,431 : INFO : Step 13, Validation Loss= 0.5453, Validation Accuracy= 0.892
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 - tensorflow - INFO - Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,144 : INFO : Step 14, Minibatch Loss= 0.0052, Training Accuracy= 0.999
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 - tensorflow - INFO - Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:47,205 : INFO : Step 14, Validation Loss= 0.6319, Validation Accuracy= 0.871
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 - tensorflow - INFO - Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,905 : INFO : Step 15, Minibatch Loss= 0.0035, Training Accuracy= 1.000
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 - tensorflow - INFO - Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:48,960 : INFO : Step 15, Validation Loss= 0.7436, Validation Accuracy= 0.888
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 - tensorflow - INFO - Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,667 : INFO : Step 16, Minibatch Loss= 0.0036, Training Accuracy= 0.999
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 - tensorflow - INFO - Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:50,720 : INFO : Step 16, Validation Loss= 0.7290, Validation Accuracy= 0.877
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 - tensorflow - INFO - Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,455 : INFO : Step 17, Minibatch Loss= 0.0028, Training Accuracy= 1.000
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 - tensorflow - INFO - Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:52,543 : INFO : Step 17, Validation Loss= 0.5497, Validation Accuracy= 0.888
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 - tensorflow - INFO - Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,322 : INFO : Step 18, Minibatch Loss= 0.0031, Training Accuracy= 0.999
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 - tensorflow - INFO - Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:54,378 : INFO : Step 18, Validation Loss= 1.0878, Validation Accuracy= 0.852
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 - tensorflow - INFO - Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,108 : INFO : Step 19, Minibatch Loss= 0.0027, Training Accuracy= 0.999
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 - tensorflow - INFO - Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:56,162 : INFO : Step 19, Validation Loss= 1.0910, Validation Accuracy= 0.849
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 - tensorflow - INFO - Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,019 : INFO : Step 20, Minibatch Loss= 0.0028, Training Accuracy= 0.999
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 - tensorflow - INFO - Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:23:58,083 : INFO : Step 20, Validation Loss= 0.9905, Validation Accuracy= 0.858
2018-01-02 19:28:03,149 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:28:03,150 : INFO : collecting all words and their counts
2018-01-02 19:28:03,150 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:28:03,178 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:28:03,178 : INFO : Loading a fresh vocabulary
2018-01-02 19:28:03,192 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:28:03,192 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:28:03,213 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:28:03,213 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:28:03,214 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:28:03,214 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 19:28:03,231 : INFO : resetting layer weights
2018-01-02 19:28:03,303 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:03,790 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:03,792 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:03,794 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:03,795 : INFO : training on 797984 raw words (558538 effective words) took 0.5s, 1146586 effective words/s
2018-01-02 19:28:03,795 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:04,296 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:04,299 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:04,304 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:04,304 : INFO : training on 797984 raw words (558204 effective words) took 0.5s, 1104781 effective words/s
2018-01-02 19:28:42,209 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-02 19:28:42,209 : INFO : collecting all words and their counts
2018-01-02 19:28:42,209 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-02 19:28:42,231 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-02 19:28:42,231 : INFO : Loading a fresh vocabulary
2018-01-02 19:28:42,244 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-02 19:28:42,245 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-02 19:28:42,262 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-02 19:28:42,262 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-02 19:28:42,262 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-02 19:28:42,262 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-02 19:28:42,274 : INFO : resetting layer weights
2018-01-02 19:28:42,349 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:42,790 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:42,797 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:42,797 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:42,797 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1259820 effective words/s
2018-01-02 19:28:42,798 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-02 19:28:43,244 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-02 19:28:43,251 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-02 19:28:43,253 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-02 19:28:43,253 : INFO : training on 797984 raw words (558916 effective words) took 0.5s, 1237408 effective words/s
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 - tensorflow - INFO - starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:03,345 : INFO : starting training for the follwing parameters: training_steps=10, batch_size=93, embed_size=50, num_hidden=20
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,398 : INFO : Step 1, Minibatch Loss= 0.4253, Training Accuracy= 0.852
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 - tensorflow - INFO - Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:11,460 : INFO : Step 1, Validation Loss= 0.5578, Validation Accuracy= 0.735
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 - tensorflow - INFO - Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,297 : INFO : Step 2, Minibatch Loss= 0.1346, Training Accuracy= 0.961
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 - tensorflow - INFO - Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:13,355 : INFO : Step 2, Validation Loss= 0.3266, Validation Accuracy= 0.895
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 - tensorflow - INFO - Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,224 : INFO : Step 3, Minibatch Loss= 0.0687, Training Accuracy= 0.980
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 - tensorflow - INFO - Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:15,290 : INFO : Step 3, Validation Loss= 0.2108, Validation Accuracy= 0.933
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 - tensorflow - INFO - Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,159 : INFO : Step 4, Minibatch Loss= 0.0474, Training Accuracy= 0.986
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 - tensorflow - INFO - Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:17,225 : INFO : Step 4, Validation Loss= 0.1928, Validation Accuracy= 0.933
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 - tensorflow - INFO - Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,094 : INFO : Step 5, Minibatch Loss= 0.0293, Training Accuracy= 0.993
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 - tensorflow - INFO - Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:19,156 : INFO : Step 5, Validation Loss= 0.4241, Validation Accuracy= 0.888
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 - tensorflow - INFO - Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,026 : INFO : Step 6, Minibatch Loss= 0.0171, Training Accuracy= 0.996
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 - tensorflow - INFO - Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:21,091 : INFO : Step 6, Validation Loss= 0.2684, Validation Accuracy= 0.920
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 - tensorflow - INFO - Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:22,959 : INFO : Step 7, Minibatch Loss= 0.0142, Training Accuracy= 0.995
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 - tensorflow - INFO - Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:23,025 : INFO : Step 7, Validation Loss= 0.4448, Validation Accuracy= 0.888
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 - tensorflow - INFO - Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,830 : INFO : Step 8, Minibatch Loss= 0.0092, Training Accuracy= 0.998
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 - tensorflow - INFO - Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:24,892 : INFO : Step 8, Validation Loss= 0.4700, Validation Accuracy= 0.901
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 - tensorflow - INFO - Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,745 : INFO : Step 9, Minibatch Loss= 0.0087, Training Accuracy= 0.997
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 - tensorflow - INFO - Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:26,814 : INFO : Step 9, Validation Loss= 0.2969, Validation Accuracy= 0.938
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 - tensorflow - INFO - Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,684 : INFO : Step 10, Minibatch Loss= 0.0078, Training Accuracy= 0.998
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 - tensorflow - INFO - Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-02 19:29:28,748 : INFO : Step 10, Validation Loss= 0.6205, Validation Accuracy= 0.886
2018-01-03 09:50:27,808 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:50:27,812 : INFO : collecting all words and their counts
2018-01-03 09:50:27,813 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:50:27,845 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:50:27,846 : INFO : Loading a fresh vocabulary
2018-01-03 09:50:27,876 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:50:27,876 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:50:27,908 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:50:27,908 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:50:27,908 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:50:27,909 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:50:27,925 : INFO : resetting layer weights
2018-01-03 09:50:28,016 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:50:28,439 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:50:28,440 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:50:28,446 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:50:28,446 : INFO : training on 797984 raw words (558582 effective words) took 0.4s, 1333700 effective words/s
2018-01-03 09:50:28,446 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:50:28,950 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:50:28,953 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:50:28,956 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:50:28,956 : INFO : training on 797984 raw words (558696 effective words) took 0.5s, 1114391 effective words/s
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:50:51,563 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,630 - tensorflow - INFO - Step 1, Minibatch Loss= 0.4034, Training Accuracy= 0.840
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:51:01,710 - tensorflow - INFO - Step 1, Validation Loss= 0.6232, Validation Accuracy= 0.604
2018-01-03 09:53:59,151 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:53:59,151 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:53:59,151 : INFO : collecting all words and their counts
2018-01-03 09:53:59,151 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 09:53:59,152 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:53:59,152 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:53:59,177 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:53:59,177 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:53:59,177 : INFO : Loading a fresh vocabulary
2018-01-03 09:53:59,177 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 09:53:59,193 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:53:59,193 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:53:59,193 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:53:59,193 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:53:59,218 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:53:59,218 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 09:53:59,219 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 09:53:59,219 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:53:59,219 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:53:59,219 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:53:59,233 : INFO : resetting layer weights
2018-01-03 09:53:59,233 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 09:53:59,313 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,313 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,765 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:53:59,765 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:53:59,769 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:53:59,769 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:53:59,773 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:53:59,773 : INFO : training on 797984 raw words (558605 effective words) took 0.5s, 1225854 effective words/s
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.5s, 1225854 effective words/s
2018-01-03 09:53:59,773 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:53:59,773 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:54:00,357 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:54:00,357 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:54:00,366 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:54:00,366 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:54:00,369 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:54:00,369 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:54:00,369 : INFO : training on 797984 raw words (558766 effective words) took 0.6s, 947092 effective words/s
2018-01-03 09:54:00,369 - gensim.models.word2vec - INFO - training on 797984 raw words (558766 effective words) took 0.6s, 947092 effective words/s
2018-01-03 09:54:18,479 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:54:18,479 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:54:28,233 : INFO : Step 1, Minibatch Loss= 0.3887, Training Accuracy= 0.884
2018-01-03 09:54:28,233 - root - INFO - Step 1, Minibatch Loss= 0.3887, Training Accuracy= 0.884
2018-01-03 09:54:28,289 : INFO : Step 1, Validation Loss= 0.5196, Validation Accuracy= 0.751
2018-01-03 09:54:28,289 - root - INFO - Step 1, Validation Loss= 0.5196, Validation Accuracy= 0.751
2018-01-03 09:55:57,363 : INFO : test
2018-01-03 09:55:57,363 - root - INFO - test
2018-01-03 09:57:01,986 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:57:01,986 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 09:57:01,987 : INFO : collecting all words and their counts
2018-01-03 09:57:01,987 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 09:57:01,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:57:01,987 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 09:57:02,021 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:57:02,021 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 09:57:02,021 : INFO : Loading a fresh vocabulary
2018-01-03 09:57:02,021 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 09:57:02,039 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:57:02,039 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 09:57:02,040 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:57:02,040 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 09:57:02,078 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 09:57:02,078 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 09:57:02,078 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:57:02,078 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 09:57:02,079 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:57:02,079 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 09:57:02,100 : INFO : resetting layer weights
2018-01-03 09:57:02,100 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 09:57:02,170 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,170 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,632 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:02,632 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:02,634 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:02,634 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:02,641 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:02,641 : INFO : training on 797984 raw words (558609 effective words) took 0.5s, 1200088 effective words/s
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.5s, 1200088 effective words/s
2018-01-03 09:57:02,641 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:02,641 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 09:57:03,171 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:03,171 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 09:57:03,174 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:03,174 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 09:57:03,178 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:03,178 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 09:57:03,178 : INFO : training on 797984 raw words (558875 effective words) took 0.5s, 1049312 effective words/s
2018-01-03 09:57:03,178 - gensim.models.word2vec - INFO - training on 797984 raw words (558875 effective words) took 0.5s, 1049312 effective words/s
2018-01-03 09:57:21,546 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:57:21,546 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 09:57:31,145 : INFO : Step 1, Minibatch Loss= 0.2820, Training Accuracy= 0.923
2018-01-03 09:57:31,145 - root - INFO - Step 1, Minibatch Loss= 0.2820, Training Accuracy= 0.923
2018-01-03 09:57:31,200 : INFO : Step 1, Validation Loss= 0.4428, Validation Accuracy= 0.804
2018-01-03 09:57:31,200 - root - INFO - Step 1, Validation Loss= 0.4428, Validation Accuracy= 0.804
2018-01-03 09:57:31,201 : INFO : Code run-time: 29.735768795013428 seconds
2018-01-03 09:57:31,201 - root - INFO - Code run-time: 29.735768795013428 seconds
2018-01-03 10:08:30,512 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,512 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,512 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:08:30,513 : INFO : collecting all words and their counts
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:08:30,513 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,513 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:08:30,538 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:08:30,538 : INFO : Loading a fresh vocabulary
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:08:30,538 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:08:30,552 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,552 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,552 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:08:30,553 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,553 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,553 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:08:30,570 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,570 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,570 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:08:30,571 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:08:30,571 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,571 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:08:30,572 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,572 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,572 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:08:30,589 : INFO : resetting layer weights
2018-01-03 10:08:30,589 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:08:30,589 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:08:30,665 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:30,665 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:30,665 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,104 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,104 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,109 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,109 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,109 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,111 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,111 : INFO : training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training on 797984 raw words (558605 effective words) took 0.4s, 1263772 effective words/s
2018-01-03 10:08:31,111 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,111 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:08:31,583 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,583 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,583 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:08:31,588 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,588 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,588 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:08:31,592 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,592 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,592 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:08:31,593 : INFO : training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:31,593 - gensim.models.word2vec - INFO - training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:31,593 - gensim.models.word2vec - INFO - training on 797984 raw words (558237 effective words) took 0.5s, 1170209 effective words/s
2018-01-03 10:08:49,977 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:49,977 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:49,977 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:08:57,621 : INFO : Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,621 - root - INFO - Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,621 - root - INFO - Step 1, Minibatch Loss= 0.2237, Training Accuracy= 0.921
2018-01-03 10:08:57,677 : INFO : Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 - root - INFO - Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 - root - INFO - Step 1, Validation Loss= 0.2872, Validation Accuracy= 0.845
2018-01-03 10:08:57,677 : INFO : Code run-time: 27.631388187408447 seconds
2018-01-03 10:08:57,677 - root - INFO - Code run-time: 27.631388187408447 seconds
2018-01-03 10:08:57,677 - root - INFO - Code run-time: 27.631388187408447 seconds
2018-01-03 10:10:22,344 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,344 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,344 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:10:22,345 : INFO : collecting all words and their counts
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:10:22,345 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,345 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:10:22,368 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:10:22,368 : INFO : Loading a fresh vocabulary
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:10:22,368 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:10:22,382 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:10:22,382 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,382 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:10:22,402 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,402 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,402 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:10:22,403 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:10:22,403 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:10:22,403 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,403 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:10:22,421 : INFO : resetting layer weights
2018-01-03 10:10:22,421 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:10:22,421 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:10:22,500 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,500 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,500 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,960 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:22,960 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,960 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:22,967 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,967 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,967 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:22,968 : INFO : training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training on 797984 raw words (558813 effective words) took 0.5s, 1211191 effective words/s
2018-01-03 10:10:22,968 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:22,968 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:10:23,502 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,502 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,502 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:10:23,509 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,509 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,509 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:10:23,510 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:10:23,510 : INFO : training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:23,510 - gensim.models.word2vec - INFO - training on 797984 raw words (558474 effective words) took 0.5s, 1040352 effective words/s
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:42,784 - tensorflow - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,463 - tensorflow - INFO - Step 1, Minibatch Loss= 0.2386, Training Accuracy= 0.919
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,528 - tensorflow - INFO - Step 1, Validation Loss= 0.3249, Validation Accuracy= 0.819
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:10:50,533 - tensorflow - INFO - Code run-time: 28.64625883102417 seconds
2018-01-03 10:17:00,602 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,602 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,602 - gensim.models.word2vec - WARNING - consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:17:00,603 : INFO : collecting all words and their counts
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - collecting all words and their counts
2018-01-03 10:17:00,603 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,603 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:17:00,626 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:17:00,626 : INFO : Loading a fresh vocabulary
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:17:00,626 - gensim.models.word2vec - INFO - Loading a fresh vocabulary
2018-01-03 10:17:00,640 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:17:00,640 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,640 - gensim.models.word2vec - INFO - min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:17:00,659 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 6994 items
2018-01-03 10:17:00,659 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - sample=0.001 downsamples 59 most-common words
2018-01-03 10:17:00,659 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,659 - gensim.models.word2vec - INFO - downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:17:00,660 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,660 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,660 - gensim.models.word2vec - INFO - estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:17:00,674 : INFO : resetting layer weights
2018-01-03 10:17:00,674 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:17:00,674 - gensim.models.word2vec - INFO - resetting layer weights
2018-01-03 10:17:00,750 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:00,750 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:00,750 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,176 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,181 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,182 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,182 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training on 797984 raw words (558609 effective words) took 0.4s, 1331131 effective words/s
2018-01-03 10:17:01,182 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,182 - gensim.models.word2vec - INFO - training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:17:01,616 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,616 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,616 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:17:01,622 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,622 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,622 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:17:01,624 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:17:01,624 : INFO : training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:01,624 - gensim.models.word2vec - INFO - training on 797984 raw words (558818 effective words) took 0.4s, 1277317 effective words/s
2018-01-03 10:17:21,615 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:21,615 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:21,615 - root - INFO - starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:17:29,250 : INFO : Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,250 - root - INFO - Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,250 - root - INFO - Step 1, Minibatch Loss= 0.3407, Training Accuracy= 0.905
2018-01-03 10:17:29,305 : INFO : Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 - root - INFO - Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 - root - INFO - Step 1, Validation Loss= 0.4403, Validation Accuracy= 0.798
2018-01-03 10:17:29,305 : INFO : Code run-time: 29.17209815979004 seconds
2018-01-03 10:17:29,305 - root - INFO - Code run-time: 29.17209815979004 seconds
2018-01-03 10:17:29,305 - root - INFO - Code run-time: 29.17209815979004 seconds
2018-01-03 10:20:13,486 : WARNING : consider setting layer size to a multiple of 4 for greater performance
2018-01-03 10:20:13,487 : INFO : collecting all words and their counts
2018-01-03 10:20:13,487 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-01-03 10:20:13,523 : INFO : collected 6994 word types from a corpus of 99748 raw words and 4743 sentences
2018-01-03 10:20:13,523 : INFO : Loading a fresh vocabulary
2018-01-03 10:20:13,539 : INFO : min_count=1 retains 6994 unique words (100% of original 6994, drops 0)
2018-01-03 10:20:13,539 : INFO : min_count=1 leaves 99748 word corpus (100% of original 99748, drops 0)
2018-01-03 10:20:13,556 : INFO : deleting the raw counts dictionary of 6994 items
2018-01-03 10:20:13,557 : INFO : sample=0.001 downsamples 59 most-common words
2018-01-03 10:20:13,557 : INFO : downsampling leaves estimated 69830 word corpus (70.0% of prior 99748)
2018-01-03 10:20:13,557 : INFO : estimated required memory for 6994 words and 50 dimensions: 6294600 bytes
2018-01-03 10:20:13,568 : INFO : resetting layer weights
2018-01-03 10:20:13,639 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:20:14,072 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:20:14,075 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:20:14,078 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:20:14,078 : INFO : training on 797984 raw words (558609 effective words) took 0.4s, 1283174 effective words/s
2018-01-03 10:20:14,079 : INFO : training model with 3 workers on 6994 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
2018-01-03 10:20:14,496 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-01-03 10:20:14,499 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-01-03 10:20:14,503 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-01-03 10:20:14,503 : INFO : training on 797984 raw words (558651 effective words) took 0.4s, 1327742 effective words/s
2018-01-03 10:20:32,417 : INFO : starting training for the follwing parameters: training_steps=1, batch_size=93, embed_size=50, num_hidden=20
2018-01-03 10:20:40,486 : INFO : Step 1, Minibatch Loss= 0.3690, Training Accuracy= 0.888
2018-01-03 10:20:40,550 : INFO : Step 1, Validation Loss= 0.5586, Validation Accuracy= 0.727
2018-01-03 10:20:40,551 : INFO : Code run-time: 27.581203937530518 seconds
